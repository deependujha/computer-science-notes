{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"#content-tabs","title":"Content tabs","text":"<p>Example</p> C++Python <pre><code># include&lt;iostream&gt;\nusing namespace std;\n\nint main(){\n    cout&lt;&lt;\"Hello World\"&lt;&lt;endl;\n    return 0;\n}\n</code></pre> <pre><code>print(\"Hello World\")\n</code></pre>"},{"location":"01-os/","title":"Operating System \ud83e\udd13\ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb","text":""},{"location":"01-os/#what-is-operating-system","title":"What is Operating System?","text":"<p>Operating System</p> <p>Interface between user (application) and hardware.</p>"},{"location":"01-os/01-Basic-Concepts/01-introduction/01-introduction-to-os/","title":"Introduction to Operating System","text":"<ul> <li> <p>Application software: performs specific task for the user.</p> </li> <li> <p>System software: operates and controls the computer system and provides a platform to run application software.</p> </li> </ul> What is an Operating System? <p>An operating system is a piece of software that manages all the resources of a computer system, both hardware and software, and provides an environment in which the user can execute his/her programs in a convenient and efficient manner by hiding underlying complexity of the hardware and acting as a resource manager.</p> <ul> <li>It is a system software that acts as an interface between the user and the computer.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/01-introduction-to-os/#why-os","title":"Why OS?","text":"<ol> <li> <p>What if there is no OS?</p> <ul> <li>Bulky and complex app. (Hardware interaction code must be in app\u2019s code base)</li> <li>Resource exploitation by 1 App (since there's no one to protect and manage resources)</li> <li>No memory protection. (One app can overwrite another app's memory)</li> </ul> </li> <li> <p>What is an OS made up of?</p> <ul> <li>Collection of system software.</li> </ul> </li> </ol>"},{"location":"01-os/01-Basic-Concepts/01-introduction/01-introduction-to-os/#functions-of-an-operating-system","title":"Functions of an operating system","text":"<ul> <li>Access to the computer hardware.</li> <li>interface between the user and the computer hardware </li> <li>Resource management (Aka, Arbitration) (memory, device, file, security, process, etc)</li> <li>Hides the underlying complexity of the hardware. (Aka, Abstraction)</li> <li>facilitates the execution of application programs by providing isolation and protection.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/01-introduction-to-os/#goals-of-os","title":"Goals of OS \ud83d\ude42","text":"<ul> <li>Maximum CPU utilization</li> <li>Less process starvation</li> <li>Higher-priority job execution</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/","title":"Types of Operating Systems","text":""},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/#types-of-os","title":"Types of OS \ud83c\udf89","text":"<ul> <li>Single processing OS [MS-DOS 1981]</li> <li>Batch-processing OS [ATLAS, Manchester Univ., 1950s-1960s]</li> <li>Multi-programming OS [THE, DIJKSTRA, early 1960s]</li> <li>Multi-tasking OS [CTSS, MIT, early 1960s]</li> <li>Multi-processing OS [Windows NT]</li> <li>Distributed System [LOCUS]</li> <li>Real-time OS [ATCS]</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/#details-of-os","title":"~&gt; Details of OS \ud83e\udd13","text":""},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/#1-single-processing-os","title":"1. Single processing OS","text":"<ul> <li>Only 1 process executes at a time from the ready queue (OLDEST)</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/#2-batch-processing-os","title":"2. Batch-processing OS","text":"<ul> <li>Firstly, user prepares his job using punch cards.</li> <li>Then, he submits his job to the computer operator.</li> <li>Operator collects the jobs from different users and sorts the jobs into batches with similar needs.</li> <li>Then, operator submits the batches to the processor one by one.</li> <li>All the jobs of one batch are executed together.</li> </ul> <ul> <li>Priorities cannot be set, if a job comes with some higher priority.</li> <li>May lead to starvation. (A batch may take more time to complete)</li> <li>CPU may become idle in case of I/O operations.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/#3-multi-programming-os","title":"3. Multi-programming OS","text":"<ul> <li>Single CPU</li> <li>Maintains a ready queue. It increases CPU utilization by keeping multiple jobs (codes &amp; data) in the memory so that the CPU always has some job to execute in case the currently running job gets busy with I/O.</li> <li>Context Switching for process</li> <li>Switch happens when current process goes to the wait state.</li> <li>When context switching, the running program writes/saves details in PCB (process control block).</li> <li>CPU idle time reduces.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/#4-multi-tasking-os","title":"4. Multi-tasking OS","text":"<ul> <li>Almost similar to Multi-programming OS + time-sharing</li> <li>Each process is executed for a maximum fixed interval of time, then another program is sent to the CPU.</li> <li>It is also known as <code>time-sharing systems</code>.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/#5-multi-processing-os","title":"5. Multi-processing OS","text":"<ul> <li>More than 1 CPU in a single computer</li> <li>Increases reliability, if 1 CPU fails, the other is still running. Better throughput</li> <li>Lesser process starvation (if 1 process is running on 1 CPU, another process can run on another CPU)</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/#5-distributed-os","title":"5. Distributed OS","text":"<ul> <li>OS manages many bunches of resources,</li> <li><code>&gt;= 1 CPU, &gt;= 1 memory, &gt;= 1 GPU, etc.</code></li> <li>Loosely connected autonomous, interconnected nodes</li> <li>Collection of independent, networked, communicating, and physically separate computational nodes.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/02-types-of-os/#6-real-time-os-rtos","title":"6. Real-time OS (RTOS)","text":"<ul> <li>Real-time, error-free, computations within time-tight boundaries.</li> <li>Air-traffic control system, ROBOTS, etc.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/03-multi-tasking-vs-multi-threading/","title":"Multi-tasking Vs Multi-threading \ud83e\udd77\ud83c\udffb","text":"Analogy explanation of <code>multitasking</code> &amp; <code>multithreading</code> <p>Let's say there's one computer and a maintainer, and there are 5 people in a line waiting for their chance to use PC and do their work. Maintainer maintains a rule that no individual is allowed to work continuously for consecutive 5 minutes. If his/her work completes with in 5 minutes, they leave and the next one will get the PC, else, after 5 minutes, they will go back to the end of the line and again wait for their turn.</p> <p>This is multi-tasking, (time-sharing).</p> <p>Now, suppose a individual person needs to send some mail, research some topic, and download some pics. Either he can do one task after another, or he can perform a task for some time, let's say 1 minute and then move to another task. So, he is basically switching tasks in his own time frame.  This is multi-threading. Each individual task will be called an independent thread of execution.</p> <p>This is multi-threading.</p>"},{"location":"01-os/01-Basic-Concepts/01-introduction/03-multi-tasking-vs-multi-threading/#concept","title":"Concept \ud83d\udd75\ud83c\udffb\u200d\u2642\ufe0f","text":"<p>Program: A Program is an executable file which contains a certain set of instructions written to complete the specific job or operation on your computer.     - It\u2019s a compiled code. Ready to be executed.     - Stored in Disk</p> <p>Process: <code>Program under execution</code>.     -  Resides in Computer\u2019s primary memory (RAM).</p> <p>Threads: A thread is a lightweight process that runs within a larger process or within an operating system. It is also known as the thread of execution or the thread of control.</p> <p>Threads \ud83e\udea1\ud83e\uddf6</p> <ul> <li>Single sequence stream within a process.</li> <li>An independent path of execution in a process.</li> <li>lightweight process. It is a smallest unit of processing.</li> <li>A thread is a single sequence stream within in a process.</li> <li>Because threads have some of the properties of processes, they are sometimes called <code>lightweight processes</code>.</li> <li>Used to achieve parallelism by dividing a process's tasks which are independent path of execution.</li> <li>Threads exist within a process \u2014 every process has at least one. Threads share the process\u2019s resources, including memory and open files.</li> <li>E.g., Multiple tabs in a browser, text editor (When you are typing in an editor, spell-checking, formatting of text and saving the text are done concurrently by multiple threads.)</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/03-multi-tasking-vs-multi-threading/#multi-tasking-vs-multi-threading_1","title":"Multi-tasking Vs Multi-threading","text":"Multi-Tasking Multi-Threading The execution of more than one task simultaneously A process is divided into several different sub-tasks called as threads, which has its own path of execution. This concept is called as multithreading. Concept of more than 1 processes being context switched. Concept of more than 1 thread. Threads are context switched. Isolation and memory protection exists. OS must allocate separate memory and resources to each program that CPU is executing. No isolation and memory protection, resources are shared among threads of that process. OS allocates memory to a process; multiple threads of that process share the same memory and resources allocated to the process."},{"location":"01-os/01-Basic-Concepts/01-introduction/03-multi-tasking-vs-multi-threading/#thread-scheduling","title":"Thread Scheduling","text":"<ul> <li>Threads are scheduled for execution based on their priority.</li> <li>Even though threads are executing within the runtime, all threads are assigned processor time slices by the operating system.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/03-multi-tasking-vs-multi-threading/#thread-context-switching-vs-process-context-switching","title":"Thread Context Switching Vs Process Context Switching","text":"Thread Context Switching Process Context Switching OS saves current state of thread &amp; switches to another thread of same process. OS saves current state of process &amp; switches to another process by restoring its state. Doesn\u2019t includes switching of memory address space. (But Program counter, registers &amp; stack are included.) Includes switching of memory address space. Fast switching. Slow switching. CPU\u2019s cache state is preserved. CPU\u2019s cache state is flushed. If threads are so good concept, why don't we make 100s or 1000s of threads? <ul> <li>You can create as many threads as you want, but you will only get as much parallelism as the number of cores in your CPU.</li> <li>Threads are not free. <code>Each thread consumes memory for its stack and other data structures</code>. </li> <li>Threads also require time to create and destroy. </li> <li><code>If you have too many threads, the overhead of managing them can exceed the benefit of parallelism</code>.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/","title":"Components of Operating System","text":""},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#components-of-os","title":"Components of OS \ud83d\ude08","text":"<ol> <li> <p>Kernel: A kernel is that part of the operating system which interacts directly with the hardware and performs the most crucial tasks.</p> <ul> <li>Heart of OS/Core component</li> <li>Very first part of OS to load on start-up.</li> </ul> </li> <li> <p>User space: Where application software runs, apps don\u2019t have privileged access to the underlying hardware. It interacts with kernel.</p> <ul> <li>GUI</li> <li>CLI</li> </ul> </li> </ol> <p>shell/ Command Interpreter</p> <p>A shell, also known as a command interpreter, is that part of the operating system that <code>receives commands from the users and gets them executed.</code></p>"},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#cpu-execution-modes","title":"CPU execution modes \ud83d\udea6","text":"<p>There are two modes in which CPU can execute code:</p> <ol> <li> <p>User mode</p> <ul> <li>non-privileged mode.</li> <li>used to run user applications and programs defined in user space.</li> </ul> </li> <li> <p>Kernel mode</p> <ul> <li>privileged mode.</li> <li>used to run the kernel and core OS services (defined in kernel space).</li> </ul> </li> </ol> <p>Kernel mode</p> <p>When you are typing <code>mkdir newDir</code> in terminal, the <code>mkdir</code> command is running in user mode, but the <code>mkdir</code> command is calling the <code>mkdir</code> system call which is running in kernel mode.</p> <ul> <li>CPU execution switches from <code>user mode</code> to <code>kernel mode</code>.</li> <li>This is done by system interrupts.</li> <li>The switching takes some time, so it's not good to switch frequently.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#functions-of-kernel","title":"Functions of Kernel \ud83d\udc6e\ud83c\udffb\u200d\u2642\ufe0f","text":"<p>1. Process management</p> <ul> <li>Scheduling processes and threads on the CPUs.</li> <li>Creating &amp; deleting both user and system process.</li> <li>Suspending and resuming processes</li> <li>Providing mechanisms for process synchronization or process communication.</li> </ul> <p>2. Memory management</p> <ul> <li>Allocating and deallocating memory space as per need.</li> <li>Keeping track of which part of memory are currently being used and by which process.</li> </ul> <p>3. File management</p> <ul> <li>Creating and deleting files.</li> <li>Creating and deleting directories to organize files.</li> <li>Mapping files into secondary storage.</li> <li>Backup support onto a stable storage media.</li> </ul> <p>4. I/O management</p> <ul> <li>to manage and control I/O operations and I/O devices</li> <li>Buffering (data copy between two devices), caching and spooling.<ul> <li>Within differing speed two jobs.</li> <li>Eg. Print spooling and mail spooling.</li> </ul> </li> <li>Buffering<ul> <li>Within one job.</li> <li>Eg. Youtube video buffering</li> </ul> </li> <li>Caching<ul> <li>Memory caching, Web caching etc.</li> </ul> </li> </ul> what is spooling? <ul> <li>Spooling is a process in which data is temporarily held to be used and executed by a device, program or the system. It is a place where data is stored to be processed or printed later.</li> <li>In modern systems, spooling is often used when data needs to be transferred from a program to a peripheral (such as a printer).</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#types-of-kernels","title":"Types of Kernels \ud83e\udd16","text":""},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#1-monolithic-kernel","title":"1. Monolithic Kernel","text":"<ul> <li>All functions are in kernel itself. <pre><code>- Bulky in size.\n- Memory required to run is high.\n- Less reliable, one module crashes -&gt; whole kernel is down.\n+ High performance as communication is fast. (Less user mode, kernel mode overheads)\n</code></pre></li> <li>Eg. Linux, Unix, MS-DOS.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#2-micro-kernel","title":"2. Micro Kernel","text":"<ul> <li>Only major functions are in kernel.<ul> <li>Memory management.</li> <li>Process management.</li> </ul> </li> <li>File management and IO management are in User-space. <pre><code>+ smaller in size.\n+ More Reliable\n+ More stable\n- Performance is slow (bcoz of switching between user mode and kernel mode)\n- Overhead switching b/w user mode and kernel mode.\n</code></pre></li> <li>Eg. L4 Linux, Symbian OS, MINIX etc.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#3-hybrid-kernel","title":"3. Hybrid Kernel","text":"<ul> <li>Advantages of both worlds. (File management. in User space and rest in Kernel space. ) <pre><code>+ Combined approach.\n+ Speed and design of mono.\n+ Modularity and stability of micro.\n</code></pre></li> <li>Eg. MacOS, Windows NT/7/10</li> <li>IPC also happens but lesser overheads</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#4-exo-kernels","title":"4. Exo kernels","text":"<ul> <li>Smallest in size.</li> <li>Only basic functions.</li> <li>Rest in user space. <pre><code>- has fewest hardware abstractions as possible.\n- It allocates physical resources to applications.\n</code></pre></li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#5-nano-kernel","title":"5. Nano Kernel","text":"<ul> <li>It is the type of kernel that offers hardware abstraction but without system services.</li> <li>Micro Kernel also does not have system services therefore the Micro Kernel and Nano Kernel have become analogous.</li> <li>The main difference between the two is that the Nano Kernel is designed to be as small as possible.</li> <li><code>Micro kernels</code> which actually are micro in size are also called <code>nano kernels</code>.</li> </ul> Nano/Exo kernels <p>a type of operating system kernel that has a minimal and streamlined design, with a focus on minimalism and efficiency. The goal of a nano kernel is to provide only the essential functions required for the operation of a system while delegating other functions to user-space processes.</p>"},{"location":"01-os/01-Basic-Concepts/01-introduction/04-components-of-os/#communication-bw-user-mode-and-kernel-mode","title":"Communication b/w User mode and Kernel mode \ud83d\udce1","text":"Q. How will communication happen between user mode and kernel mode? <ul> <li>Inter process communication (IPC). This can be done in two ways:<ul> <li>Shared memory: <ul> <li>A region of memory that is shared between two processes.</li> <li>One process writes to the shared memory and the other process reads from it.</li> </ul> </li> <li>Message passing: <ul> <li>A logical channel is established between two processes.</li> <li>A process sends a message to another process and the other process receives it.</li> <li>Eg. pipes, sockets, message queues, signals, semaphores, shared memory, and message passing.</li> </ul> </li> </ul> </li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/05-system-calls/","title":"System Calls \ud83d\udcde\u260e\ufe0f","text":"<p>How do apps interact with Kernel?</p> <p>using system calls.</p>"},{"location":"01-os/01-Basic-Concepts/01-introduction/05-system-calls/#what-are-system-calls","title":"What are system calls?","text":"<ul> <li>A system call is a mechanism using which a user program can request a service from the kernel for which it does not have the permission to perform.</li> <li>User programs typically do not have permission to perform operations like accessing I/O devices and communicating other programs.</li> <li><code>System Calls are the only way through which a process can go into kernel mode from user mode.</code></li> <li>Transitions from <code>UserMode</code> to <code>KernelMode</code> done by software interrupts.</li> <li>System Calls are implemented in C and Assembly language.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/05-system-calls/#example","title":"Example:","text":"<ul> <li> <p>Eg. <code>mkdir my_dir</code></p> <ul> <li>Mkdir indirectly calls kernel and asked the file mgmt. module to create a new directory.</li> <li>Mkdir is just a wrapper of actual system calls.</li> <li>Mkdir interacts with kernel using system calls.   </li> </ul> </li> <li> <p>Eg. <code>Creating a process</code></p> <ul> <li>User executes a process. (User space)</li> <li>Gets system call. (US)</li> <li>Exec system call to create a process. (KS)</li> <li>Return to user space.</li> </ul> </li> </ul>"},{"location":"01-os/01-Basic-Concepts/01-introduction/05-system-calls/#types-of-system-calls","title":"Types of System Calls:","text":""},{"location":"01-os/01-Basic-Concepts/01-introduction/05-system-calls/#faqs","title":"FAQs \ud83d\ude4b\u200d\u2642\ufe0f","text":"Q.1: What is the purpose of System Calls? <p>The purpose of the system calls is to allow user-level applications access of the services provided by the kernel. The user apps do not have the privilege to perform operations, so they make system calls which further requests a kernel to provide a specific service.</p> Q.2: How do device management System Calls work? <p>Device management system calls work by allowing a certain process or a device interact and get access to other hardware resources and perform various operations.</p> Q.3: What is user mode and kernel mode? <p>User mode and kernel modes are two different privilege modes of a Computer System, that separates the execution of operations by the user applications and the kernel on hardware. This separation provides security, stability, and a level of control over system resources.</p> Q.4: What happens when a System Call is executed? <p>When a system call is executed, a context switch occurs and the computer system switches from user mode to kernel mode and now the kernel performs the desired operation.</p> Q.5: What is a software interrupt? <p>A software interrupt is a mechanism through which the OS performs a context switch and transition from user mode to kernel mode. A software interrupt use is not limited only to the system calls but it can also be made when a high priority task is required to be executed by the CPU.</p>"},{"location":"01-os/01-Basic-Concepts/02-important-to-know/06-how-operating-system-boots-up/","title":"How Operating System Boots up?","text":"<p>We can describe it in 5 steps:</p> <p></p> <ol> <li> <p>PC power On.</p> </li> <li> <p>CPU initializes itself and looks for a firmware program (BIOS) stored in BIOS Chip (Basic input-output system chip is a ROM chip found on mother board that allows to access &amp; setup computer system at most basic level.)</p> <ul> <li>In modern PCs, CPU loads UEFI (<code>Unified extensible firmware interface</code>)</li> </ul> </li> <li> <p>CPU runs the BIOS which tests and initializes system hardware. Bios loads configuration settings. If something is not appropriate (like missing RAM) error is thrown and boot process is stopped. This is called POST (Power on self-test) process. </p> <ul> <li>(UEFI can do a lot more than just initialize hardware; it\u2019s really a tiny operating system. For example, Intel CPUs have the Intel Management Engine. This provides a variety of features, including powering Intel\u2019s Active Management Technology, which allows for remote management of Business PCs.)</li> </ul> </li> <li> <p>BIOS will handoff responsibility for booting your PC to your OS\u2019s bootloader.</p> <ul> <li>BIOS looked at the MBR (Master Boot Record), a special boot sector at the beginning of a disk The MBR contains code that loads the rest of the OS, known as <code>bootloader</code>. The BIOS executes the bootloader, which takes it from there and begins booting the actual OS (windows or linux or mac).</li> <li>Typically, present at the <code>0th index</code> of the disk.</li> <li>In other words, BIOS or UEFI examines a storage device on your system to look for a small program, either in MBR or on an EFI system partition, and runs it.</li> </ul> </li> <li> <p>The bootloader is a small program that has the large task of booting the rest of the operating system (Boots Kernel then, User Space).</p> <ul> <li>Windows uses a bootloader named <code>Windows Boot Manager (Bootmgr.exe)</code>.</li> <li>most Linux systems use <code>GRUB</code>, and Macs use something called <code>boot.efi</code>.</li> </ul> </li> </ol>"},{"location":"01-os/01-Basic-Concepts/02-important-to-know/07-32-Bit_vs_64-Bit-os/","title":"Difference between 32-bit &amp; 64-bit Operating System","text":""},{"location":"01-os/01-Basic-Concepts/02-important-to-know/07-32-Bit_vs_64-Bit-os/#comparison","title":"Comparison \ud83d\ude08","text":"32-bit 64-bit A 32-bit OS has 32-bit registers, and it can access 2^32 unique memory addresses. i.e., 4GB of RAM. A 64-bit OS has 64-bit registers, and it can access 2^64 unique memory addresses. i.e., 17,179,869,184 GB of RAM. 32-bit CPU architecture can process 32 bits of data &amp; information. 64-bit CPU architecture can process 64 bits of data &amp; information."},{"location":"01-os/01-Basic-Concepts/02-important-to-know/07-32-Bit_vs_64-Bit-os/#advantages-of-64-bit-os-over-32-bit-os","title":"Advantages of 64-BIT OS over 32-BIT OS: \ud83e\udd29","text":"<ol> <li> <p>Addressable Memory: 32-bit CPU -&gt; 2^32 memory addresses, 64-bit CPU -&gt; 2^64 memory addresses.</p> </li> <li> <p>Resource usage: Installing more RAM on a system with a 32-bit OS doesn't impact performance. However, upgrade that system with excess RAM to the 64-bit version of Windows, and you'll notice a difference.</p> </li> <li> <p>Performance: <code>All calculations take place in the registers</code>. When you\u2019re performing math in your code, operands are loaded from memory into registers. So, having larger registers allow you to perform larger calculations at the same time.</p> <ul> <li>32-bit processor can execute 4 bytes of data in 1 instruction cycle while 64-bit means that processor can execute 8 bytes of data in 1 instruction cycle. (In 1 sec, there could be thousands to billions of instruction cycles depending upon a processor design, hence, <code>64-bit can process much more data in 1 sec than 32-bit</code>.)</li> </ul> </li> <li> <p>Compatibility: 64-bit CPU can run both 32-bit and 64-bit OS. While 32-bit CPU can only run 32-bit OS. (All the starting bits will be 0 in 64-bit CPU while working with 32-bit OS.)</p> </li> <li> <p>Better Graphics performance: 8-bytes graphics calculations make graphics-intensive apps run faster.</p> </li> </ol>"},{"location":"01-os/01-Basic-Concepts/02-important-to-know/08-different-STORAGES-used-in-computers/","title":"Different STORAGES used in Computers \ud83e\udd13\ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb","text":""},{"location":"01-os/01-Basic-Concepts/02-important-to-know/08-different-STORAGES-used-in-computers/#memory-hierarchy","title":"Memory Hierarchy","text":"<ul> <li> <p>Register: Smallest unit of storage. It is a part of CPU itself.</p> <ul> <li>A register may hold an instruction, a storage address, or any data (such as bit sequence or individual characters).</li> <li>Registers are a type of computer memory used to quickly accept, store, and transfer data and instructions that are being used immediately by the CPU.</li> </ul> </li> <li> <p>Cache: Additional memory system that temporarily stores frequently used instructions and data for quicker processing by the CPU.</p> </li> <li> <p>Main Memory: <code>RAM</code>.</p> </li> <li>Secondary Memory: Storage media, on which computer can store data &amp; programs.</li> </ul>"},{"location":"01-os/01-Basic-Concepts/02-important-to-know/08-different-STORAGES-used-in-computers/#comparison","title":"Comparison \ud83e\udd3a","text":"<ol> <li> <p>Cost:</p> <ul> <li>Primary storages are costly.</li> <li>Registers are most expensive due to expensive semiconductors &amp; labour.</li> <li>Secondary storages are cheaper than primary.</li> </ul> </li> <li> <p>Access Speed:</p> <ul> <li>Primary has higher access speed than secondary memory.</li> <li>Registers has highest access speed, then comes cache, then main memory.</li> </ul> </li> <li> <p>Storage size:</p> <ul> <li>Secondary has more space.</li> </ul> </li> <li> <p>Volatility:</p> <ul> <li>Primary memory is volatile. <code>(Data is lost when power is turned off.)</code></li> <li>Secondary is non-volatile. <code>(Data is retained even when power is turned off.)</code></li> </ul> </li> </ol>"},{"location":"01-os/02-process-management/01-intro-to-process/01-intro-to-process-management/","title":"Introduction to Process Management \ud83c\udff4\u200d\u2620\ufe0f","text":"<p>What is a program?</p> <p>Compiled code, that is ready to execute.</p> <p>What is a process?</p> <p>Program under execution.</p> <p>How OS creates a process? Converting program into a process.</p> <ul> <li>Load the program &amp; static data into memory.</li> <li>Allocate runtime stack.</li> <li>Heap memory allocation.</li> <li>IO tasks:<ul> <li>After allocating memory, OS then creates I/O descriptors for the process.</li> <li>These descriptors are used to interact with the I/O devices. They are:<ul> <li><code>input descriptor</code> (creates a handler that process will use when it needs to read from the input device)</li> <li><code>output descriptor</code> (creates a handler that process will use when it needs to write to the output device)</li> <li><code>error descriptor</code> (creates a handler that process will use when it needs to write to the error device)</li> </ul> </li> </ul> </li> <li>OS handoffs control to main ().</li> </ul> Why do we return 0 from main? <ul> <li>Every process in the OS is created as a child of the <code>init (root)</code> process.</li> <li>It is a convention to return 0 from main to indicate that the program has executed successfully.</li> <li>If the program has encountered an error, then we return a non-zero value.</li> <li>In case of an error, the OS can take necessary action based on the return value.</li> </ul>"},{"location":"01-os/02-process-management/01-intro-to-process/01-intro-to-process-management/#architecture-of-a-process-in-ram","title":"Architecture of a Process in RAM \ud83c\udfd7\ufe0f\ud83c\udfd9\ufe0f","text":""},{"location":"01-os/02-process-management/01-intro-to-process/01-intro-to-process-management/#attributes-of-a-process","title":"Attributes of a Process","text":"<ul> <li>OS maintains a Process table to keep track of all the processes.</li> <li>Each process in the table is called a Process Control Block (PCB).</li> <li>PCB contains all the information about the process.</li> </ul>"},{"location":"01-os/02-process-management/01-intro-to-process/01-intro-to-process-management/#pcb-structure","title":"PCB structure \ud83d\udce6","text":"<ul> <li>Process ID (PID): Unique identifier for the process.</li> <li>Process State: Current state of the process. (Running, Ready, Blocked, etc.)</li> <li>Program Counter (PC): Microprocessors convert the code into sequence of instructions. PC keeps track of the next instruction to be executed.</li> <li>Registers: it is a data structure. When a processes is running and it's time slice expires, the current value of process specific registers would be stored in the PCB and the process would be swapped out. When the process is scheduled to be run, the register values is read from the PCB and written to the CPU registers. This is the main purpose of the registers in the PCB.</li> </ul>"},{"location":"01-os/02-process-management/01-intro-to-process/02-process-state-n-process-queues/","title":"Process State &amp; Process Queue \ud83d\udc6f","text":""},{"location":"01-os/02-process-management/01-intro-to-process/02-process-state-n-process-queues/#process-state","title":"Process State \ud83c\udfc3\ud83c\udffb","text":"<p>As process executes, it changes state. Each process may be in one of the following states:</p> <ul> <li> <p>New: OS is about to pick the program &amp; convert it into process. Or, the process is being created.</p> </li> <li> <p>Run: Instructions are being executed; CPU is allocated.</p> </li> <li> <p>Waiting: Waiting for IO.</p> </li> <li> <p>Ready: The process is in memory, waiting to be assigned to a processor.</p> </li> <li> <p>Terminated: The process has finished execution. PCB entry removed from process table.</p> </li> </ul> <p></p> <p>Process state</p> <ul> <li>Long-term scheduler: Selects which processes from a pool of <code>new</code> processes should be brought into the <code>ready</code> queue. It is called <code>long-term</code> because it is invoked infrequently (let's say after 1 second).</li> <li>When a process is in <code>ready state</code>, it is waiting to be assigned to a processor. Short-term scheduler selects a process from the <code>ready queue</code> and assigns it to the processor. It is called <code>short-term</code> because it is invoked very frequently (let's say after every 100 milliseconds).</li> <li>Waiting state is a temporary state. A process is moved to the waiting state if it needs to wait for a resource (like I/O) to become available. For example, if a process is waiting for user input, it will be in the waiting state. When the input is available, the process will be moved to the ready state and the short-term scheduler will pick a process from the ready queue and assign it to the processor.</li> <li>Terminated state is the final state. The process has finished its execution and is removed from the system.</li> <li>Interrupt is a signal to the OS that an event has occurred and needs immediate attention. It can be generated by the hardware or software. For example, an interrupt can be generated by a clock to indicate that a fixed interval of time has passed and the <code>running process</code> needs to be moved to the <code>ready queue</code> so that another process can be assigned to the processor.</li> </ul> Remember <ul> <li>Short-term scheduler: CPU Scheduler.</li> <li>Long-term scheduler: Job Scheduler.</li> </ul> What is Dispatcher? <ul> <li>It is the module that gives control of the CPU to the process selected by the short-term scheduler. It involves:<ul> <li>Switching context.</li> <li>Switching to user mode.</li> <li>Jumping to the proper location in the user program to restart that program.</li> </ul> </li> </ul> <p>Dispatch latency is the time taken to stop running process and run another process which was in the ready queue.</p>"},{"location":"01-os/02-process-management/01-intro-to-process/02-process-state-n-process-queues/#process-queue","title":"Process Queue \ud83d\udeb6\ud83c\udffb\u200d\u2642\ufe0f","text":"<ol> <li> <p>Job Queue:</p> <ul> <li>Processes in new state.</li> <li>Present in secondary memory.</li> <li><code>Job Schedular (Long term schedular (LTS)) picks process from the pool and loads them into memory for execution.</code></li> </ul> </li> <li> <p>Ready Queue:</p> <ul> <li>Processes in Ready state.</li> <li>Present in main memory.</li> <li><code>CPU Schedular (Short-term schedular) picks process from ready queue and dispatch it to CPU.</code></li> </ul> </li> <li> <p>Waiting Queue:</p> <ul> <li>Processes in Wait state.</li> </ul> </li> </ol>"},{"location":"01-os/02-process-management/01-intro-to-process/02-process-state-n-process-queues/#degree-of-multi-programming","title":"\u2b50\ufe0f Degree of multi-programming \ud83d\udcca","text":"<ul> <li>The number of processes in the memory.</li> <li>The degree of multiprogramming describes the maximum number of processes that a single-processor system can accommodate efficiently.</li> </ul> <p>Who controls degree of multi-programming?</p> <p>LTS controls degree of multi-programming. Because it decides how many processes are to be loaded into the memory (ready queue) for execution.</p>"},{"location":"01-os/02-process-management/01-intro-to-process/03-swapping-context-switching-orphan-n-zombie-process/","title":"Swapping (MTS), Context Switching, Orphan and Zombie Process","text":""},{"location":"01-os/02-process-management/01-intro-to-process/03-swapping-context-switching-orphan-n-zombie-process/#swapping-medium-term-scheduler-mts","title":"Swapping &amp; Medium-term scheduler (MTS) \u2653\ufe0f","text":"<p>Info</p> <ul> <li>Long-term scheduler (or job scheduler) selects which processes should be brought into the ready queue. It aims to select a good process mix of I/O-bound and CPU-bound processes.</li> <li>It anticipates their resource usages and then selects a good process mix. But its not perfect, and it may over-commit memory. </li> <li>Hence, we need to free up memory by removing some processes from memory. This is done by medium-term scheduler (MTS).</li> <li>medium-term scheduler (MTS) is a part of the operating system that decides which processes to swap in and out of memory. It is a part of the swapping function.</li> <li>Swapped-out processes are placed on the disk (in swap memory) and are swapped-in when memory becomes available.</li> <li>Swapping-out reduces the degree of multi-programming, and swapping-in increases it.</li> </ul> <p>Swapping is a mechanism in which a process can be swapped temporarily out of main memory (or move) to secondary storage (disk) and make that memory available to other processes. At some later time, the system swaps back the process from the secondary storage to main memory.</p>"},{"location":"01-os/02-process-management/01-intro-to-process/03-swapping-context-switching-orphan-n-zombie-process/#context-switching","title":"Context Switching \ud83d\udd04","text":"<ul> <li>Switching the CPU to another process requires performing a state save of the current process and a state restore of a different process.</li> <li>When this occurs, <code>the kernel saves the context of the old process in its PCB and loads the saved context of the new process scheduled to run</code>.</li> <li>It is pure overhead, because the system does no useful work while switching.</li> <li>Speed varies from machine to machine, depending on the memory speed, the number of registers that must be copied etc.</li> </ul>"},{"location":"01-os/02-process-management/01-intro-to-process/03-swapping-context-switching-orphan-n-zombie-process/#orphan-process","title":"Orphan process \ud83e\uddd2","text":"<ul> <li><code>Each process in the system has a parent process</code>. The root of the process tree is the <code>init process</code> (with PID=1).</li> <li>The process whose parent process has been terminated and it is still running.</li> <li>Orphan processes are adopted by init process.</li> <li>Init is the first process of OS. (PID = 1)</li> </ul> Practical on Orphan Process <ol> <li>Create a <code>orphan-script.sh</code> file and write the below code in it. <pre><code>#!/bin/bash\nsleep 200 &amp; # this will create a child process and detach it from the parent process.\n</code></pre></li> <li>Run the script using <code>./orphan-script.sh</code> command. (<code>chmod +x orphan-script.sh</code> if permission denied)</li> <li>In another terminal, check for the process <code>sleep</code> using <code>ps -al</code> command. Look for the <code>PPID</code> column. It should be <code>1</code> (init process).</li> </ol>"},{"location":"01-os/02-process-management/01-intro-to-process/03-swapping-context-switching-orphan-n-zombie-process/#zombie-process-defunct-process","title":"Zombie process / Defunct process \ud83e\udddf","text":"<ul> <li>A zombie process is a process whose execution is completed but it still has an entry in the process table.</li> <li>Zombie processes usually occur for child processes, as the parent process still needs to read its child\u2019s exit status.</li> <li><code>Once this is done using the wait system call, the zombie process is eliminated from the process table. This is known as</code> reaping the zombie process.</li> <li>It is because parent process may call wait () on child process for a longer time duration and child process got terminated much earlier.</li> <li>As entry in the process table can only be removed, after the parent process reads the exit status of child process. Hence, the child process remains a zombie till it is removed from the process table.</li> </ul> Practical on Zombie Process <ol> <li>Create a <code>zombie-script.sh</code> file and write the below code in it. <pre><code>#!/bin/bash\nfor i in {1..100}\ndo\n    sleep 1&amp;\ndone\nexec sleep 100\n</code></pre></li> <li>Run the script using <code>./zombie-script.sh</code> command. (<code>chmod +x zombie-script.sh</code> if permission denied)</li> <li>In another terminal, check for the zombie process using <code>ps -elf | grep Z</code> command. There should be 100 zombie processes each with same <code>PPID</code> as <code>zombie-script.sh</code> process.</li> </ol>"},{"location":"01-os/02-process-management/01-intro-to-process/03-swapping-context-switching-orphan-n-zombie-process/#limitations-of-process-table-in-os","title":"Limitations of <code>Process Table</code> in OS","text":"<ul> <li>Process table is a data structure maintained by the operating system to store information about the processes.</li> <li>Process table has a limited size, and it is not possible to keep all the processes in the memory all the time.</li> <li>Zombie processes could fill up the process table and prevent new processes from being created.</li> </ul> <p>Maximum number of process table entries</p> <ul> <li>Windows: Windows Operating System limits the number of process table entries to 65536.</li> <li>Linux: The maximum number of process table entries in Linux varies based on the distribution, architecture and kernel version. In general, it ranges from 32768 to 4194304.</li> </ul>"},{"location":"01-os/02-process-management/02-process-scheduling/01-introduction-to-process-scheduling/","title":"Introduction to Process Scheduling","text":""},{"location":"01-os/02-process-management/02-process-scheduling/01-introduction-to-process-scheduling/#process-scheduling","title":"Process Scheduling \ud83d\udd25","text":"<ul> <li>Basis of Multi-programming OS.</li> <li>By switching the CPU among processes, the OS can make the computer more productive.</li> <li>Many processes are kept in memory at a time, when a process must wait(I/O operations) or time quantum expires, the OS takes the CPU away from that process &amp; gives the CPU to another process &amp; this pattern continues.</li> </ul>"},{"location":"01-os/02-process-management/02-process-scheduling/01-introduction-to-process-scheduling/#terminologies","title":"Terminologies \ud83d\udcda","text":"<p>CPU Scheduler</p> <ul> <li>Whenever the CPU become ideal, OS must select one process from the ready queue to be executed.</li> <li>Done by STS (short-term scheduler).</li> </ul> <p>Non-Preemptive scheduling <code>(not emptied pre (before) - \u274c time quantum)</code></p> <ul> <li>Once CPU has been allocated to a process, the process keeps the CPU until it releases CPU either by terminating or by switching to wait-state (process is doing I/O).</li> <li><code>Starvation</code>, as a process with long burst time may starve less burst time process.</li> <li>Low CPU utilization.</li> </ul> <p>Preemptive scheduling <code>(emptied pre (before) - \u2705 time quantum)</code></p> <ul> <li>CPU is taken away from a process after time quantum expires along with terminating or switching to wait-state.</li> <li><code>Less Starvation</code></li> <li>High CPU utilization</li> </ul> <p>Terminologies associated with CPU scheduling</p> <ul> <li>Throughput: No. of processes completed per unit time.</li> <li>Arrival time (AT): Time when process is arrived at the ready queue.</li> <li>Burst time (BT): The time required by the process for its execution.</li> <li>Turn-around time (TAT): Time taken from first time process enters ready state till it terminates. (CT - AT)</li> <li>Wait time (WT): Time process spends waiting for CPU. (WT = TAT \u2013 BT)</li> <li>Response time: Time duration between process getting into ready queue and process getting CPU for the first time.</li> <li>Completion Time (CT): Time taken till process gets terminated.</li> </ul>"},{"location":"01-os/02-process-management/02-process-scheduling/01-introduction-to-process-scheduling/#goals-of-cpu-scheduling","title":"Goals of CPU scheduling \u26bd\ufe0f","text":"<ul> <li>Maximum CPU utilization</li> <li>Minimum Turnaround time (TAT).</li> <li>Min. Wait-time</li> <li>Min. response time.</li> <li>Max. throughput of system.</li> </ul>"},{"location":"01-os/02-process-management/02-process-scheduling/02-fcfs-n-convoy-effect/","title":"FCFS &amp; Convoy Effect","text":""},{"location":"01-os/02-process-management/02-process-scheduling/02-fcfs-n-convoy-effect/#fcfs-first-come-first-serve","title":"FCFS (First Come First Serve) \ud83c\udfc1","text":"<ul> <li>FCFS is simplest of CPU Scheduling Algorithm</li> <li>Executes process that comes first.</li> <li>It is non-preemptive algorithm.</li> </ul> <p>Definition</p> <p>Process that comes in ready queue first gets to be executed by the CPU first, then second one, then third one, and so on. The arrival time of processes is deciding factor here. Ready queue acts like FIFO (First In First Out) queue.</p>"},{"location":"01-os/02-process-management/02-process-scheduling/02-fcfs-n-convoy-effect/#convoy-effect","title":"Convoy Effect \ud83d\ude34","text":"<p>Convoy Effect</p> <ul> <li>Convoy effect is a situation where short processes are held up behind a long process.</li> <li>Shorter processes are made to wait for longer processes to complete.</li> <li>This is a problem in FCFS.</li> <li>The <code>average waiting time of different processes is very high</code>.</li> <li>Many process which require CPU for short time, are blocked by few processes which require CPU for long time.</li> </ul>"},{"location":"01-os/02-process-management/02-process-scheduling/03-sjf-priority-scheduling-round-robing/","title":"SJF, Priority Scheduling &amp; Round Robin","text":""},{"location":"01-os/02-process-management/02-process-scheduling/03-sjf-priority-scheduling-round-robing/#shortest-job-first-sjf-scheduling","title":"Shortest Job First (SJF) Scheduling","text":"Non-Preemptive SJF Scheduling <ul> <li>Process with least BT (burst time) will be dispatched to CPU first.</li> <li>Must do estimation for BT for each process in ready queue beforehand, Correct estimation of BT is an impossible task (ideally).</li> <li>Run lowest time process for all time then, choose job having lowest BT at that instance.</li> <li>This will suffer from convoy effect as if the very first process which came is Ready state is having a large BT.</li> <li>Process starvation might happen. (a shorter process might enter ready queue slightly later than a longer process, but it will wait for a long time before it gets CPU)</li> </ul> Preemptive SJF Scheduling <ul> <li>Less starvation.</li> <li>No convoy effect.</li> <li>Gives average WT less for a given set of processes as scheduling short job before a long one <code>decreases the waiting time of short jobs more than it increases the waiting time of long ones</code>.</li> </ul>"},{"location":"01-os/02-process-management/02-process-scheduling/03-sjf-priority-scheduling-round-robing/#priority-scheduling","title":"Priority Scheduling","text":"Non-Preemptive Priority Scheduling <ul> <li>Priority is assigned to a process when it is created.</li> <li>SJF is a special case of general priority scheduling with priority inversely proportional to BT.</li> </ul> Preemptive Priority Scheduling <ul> <li>Current running process can be preempted if a new process arrives with higher priority than the currently running process.</li> </ul> Problem with Priority Scheduling <ul> <li>Starvation: Low priority processes may never execute.</li> </ul> <p>Solution \ud83d\ude0e</p> <p>Aging (increase priority of process as it waits in the system).</p> <ul> <li>e.g., increase priority by 1 after every 15 seconds</li> </ul>"},{"location":"01-os/02-process-management/02-process-scheduling/03-sjf-priority-scheduling-round-robing/#round-robin-scheduling","title":"Round Robin Scheduling","text":"Info <ul> <li>Most popular</li> <li>Like FCFS, but preemption is added to switch between processes.</li> <li>Designed especially for time-sharing systems.</li> <li>Criteria: AT (arrival time) and TQ (time quantum).</li> </ul> <p>Advantages</p> <ul> <li>Fairness: All processes get equal share of CPU.</li> <li>No process starvation.</li> <li>No convoy effect.</li> </ul> <p>Disadvantages</p> <ul> <li>Too much context switching.</li> <li>If TQ is too large, it becomes FCFS.</li> <li>If TQ is too small, too much context switching, and increases overhead.</li> </ul>"},{"location":"01-os/02-process-management/02-process-scheduling/04-mlq-n-mlfq/","title":"MLQ &amp; MLFQ (Multi-Level Queue &amp; Multi-Level Feedback Queue)","text":""},{"location":"01-os/02-process-management/02-process-scheduling/04-mlq-n-mlfq/#multi-level-queue-scheduling-mlq","title":"Multi-level queue scheduling (MLQ)","text":"<ul> <li>Ready queue is divided into multiple queues depending upon priority.</li> <li>A process is permanently assigned to one of the queues (inflexible) based on some property of process, memory, size, process priority or process type.</li> <li>Each queue has its own scheduling algorithm. E.g., SP -&gt; RR, IP -&gt; RR &amp; BP -&gt; FCFS.<ul> <li>(SP: System process, IP: Interactive process, BP: Batch process)</li> <li>(RR: Round Robin, FCFS: First Come First Serve)</li> </ul> </li> </ul> more info <ul> <li>System process: Created by OS (Highest priority)</li> <li>Interactive process (Foreground process): Needs user input (I/O).</li> <li>Batch process (Background process): Runs silently, no user input required</li> </ul> <ul> <li>Scheduling among different sub-queues is implemented as fixed priority preemptive scheduling. E.g., foreground queue has absolute priority over background queue.</li> <li>If an interactive process comes &amp; batch process is currently executing. Then, batch process will be preempted.</li> </ul> <p>Problems with <code>multi-level queue scheduling</code>:</p> <ul> <li>Only after completion of all the processes from the top-level ready queue, the further level ready queues will be scheduled.</li> <li>Starvation for lower priority process.</li> <li>Convoy effect is present.</li> </ul>"},{"location":"01-os/02-process-management/02-process-scheduling/04-mlq-n-mlfq/#multi-level-feedback-queue-scheduling-mlfq","title":"Multi-level feedback queue scheduling (MLFQ) \ud83e\udd77\ud83c\udffb","text":"<ul> <li> <p>The one which is actually used in practice in most of the systems.</p> </li> <li> <p>Multiple sub-queues are present.</p> </li> </ul> <p>what's new?</p> <ul> <li>Process can move between queues.</li> <li>If a process uses too much CPU time, it will be moved to lower priority queue (to account for other processes).</li> <li>If a process uses too much I/O, it will be moved to higher priority queue. (so that user can interact with it, else he will feel like system is hanging).</li> <li>Aging is used to prevent starvation. (Aging: If a process waits too much in a lower-priority queue, it may be moved to a higher priority queue).</li> </ul> <p>Advantages of MLFQ:</p> <ul> <li>Less starvation then MLQ. (doesn't mean, it's completely free from starvation).</li> <li>It is flexible.</li> <li>Can be configured to match a specific system design requirement.</li> </ul> <p></p>"},{"location":"01-os/02-process-management/02-process-scheduling/05-comparison-between-process-scheduling-algos/","title":"Comparison between Process Scheduling Algorithms \ud83e\udd3c\u200d\u2642\ufe0f","text":"Design Preemption Convoy Effect Overhead <code>(context switching)</code> First come First Serve Simple No Yes No Shortest Job First Complex (how to find out <code>burst time</code>) No Yes No Pre-emptive Shortest Job First Complex Yes No Yes Priority Scheduling Complex (how to give suitable <code>priority</code>) No Yes No Pre-Emptive Priority Complex Yes Yes (low priority might never get CPU) Yes Round Robin Simple Yes No Yes Multi-level Queue Complex Yes Yes Yes Multi-level Feedback Queue Complex Yes Yes (though we try to reduce it using aging) Yes"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/01-intro-to-concurrency/","title":"Introduction to Concurrency \ud83d\ude0e","text":""},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/01-intro-to-concurrency/#concurrency","title":"Concurrency \ud83e\udd14","text":"<ul> <li>Concurrency is the execution of the multiple instruction sequences at the same time.</li> <li>It happens in the operating system when there are several process threads running in parallel.</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/01-intro-to-concurrency/#thread","title":"Thread","text":"<ul> <li>Single sequence stream within a process.</li> <li>An independent path of execution in a process.</li> <li>Light-weight process.</li> <li>Used to achieve parallelism by dividing a process\u2019s tasks which are independent path of execution.</li> <li>E.g., Multiple tabs in a browser, text editor (When you are typing in an editor, spell checking, formatting of text and saving the text are done concurrently by multiple threads.)</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/01-intro-to-concurrency/#thread-scheduling","title":"Thread Scheduling","text":"<ul> <li>Threads are scheduled for execution based on their priority.</li> <li>Even though threads are executing within the runtime, all threads are assigned processor time slices by the operating system.</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/01-intro-to-concurrency/#threads-context-switching","title":"Threads context switching","text":"<ul> <li>OS saves current state of thread &amp; switches to another thread of same process.</li> <li>Doesn\u2019t includes switching of memory address space. (But Program counter, registers &amp; stack are included.)</li> <li>Fast switching as compared to process switching</li> <li>CPU\u2019s cache state is preserved.</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/01-intro-to-concurrency/#how-each-thread-get-access-to-the-cpu","title":"How each thread get access to the CPU?","text":"<ul> <li>Each thread has its own program counter.</li> <li>Depending upon the thread scheduling algorithm, OS schedule these threads.</li> <li>OS will fetch instructions corresponding to PC of that thread and execute instruction.</li> <li>I/O or TQ, based context switching is done here as well<ul> <li>We have TCB (Thread control block) like PCB for state storage management while performing context switching.</li> </ul> </li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/01-intro-to-concurrency/#will-single-cpu-system-would-gain-by-multi-threading-technique","title":"Will single CPU system would gain by multi-threading technique?","text":"<ul> <li>Never.</li> <li>As two threads have to context switch for that single CPU.</li> <li>This won\u2019t give any gain.</li> <li>for the CPU intensive tasks, there won't be gain, but for i/o or network related tasks, we will definitely benefit from using multithreading.</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/01-intro-to-concurrency/#benefits-of-multi-threading","title":"Benefits of Multi-threading","text":"<ul> <li>Responsiveness</li> <li>Resource sharing: Efficient resource sharing.</li> <li>Economy: It is more economical to create and context switch threads.<ul> <li>Also, allocating memory and resources for process creation is costly, so better to divide tasks into threads of same process.</li> </ul> </li> <li>Threads allow utilization of multiprocessor architectures to a greater scale and efficiency.</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/01-intro-to-concurrency/#python-code-for-multi-threading","title":"Python Code for <code>Multi-threading</code>","text":"<pre><code>import time\nimport threading\n\n\ndef my_printer_t1():\n    for i in range(10):\n        print(f\"thread-1: {i=}\")\n        time.sleep(1)\n\ndef my_printer_t2():\n    for i in range(10):\n        print(f\"thread-2: {i=}\")\n        time.sleep(1)\n\nif __name__ ==\"__main__\":\n    # args for passing function arguments\n    t1 = threading.Thread(target=my_printer_t1, args=())\n    t2 = threading.Thread(target=my_printer_t2, args=())\n\n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n\n    print(\"Done!\")\n</code></pre>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/02-critical-section-n-race-condition/","title":"Critical section &amp; Race condition \ud83c\udfce\ufe0f","text":""},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/02-critical-section-n-race-condition/#critical-section","title":"Critical Section","text":"<p>The critical section refers to the segment of code where processes/threads access shared resources, such as common variables and files, and perform write operations on them.</p> <ul> <li>Since processes/threads execute concurrently, any process can be interrupted mid-execution.</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/02-critical-section-n-race-condition/#race-condition","title":"Race Condition","text":"<ul> <li>A race condition occurs when two or more threads can access shared data and they try to change it at the same time.</li> <li>Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data.</li> <li>Therefore, the result of the change in data is dependent on the thread scheduling algorithm, i.e., both threads are \"racing\" to access/change the data.</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/02-critical-section-n-race-condition/#solution-to-race-condition","title":"Solution to Race Condition","text":"<p>Solutions of Race condition</p> <ul> <li>Atomic operations: Make Critical code section an atomic operation, i.e., Executed in one CPU cycle.</li> <li>Mutual Exclusion using <code>locks</code>. (MutEX)</li> <li>Semaphores</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/02-critical-section-n-race-condition/#what-are-the-conditions-to-be-full-filled-to-be-a-solution-to-race-condition","title":"What are the conditions to be full-filled to be a solution to race condition?","text":"<p>Conditions required</p> <ol> <li>Mutual exclusion (<code>only one thread goes inside critical section at once</code>)</li> <li>Progress (<code>No thread should stop another thread from entering into critical section, if it's not in the critical section itself</code>).</li> <li>Bounded Waiting (<code>no indefinite waiting</code>)</li> </ol> <p>Though we typically don't bother much about <code>condition-3</code>, but <code>1 &amp; 2 condition</code> are must.</p>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/02-critical-section-n-race-condition/#can-we-use-a-simple-flag-variable-to-solve-the-problem-of-race-condition","title":"Can we use a simple flag variable to solve the problem of race condition?","text":"<ul> <li>No</li> </ul> Explanation <ul> <li>Let's say, we have a flag <code>turn</code>, and two threads are executing.</li> <li>For thread-1, it will be in <code>while loop until turn is not false (0)</code>; and for thread-2, it will be in <code>while loop until turn is not true (1)</code>.</li> <li>Once while loop breaks, it will go into critical section, and once done with critical section, it will modify the flag, so that other threads can enter in critical section.</li> <li>So, mutual exclusion is achieved.</li> <li>But, the problem is, which thread will execute first, depends on the initial value of <code>turn</code> flag. If it is false by default, thread-1 will execute first, and if thread-2 reaches first, it will still have to wait until thread-1 is done.</li> <li>So, second-condition of being a solution is not full-filled.</li> <li>That's why, <code>single flag can't be used as solution for critical section</code>. </li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/02-critical-section-n-race-condition/#petersons-solution","title":"Peterson\u2019s solution","text":"<ul> <li>Peterson's solution can be used to avoid race condition for only 2 processes/ threads.</li> </ul> Detailed description of Peterson's solution to avoid race condition <ul> <li>We create a bool <code>turn</code>, and a boolean array <code>flag</code> of size 2.</li> <li>flag denotes, if \\(i^{th}\\) thread/process can enter critical section or not.</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/02-critical-section-n-race-condition/#mutexlocks","title":"Mutex/Locks","text":"<ul> <li>Locks can be used to implement mutual exclusion and avoid race condition by allowing only one thread/process to access critical section.</li> </ul> <p>Disadvantages</p> <ul> <li>Contention: one thread has acquired the lock, other threads will be busy waiting, what if thread that had acquired the lock dies, then all other threads will be in infinite waiting.</li> <li>Deadlocks (<code>one process has locked one critical section, and another process has locked another critical section, and both are waiting for each other to release their part so that they can continue and complete</code>)</li> <li>Debugging (<code>it's tedious to debug mutex codes</code>)</li> <li>Starvation of high priority (<code>a low priority process might have locked critical section, and a high priority process will starve</code>)</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/03-conditional-variable-n-semaphore/","title":"Conditional variable &amp; Semaphores","text":""},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/03-conditional-variable-n-semaphore/#thread-synchronization-problem-with-current-approach","title":"Thread synchronization problem with current approach","text":"<p>So until of now, we have seen couple of approaches, like using flag boolean value, peterson's solution, and mutex.</p> <ul> <li>The biggest problem with mutex is of busy waiting. Until the lock is acquired, another thread has to be in a repetitive while loop of checking if the lock is free or not. So, it's basically wasting CPU clocks. These CPU clocks could have been used by a more meaningful app.</li> </ul> <p>Busy Waiting</p> <p>Busy waiting, also known as busy looping or spinning, is a process synchronization technique in computer science and software engineering where a process repeatedly checks if a condition is true before executing. For example, a process might check if a lock is available.</p> <p>To account for this, some new methods were introduced like:</p> <ul> <li>Conditional Variables</li> <li>Semaphores</li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/03-conditional-variable-n-semaphore/#conditional-variables","title":"Conditional Variables","text":"<ul> <li> <p>Condition variables are synchronization primitives that enable threads to wait until a particular condition occurs.</p> </li> <li> <p>There are two types of actions that can be performed with condition variables:</p> <ul> <li>wait</li> <li>signal</li> </ul> </li> <li> <p>We use the wait instruction in a thread if we want to halt the execution of that thread till a certain condition is met.</p> </li> <li> <p>We use the signal instruction if we want to continue executing the leading thread in the waiting queue.</p> </li> <li> <p>Contention is not here, as after critical section work is done, we will notify others, and they don't have to check every now-and-than and waste CPU cycles.</p> </li> </ul>"},{"location":"01-os/02-process-management/03-concurrency-n-deadlocks/03-conditional-variable-n-semaphore/#semaphores","title":"Semaphores","text":"<ul> <li>Suppose we have a printer that itself has 3 sub-printers, and hence it can print 3 documents at once, so it can execute 3 process at once.</li> <li>Semaphore is a synchronization method, in which we have a number which is equal to the number of resources.</li> <li>Multiple threads can go and execute <code>critical section</code> concurrently.</li> <li>Allows multiple program threads to access the finite instance of resources whereas mutex allows multiple threads to access a single shared resource one at a time.</li> </ul> <ul> <li>Binary semaphore: value can be 0 or 1.<ul> <li>Aka, mutex locks</li> </ul> </li> <li>Counting semaphore<ul> <li>Can range over an unrestricted domain.</li> <li>Can be used to control access to a given resource consisting of a finite number of instances.</li> </ul> </li> </ul> <p>Semaphore process</p> <p></p> <ul> <li> <p>To overcome the need for busy waiting, we can modify the definition of the wait () and signal () semaphore operations. When a process executes the wait () operation and finds that the semaphore value is not positive, it must wait. However, rather than engaging in busy waiting, the process car block itself. The block- operation places a process into a waiting queue associated with the semaphore, and the state of the process is switched to the Waiting state. Then control is transferred to the CPU scheduler, which selects another process to execute.</p> </li> <li> <p>A process that is blocked, waiting on a semaphore S, should be restarted when some other process executes a signal () operation. The process is restarted by a wakeup() operation, which changes the process from the waiting state to the ready state. The process is then placed in the ready queue.</p> </li> </ul>"},{"location":"02-dbms/","title":"DataBase Management System (DBMS) \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb","text":""},{"location":"02-dbms/#contents","title":"Contents","text":""},{"location":"02-dbms/01-introduction/01-dbms/","title":"Introduction to DBMS","text":""},{"location":"02-dbms/01-introduction/01-dbms/#what-is-data","title":"What is Data?","text":"<ul> <li>Data is a collection of raw, unorganized facts and details like text, observations, figures, symbols, and descriptions of things etc.</li> <li><code>data does not carry any specific purpose and has no significance by itself</code>.</li> </ul>"},{"location":"02-dbms/01-introduction/01-dbms/#what-is-information","title":"What is Information?","text":"<ul> <li>Information is processed, organized &amp; structured data.</li> <li>Provides <code>context of data</code> &amp; <code>helps in decision making</code>.</li> </ul>"},{"location":"02-dbms/01-introduction/01-dbms/#data-vs-information","title":"Data vs information","text":"<p>Info</p> <ul> <li>Data is collection of facts, while information puts those facts into context.</li> <li>Data on its own is meaningless. When it's analyzed and interpreted, it becomes meaningful information.</li> </ul>"},{"location":"02-dbms/01-introduction/01-dbms/#what-is-database","title":"What is <code>Database</code>?","text":"<ul> <li>Database is an electronic place/system where data is stored in a way that it can be easily accessed, managed &amp; updated.</li> </ul>"},{"location":"02-dbms/01-introduction/01-dbms/#what-is-dbms","title":"What is DBMS?","text":"<p>DBMS definition</p> <ul> <li> <p>A DBMS is the database itself, along with all the software and functionality, to provide a way to store and retrieve database information that is both convenient and efficient.</p> </li> <li> <p>It is used to perform different operations, like addition, access, updating, and deletion of the data.</p> </li> </ul>"},{"location":"02-dbms/01-introduction/01-dbms/#why-not-directly-use-file-system","title":"Why not directly use file-system?","text":"<p>file-system has major disadvantages</p> <ol> <li> <p>Data redundancy and consistency (same data can be present in multiple locations and they might even be not consistent. Data of same user can be different in different locations.)</p> </li> <li> <p>Difficulty in accessing data (file system is good for normal tasks, but it\u2019s not optimized for accessing data using complex queries.)</p> </li> <li> <p>Data isolation (unrelated data can be present in the same location)</p> </li> <li> <p>Integrity problems (A person with less than 18 years of age should not be able to register, holding such constraints is difficult to implement)</p> </li> <li> <p>Atomicity problems (for a batch of transactions, either the whole transaction should be successful or whole should fail, like, when user A sends money to user B, the two actions: addition of amount in B\u2019s balance and deduction of amount in A\u2019s balance, should either both be successful or both fail.)</p> </li> <li> <p>Concurrent-access anomalies (If credit card is being used by me and my wife, then concurrent access should be supported and expected issues should be taken care of.)</p> </li> <li> <p>Security problems (we want some data to be available to the developers but don\u2019t want whole data to be available to them).</p> </li> </ol> <ul> <li>It\u2019s not like, we can\u2019t implement above features in the file-system. We obviously can, but, it is a tedious task in itself, plus, we would be required to do it every time.</li> <li><code>DBMS has taken care of all these issues, so we can use them directly</code>.</li> </ul>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/","title":"Architecture of DBMS","text":"<ul> <li>The major purpose of DBMS is to provide users with an abstract view of the data. That is, the system hides certain details of how the data is stored and maintained.</li> <li>To simplify user interaction with the system, abstraction is applied through several levels of abstraction.</li> </ul>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#three-schema-architecture-view-of-data","title":"Three-Schema architecture (<code>View of data</code>)","text":"<ul> <li>The main objective of three level architecture is to enable multiple users to access the same data with a personalized view while storing the underlying data only once.</li> </ul>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#1-physical-level-internal-level","title":"1. Physical level/ Internal level","text":"<p>Physical level/ Internal level</p> <ul> <li>The lowest level of abstraction describes how the data are stored.</li> <li>Low-level data structures used.</li> <li>It has Physical schema which describes physical storage structure of DB.</li> <li>Talks about: Storage allocation (N-ary tree etc), Data compression &amp; encryption etc.</li> <li>Goal: We must define algorithms that allow efficient access to data.</li> </ul>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#2-logical-level-conceptual-level","title":"2. Logical level / Conceptual level \u2705","text":"<p>Logical level / Conceptual level</p> <ul> <li>The conceptual schema describes the design of a database at the conceptual level, describes what data are stored in DB, and what relationships exist among those data.</li> <li>User at logical level does not need to be aware about physical-level structures.</li> <li>DBA (<code>database administrator</code>), who must decide what information to keep in the DB use the logical level of abstraction.</li> <li>Goal: ease to use.</li> </ul>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#3-view-level-external-level","title":"3. View level / External level","text":"<p>View level / External level</p> <ul> <li>Highest level of abstraction aims to simplify users\u2019 interaction with the system by providing different view to different end-user.</li> <li>Each view schema describes the database part that a particular user group is interested and hides the remaining database from that user group.</li> <li>At the external level, a database contains several schemas that sometimes called as sub-schema. The sub-schema is used to describe the different view of the database.</li> <li>At views also provide a security mechanism to prevent users from accessing certain parts of DB.</li> </ul> <ul> <li> <p>a person working in amazon logistics, don't need to have access to user's credit card, but needs access to location.</p> </li> <li> <p>another engineer in payment department of amazon, don't need to have access to user's search history or carts.</p> </li> </ul> <p>So, for the same db, each user has different sub-schema for them.</p>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#instances-schema","title":"Instances &amp; Schema","text":"<ul> <li>The collection of information stored in the DB at a particular moment is called an <code>instance of DB</code>.</li> <li>The overall design of the DB is called the <code>DB schema</code>.</li> <li>Schema is structural description of data. Schema doesn\u2019t change frequently. Data may change frequently.</li> <li>We have 3 types of Schemas: <code>Physical</code>, <code>**Logical**</code>, <code>several view schemas</code> called sub-schemas.</li> </ul> <p>Tip</p> <ul> <li><code>Logical schema</code> is <code>most important</code> in terms of its effect on application programs, as programmers construct apps by using logical schema.</li> <li>Physical data independence, physical schema change should not affect logical schema/application programs.</li> </ul>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#data-models","title":"Data models","text":"<ul> <li>Provides a way to describe the design of a DB at logical level.</li> <li> <p>Underlying the structure of the DB is the Data Model; a collection of conceptual tools for <code>describing data</code>, <code>data relationships</code>, <code>data semantics</code> &amp; <code>consistency constraints</code>.</p> </li> <li> <p>E.g., <code>ER model</code>, <code>Relational Model</code>, <code>object-oriented model</code>, <code>object-relational data model</code>, etc.</p> </li> </ul>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#database-languages","title":"Database Languages","text":"<ul> <li>Data definition language (DDL) to specify the db schema. (like, constraints, which must be checked before each updation)</li> <li>Data manipulation language (DML) to express db queries &amp; updates.</li> </ul> <p>Practically, both languages are present in a single DB language, e.g., SQL language.</p>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#how-is-database-accessed-from-application-programs","title":"How is <code>database</code> accessed from application programs?","text":"<ul> <li> <p>Interface is provided in the host languages (like c, c++, java, etc), that convert normal statement into DML statements &amp; then send it to DB, and finally return the response.</p> <ul> <li>Open Database Connectivity (ODBC), Microsoft C</li> <li>Java Database Connectivity (JDBC), Java</li> </ul> </li> <li> <p>ORMs (<code>object-relation mapper</code>): ORM is a computer technique that maps the schema of a relational database to the classes of an object-oriented programming language.</p> <ul> <li>SQLAlchemy</li> <li>Mongoose</li> <li>Prisma</li> </ul> </li> </ul>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#dba-database-administrator","title":"DBA (<code>Database administrator</code>)","text":"<ul> <li>A person who has central control of both the data &amp; the programs that access those data.</li> </ul> Functions of DBA <ul> <li>Schema definition</li> <li>storage structure &amp; access methods</li> <li>schema &amp; physical organization modifications</li> <li>Authorization control</li> <li>routine maintenance:<ul> <li>periodic backups</li> <li>security patches</li> <li>any upgrades</li> </ul> </li> </ul>"},{"location":"02-dbms/01-introduction/02-architecture-of-dbms/#dbms-application-architecture","title":"DBMS application architecture","text":"<p>Depending on the relative location of client &amp; server and how do they communicate, we have three types of <code>DBMS Application architecture</code>.</p> <ol> <li>Tier-1 architecture: The client, server &amp; DB all present on the same machine.</li> <li>Tier-2 architecture: DB is in some remote server, and client connects directly to DB and communicates.</li> <li>Tier-3 architecture: The client communicates with <code>app server</code>, that in turn communicates with <code>DB server</code>.</li> </ol> <p>Comparison</p> <p>Obviously, tier-3 is the most scalable &amp; safe for WWW applications.</p>"},{"location":"02-dbms/02-entity-relationship-model/01-er-model/","title":"Entity-Relationship Model","text":""},{"location":"02-dbms/03-relational-model/01-relational-model/","title":"Relational Model (RDBMS)","text":""},{"location":"02-dbms/04-sql/01-introduction/","title":"SQL (<code>structured query language</code>)","text":""},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/","title":"Normalization","text":"<p>What is Normalization?</p> <ul> <li>Normalization divides the larger table into smaller and links them using relationships.</li> </ul> <ul> <li> <p>Normalization is the process of organizing the data in the database.</p> </li> <li> <p>Normalization is used to minimize the redundancy from a relation or set of relations. It is also used to eliminate undesirable characteristics like Insertion, Update, and Deletion Anomalies.</p> </li> <li> <p>The normal form is used to reduce redundancy from the database table.</p> </li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#functional-dependency-fd","title":"Functional Dependency (<code>FD</code>)","text":"<ul> <li> <p>relationship between the primary key attribute (usually) of the relation to that of the other attribute of the relation.</p> </li> <li> <p><code>X =&gt; Y</code>, the left side of FD is known as a <code>Determinant</code>, the right side of the production is known as a <code>Dependent</code>.</p> </li> <li>If we can determine Y from X in a table, we say FD exists between <code>X =&gt; Y</code>.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#types-of-fd","title":"Types of FD \ud83d\udc83","text":""},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#1-trivial-fd","title":"1. Trivial FD","text":"<ul> <li><code>A =&gt; B</code> has trivial functional dependency if <code>B is a subset of A</code>. <code>A-&gt;A</code>, <code>B-&gt;B</code> are also Trivial FD.</li> </ul> Example <p>A table with primary key <code>{student_id, student_name}</code> will have trivial functional dependency with <code>{student_name}</code>, as it is already subset.</p>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#2-non-trivial-fd","title":"2. Non-trivial FD","text":"<ul> <li><code>A =&gt; B</code> has non-trivial functional dependency if <code>B is not a subset of A</code>. [A intersection B is NULL.]</li> </ul> Example <p>A table with primary key <code>{student_id}</code> will have trivial functional dependency with <code>{student_name}</code>, as it is not a subset.</p>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#rules-of-fd-armstrongs-axioms","title":"Rules of FD (<code>Armstrong\u2019s axioms</code>) \ud83c\udf09","text":""},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#1-reflexive","title":"1. Reflexive","text":"<ul> <li> <p>If <code>\u2018A\u2019 is a set of attributes</code> and <code>\u2018B\u2019 is a subset of \u2018A\u2019</code>. Then, <code>A =&gt; B</code> holds.</p> </li> <li> <p>If A \\(\\supseteq\\) B then <code>A =&gt; B</code>.</p> </li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#2-augmentation","title":"2. Augmentation","text":"<ul> <li>If B can be determined from A, then adding an attribute to this functional dependency won't change anything.</li> <li>If <code>A=&gt;B</code> holds, then <code>AX=&gt;BX</code> holds too, 'X' being a set of attributes.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#3-transitivity","title":"3. Transitivity","text":"<ul> <li>If <code>A determines B</code>, and <code>B determines C</code>, then, <code>A determines C</code>.</li> <li>If <code>A=&gt;B</code> &amp; <code>B=&gt;C</code>, then, <code>A=&gt;C</code>.</li> </ul> Example <ul> <li> <p>Reflexive</p> <ul> <li>If <code>{student_id, student_name}</code> is primary key, and <code>{student_name}</code> is an attribute, then, there exists reflexive FD.</li> </ul> </li> <li> <p>Augmentation</p> <ul> <li>If we can determine <code>{student_age}</code> from primary key <code>{student_id}</code>, i.e., functional dependency exists between the two, then, FD also exists between <code>{student_id, student_name}</code> &amp; <code>{student_age, student_name}</code>.</li> </ul> </li> <li> <p>Transitivity</p> <ul> <li>If <code>{student_id}</code> can determine <code>{student_email}</code>, and <code>{student_email}</code> can help us uniquely identify <code>{student_age}</code>, then, we can determine <code>{student_age}</code> from <code>{student_id}</code>, i.e., FD exists between the two.</li> </ul> </li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#why-normalization","title":"Why Normalization?","text":"<ul> <li>To avoid redundancy in the DB, not to store redundant data.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#what-happens-if-we-have-redundant-data","title":"What happens if we have redundant data?","text":"<p>Problems with redundant data</p> <ul> <li>Insertion, deletion &amp; updation anomalies arises.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#anomalies","title":"Anomalies","text":"<ul> <li> <p>Anomalies means <code>abnormalities</code>.</p> </li> <li> <p>Let's suppose, we have a table that stores college student details along with the branch they are in and their HOD.</p> </li> </ul> Student_id Name email branch HOD 101 Max max[at]gmail.com Mechanical Prof Andrew NG 102 William william[at]gmail.com CSE Prof Yan lecun 103 Rohit rohit[at]gmail.com Electronics Prof Zuckerberg 104 Virat virat[at]gmail.com Civil Prof Brock Lesnar 105 Dhoni dhoni[at]gmail.com Electrical Prof Mia Khalifa"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#insertion-anomaly","title":"Insertion Anomaly","text":"<ul> <li>When certain data (attribute) cannot be inserted into the DB without the presence of other data.</li> <li>Now, if the college started <code>AI/ML</code> branch too, there's no way to have this information in the table until there's some student in the branch.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#deletion-anomaly","title":"Deletion Anomaly","text":"<ul> <li>Deletion anomaly refers to the situation where the deletion of data results in the unintended loss of some other important data.</li> <li>If <code>Rohit</code> from the above table graduates and leaves college, the whole row will be dropped, and we will also lose the information that <code>Electronics</code> course is available in the college.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#updation-anomaly","title":"Updation anomaly","text":"<ul> <li>The update anomaly is when an update of a single data value requires multiple rows of data to be updated.</li> <li>Due to updation to many places, data inconsistency may arise, if one forgets to update the data at all the intended places.</li> <li>In the table, if the HOD of CSE is changed, we will be required to update all the rows which has CSE branch as its branch. (<code>multiple updation</code>)</li> </ul> <ul> <li>Due to these anomalies, DB size increases, and DB performance slows down.</li> <li>To rectify these anomalies, we use <code>Normalization</code>.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#what-is-normalization","title":"What is Normalization?","text":"<ul> <li>Normalization is used to minimize the redundancy from a relations.</li> <li>It is also used to eliminate undesirable characteristics like Insertion, Update, and Deletion Anomalies.</li> <li>Normalization divides the composite attributes into individual attributes OR larger table into smaller and links them using relationships.</li> <li>The normal form is used to reduce redundancy from the database table.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#types-of-normal-forms","title":"Types of <code>Normal forms</code>","text":""},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#1nf-first-normal-form","title":"1NF (<code>First Normal Form</code>)","text":"<ul> <li>It states that an attribute of a table cannot hold multiple values. </li> <li>It must hold only single-valued attribute.</li> <li>First normal form disallows the multi-valued attribute, composite attribute, and their combinations.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#2nf-second-normal-form","title":"2NF (<code>Second Normal Form</code>)","text":"<ul> <li>Relation must be in <code>1NF</code>.</li> <li>There should be no partial dependency.<ul> <li>All non-prime attributes must be fully dependent on PK.</li> <li>Non prime attribute can not depend on the part of the PK (or proper subset of PK).</li> </ul> </li> </ul> explanation <p>Primary key: <code>{course_no, stud_no}</code>. But, attribute <code>{course_fee}</code> can be described completely by <code>{course_no}</code>, which is a subset of primary key, hence, to make it <code>Second normal form</code>, we split it into two tables.</p>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#3nf-third-normal-form","title":"3NF (<code>Third Normal Form</code>)","text":"<ul> <li>Relation must be in <code>2NF</code>.</li> <li>No transitivity dependency exists:<ul> <li>Non-prime attribute should not find a non-prime attribute.</li> </ul> </li> </ul> explanation <p><code>{emp_id}</code> can determine <code>{rate_group}</code>, and <code>{rate_group}</code> can determine <code>{hourly_rate}</code>.</p> <ul> <li> <p>So, transitive dependency exists, i.e., <code>{emp_id}</code> can determine <code>{hourly_rate}</code>.</p> </li> <li> <p>To remove this, we split into two tables.</p> </li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#bcnf-boyce-codd-normal-form","title":"BCNF (<code>Boyce-Codd normal form</code>)","text":"<ul> <li>Relation must be in 3NF.</li> <li> <p>FD: A -&gt; B, A must be a super key.</p> <ul> <li>We must not derive prime attribute from any prime or non-prime attribute.</li> </ul> </li> <li> <p>For BCNF, the table should be in 3NF, and for every FD, <code>LHS is super key</code>.</p> </li> </ul> <p></p> <ul> <li> <p>The <code>table is not in BCNF because neither EMP_DEPT nor EMP_ID alone are keys</code>.</p> </li> <li> <p>To convert the given table into BCNF, we decompose it into three tables:</p> </li> </ul> <p></p> <ul> <li>functional dependencies</li> </ul> <p></p> <p>Success</p> <p>After BCNF, most of the redundancy has been removed.</p>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#4nf-fourth-normal-form","title":"4NF (<code>Fourth normal form</code>)","text":"<ul> <li>A relation will be in 4NF if it is in Boyce Codd normal form and has no multi-valued dependency.</li> <li>For a dependency A \u2192 B, if for a single value of A, multiple values of B exists, then the relation will be a multi-valued dependency.</li> </ul> <ul> <li>Split into two tables.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#5nf-fifth-normal-form","title":"5NF (<code>Fifth normal form</code>)","text":"<ul> <li>it is in 4NF</li> <li>from 1NF to 4NF, it was all about splitting into multiple tables.</li> <li>5<sup>th</sup> NF is about joining multiple tables, and the joining should be lossless.</li> <li>Multiple tables can be joined in any order and the final table should not contain any less or any more entries, i.e., <code>lossless joining</code>.</li> <li> <p>5NF is also known as Project-join normal form (PJ/NF).</p> </li> <li> <p>A relation is in 5NF, if it is in 4NF, and not having any join dependency and joining should be lossless.</p> </li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#summary","title":"Summary","text":""},{"location":"02-dbms/05-normalization-acid-and-indexing/01-normalization/#advantages-of-normalization","title":"Advantages of Normalization","text":"<p>Success</p> <ul> <li>Normalization helps to minimize data redundancy.</li> <li>Greater overall database organization.</li> <li>Data consistency is maintained in DB.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/02-acid-properties-and-transactions/","title":"ACID properties &amp; Transactions","text":""},{"location":"02-dbms/05-normalization-acid-and-indexing/02-acid-properties-and-transactions/#transactions","title":"Transactions","text":"<ul> <li>A unit of work done against the DB in a logical sequence.</li> <li>Sequence is very important in transaction.</li> <li>It is a logical unit of work that contains one or more SQL statements.</li> <li>The result of all these statements in a transaction either gets completed successfully (all the changes made to the database are permanent) or if at any point any failure happens it gets roll-backed (all the changes being done are undone).</li> </ul> <p>Example</p> <p>For example, let's suppose we're sending some amount X from user A to user B. The sequence of steps are:</p> <ul> <li>Read balance from A.</li> <li>If balance is greater than or equal to X, subtract X from the balance and store it in buffer.</li> <li>Write the updated balance in DB for user A.</li> <li>Read balance from B.</li> <li>Add X to B's balance in buffer.</li> <li>Write the buffer in DB for user B.</li> </ul> <p>The above 6 sequences altogether comprise a single transaction.</p>"},{"location":"02-dbms/05-normalization-acid-and-indexing/02-acid-properties-and-transactions/#acid-properties-atomic-consistent-isolation-durable","title":"ACID Properties (<code>Atomic</code>, <code>Consistent</code>, <code>Isolation</code>, <code>Durable</code>)","text":""},{"location":"02-dbms/05-normalization-acid-and-indexing/02-acid-properties-and-transactions/#atomicity","title":"Atomicity","text":"<ul> <li>Either all operations of transaction are reflected properly in the DB, or none are.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/02-acid-properties-and-transactions/#consistency","title":"Consistency","text":"<ul> <li>Integrity constraints must be maintained before and after transaction. (example, <code>balance can't be negative</code>)</li> <li>DB must be consistent after transaction happens.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/02-acid-properties-and-transactions/#isolation","title":"Isolation","text":"<ul> <li>Even though multiple transactions may execute concurrently, the system guarantees that, for every pair of transactions Ti and Tj, it appears to Ti that either Tj finished execution before Ti started, or Tj started execution after Ti finished. Thus, each transaction is unaware of other transactions executing concurrently in the system.</li> <li>Multiple transactions can happen in the system in isolation, without interfering each other.</li> <li>Multiple transactions can occur simultaneously, if they aren't interfering with each other, else, they will be executed one after other.</li> </ul> Explanation on Isolation <ul> <li>Let's say A has $1000 in his account and he transfers $50 to B. At the same time, from another device, A transfer B $50.</li> <li>If Both transactions occur simultaneously, both transactions will read $1000 to be A's balance, and the updated balance in both case will be $950.</li> <li>To tackle this, isolation is used.</li> <li>Until one transaction completes, other won't even start.</li> <li>This prevents unintended reads &amp; writes.</li> <li>It will use some sort of lock mechanism.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/02-acid-properties-and-transactions/#durability","title":"Durability","text":"<ul> <li>After transaction completes successfully, the changes it has made to the database persists, even if there are system failures.</li> </ul> Explanation on Durability <ul> <li>Suppose we have read balance from user A, subtracted X from A's balance, write the transaction, then, read B's balance, and added X to it. And, finally, write the updated balanced into the buffer. And, it will indicate a Successful transaction.</li> <li>But, most of the time, we don't directly write to the DB. We store the updated write to be performed in the memory buffer. We do this because, it is typically a time-consuming process to go from execution mode to I/O mode. Hence, we typically store in the buffer, and from time to time, we flush it and commit to the disk (DB).</li> <li>But, what if, when we responded the user with success, but we were yet to write to disk and the system crashed?</li> <li>When we will restart system, memory would have been freed and flushed, so we lost the transaction, and hence the durability has been lost.</li> <li>To achieve durability, DBMS have recovery management component, whose job is to write the successful transactions to the DB which have previously been marked to be successful.</li> <li>For this, they generally emit logs, and when the system restarts, it tries to match with the log and check if the DB is at latest update, else, it writes missing transactions. Hence, Durability is achieved.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/02-acid-properties-and-transactions/#transaction-states","title":"Transaction states","text":"<ul> <li>Active state</li> </ul> <ul> <li>The very first state of the life cycle of the transaction, all the read and write operations are being performed. If they execute without any error the T comes to Partially committed state. Although if any error occurs then it leads to a Failed state.</li> </ul> <ul> <li>Partially committed state</li> </ul> <ul> <li>After transaction is executed the changes are saved in the buffer in the main memory. If the changes made are permanent on the DB then the state will transfer to the committed state and if there is any failure, the T will go to Failed state.</li> </ul> <ul> <li>Committed state</li> </ul> <ul> <li>When updates are made permanent on the DB. Then the T is said to be in the committed state. Rollback can\u2019t be done from the committed states. New consistent state is achieved at this stage.</li> </ul> <ul> <li>Failed state</li> </ul> <ul> <li>When T is being executed and some failure occurs. Due to this it is impossible to continue the execution of the T.</li> </ul> <ul> <li>Aborted state</li> </ul> <ul> <li>When T reaches the failed state, all the changes made in the buffer are reversed. After that the T rollback completely. T reaches abort state after rollback. DB\u2019s state prior to the T is achieved.</li> </ul> <ul> <li>Terminated state</li> </ul> <ul> <li>A transaction is said to have terminated if has either committed or aborted.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/03-how-to-implement-atomicity-and-durability/","title":"How to implement <code>Atomicity</code> &amp; <code>Durability</code> in transactions?","text":"<ul> <li>Recovery Mechanism Component of DBMS supports atomicity and durability.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/03-how-to-implement-atomicity-and-durability/#shadow-copy-scheme","title":"Shadow-Copy Scheme","text":"<p>Shadow-Copy scheme</p> <ol> <li>Based on making copies of DB (aka, shadow copies).</li> <li>Assumption only one Transaction (T) is active at a time.</li> <li>A pointer called db-pointer is maintained on the disk; which <code>at any instant points to current copy of DB</code>.</li> <li>T, that wants to update DB <code>first creates a complete copy of DB</code>.</li> <li><code>All further updates are done on new DB copy leaving the original copy (shadow copy) untouched</code>.</li> <li><code>If at any point the T has to be aborted the system deletes the new copy. And the old copy is not affected</code>.</li> <li>If T success, it is committed as,<ul> <li>OS makes sure all the pages of the new copy of DB written on the disk.</li> <li>DB system updates the db-pointer to point to the new copy of DB.</li> <li>New copy is now the current copy of DB.</li> <li>The old copy is deleted.</li> <li>The T is said to have been COMMITTED at the point where the updated db-pointer is written to disk.</li> </ul> </li> </ol> <p>Atomicity</p> <ul> <li>If T fails at any time before db-pointer is updated, the old content of DB is not updated.</li> <li>T abort can be done by just deleting the new copy of DB.</li> <li>Hence, either all updates are reflected or none.</li> </ul> <p>Durability</p> <ul> <li>Suppose system fails at any time before the db-pointer is written to the disk.</li> <li>When the system restarts, it will read db-pointer &amp; will see the original contents of the DB, and none of the effects of T will be visible.</li> <li>T is assumed to be successful only when db-pointer is updated.</li> <li>If system fails after db-pointer has been updated. Before that, all the pages of the new copy were written to the disk. Hence, when system restarts, it will read new DB copy.</li> </ul> <p>A very important note about writing Disk updates</p> <p>The implementation is dependent on write to the db-operation being atomic.</p> <ul> <li>Luckily, disk system provides atomic updates to entire block or at least a disk sector. So, we make sure db-pointer lies entirely in a single sector. By storing db-pointer at the beginning of a block.</li> </ul> <p>Problem with <code>Shadow-Copy Scheme</code></p> <ul> <li>This approach is very inefficient, as we are storing the copy of the whole db in memory for each transaction.</li> <li>Will we read 1 tb DB size each time??</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/03-how-to-implement-atomicity-and-durability/#log-based-recovery-method","title":"Log-Based recovery method","text":"<ul> <li>log is a sequence of records.</li> <li><code>Log of each transaction is maintained in some stable storage so that if any failure occurs, then it can be recovered from there</code>.</li> <li>If any operation is performed on the database, then it will be recorded in the log.</li> <li>But the process of storing the logs should be done before the actual transaction is applied in the database.</li> <li>Stable storage is a classification of computer data storage technology that guarantees atomicity for any given write operation and allows software to be written that is robust against some hardware and power failures.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/03-how-to-implement-atomicity-and-durability/#deferred-db-modifications","title":"Deferred DB Modifications","text":"<ul> <li>Ensuring atomicity by recording all the DB modifications in the log but deferring the execution of all the write operations until the final action of the T has been executed.</li> <li>Log information is used to execute deferred writes when T is completed.</li> <li>If system crashed before the T completes, or if T is aborted, the information in the logs are ignored.</li> <li>If T completes, the records associated to it in the log file are used in executing the deferred writes.</li> <li>If failure occur while this updating is taking place, we preform redo.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/03-how-to-implement-atomicity-and-durability/#immediate-db-modifications","title":"Immediate DB Modifications","text":"<ol> <li>DB modifications to be output to the DB while the T is still in active state.</li> <li>DB modifications written by active T are called uncommitted modifications.</li> <li>In the event of crash or T failure, system uses old value field of the log records to restore modified values.</li> <li>Update takes place only after log records in a stable storage.</li> <li>Failure handling<ol> <li>System failure before T completes, or if T aborted, then old value field is used to undo the T.</li> <li>If T completes and system crashes, then new value field is used to redo T having commit logs in the logs.</li> </ol> </li> </ol>"},{"location":"02-dbms/05-normalization-acid-and-indexing/03-how-to-implement-atomicity-and-durability/#difference-between-the-two-deferred-vs-immediate","title":"Difference between the two (<code>Deferred Vs Immediate</code>)","text":"<ul> <li>Deferred logs what it will do, and but the updates to DB are not done immediately, but rather stored in buffer. Once the whole process is over, it will go one by one over the logs, and actually execute. If before the update were committed, system crashed, means, nothing could be updated in DB. In that case, it will restart executing the logs.</li> </ul> <ul> <li>Immediate logs will log what it will do, then does that, and proceeds like this. If the system crashes before the execution could finish or commit, when the system will restart, it will backtrack the logs and undo the operations. In case it logged committed, but before committing, system crashed, it will redo the operations based on logs.</li> </ul> <ul> <li>Deferred only read the current state, whereas Immediate logs also store the previous and new value (helpful in case of backtrack (rollup)).</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/03-how-to-implement-atomicity-and-durability/#checkpoint","title":"Checkpoint","text":"<ul> <li> <p>The checkpoint is a type of mechanism where all the previous logs are removed from the system and permanently stored in the storage disk.</p> </li> <li> <p>The checkpoint is like a bookmark. While the execution of the transaction, such checkpoints are marked, and the transaction is executed then using the steps of the transaction, the log files will be created.</p> </li> <li> <p>When it reaches to the checkpoint, then the transaction will be updated into the database, and till that point, the entire log file will be removed from the file. Then the log file is updated with the new step of transaction till next checkpoint and so on.</p> </li> <li> <p>The checkpoint is used to declare a point before which the DBMS was in the consistent state, and all transactions were committed.</p> </li> </ul> <p>Recovery using checkpoint</p> <p></p> <ul> <li>The recovery system reads log files from the end to start. It reads log files from T4 to T1.</li> <li>Recovery system maintains two lists, a redo-list, and an undo-list.</li> <li>The transaction is put into redo state if the recovery system sees a log with  and  or just . In the redo-list and their previous list, all the transactions are removed and then redone before saving their logs. <li>For example: In the log file, transaction T2 and T3 will have  and . The T1 transaction will have only  in the log file. That's why the transaction is committed after the checkpoint is crossed. Hence it puts T1, T2 and T3 transaction into redo list. <li>The transaction is put into undo state if the recovery system sees a log with  but no commit or abort log found. In the undo-list, all the transactions are undone, and their logs are removed. <li>For example: Transaction T4 will have . So T4 will be put into undo list since this transaction is not yet complete and failed amid."},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/","title":"Indexing in DBMS","text":""},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#what-is-indexing-in-dbms","title":"What is Indexing in DBMS?","text":"<p>Indexing is a technique for improving database performance by reducing the number of disk accesses necessary when a query is run. An index is a form of data structure. It\u2019s used to swiftly identify and access data and information present in a database table.</p>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#structure-of-index","title":"Structure of Index","text":"<ul> <li>We can create indices using some columns of the database.</li> </ul> <ul> <li> <p>The search key is the database\u2019s first column, and it contains a duplicate or copy of the table\u2019s candidate key or primary key. The primary key values are saved in sorted order so that the related data can be quickly accessible.</p> </li> <li> <p>The data reference is the database\u2019s second column. It contains a group of pointers that point to the disk block where the value of a specific key can be found.</p> </li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#method-of-indexing","title":"Method of Indexing","text":""},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#ordered-indices","title":"Ordered Indices","text":"<p>To make searching easier and faster, the indices are frequently arranged/sorted. Ordered indices are indices that have been sorted.</p> <p>Example</p> <p>Let\u2019s say we have a table of employees with thousands of records, each of which is ten bytes large. If their IDs begin with 1, 2, 3,\u2026, etc., and we are looking for the student with ID-543:</p> <ul> <li>We must search the disk block from the beginning till it reaches 543 in the case of a DB without an index. After reading 543*10=5430 bytes, the DBMS will read the record.</li> <li>We will perform the search using indices in the case of an index, and the DBMS would read the record after it reads 542*2 = 1084 bytes, which is significantly less than the prior example.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#primary-index","title":"Primary Index","text":"<ul> <li>Primary indexing refers to the process of creating an index based on the table\u2019s primary key. These primary keys are specific to each record and establish a 1:1 relationship between them.</li> <li>The searching operation is fairly efficient because primary keys are stored in sorted order.</li> <li>There are two types of primary indexes: dense indexes and sparse indexes.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#dense-index","title":"Dense Index","text":"<p>Every search key value in the data file has an index record in the dense index. It speeds up the search process. The total number of records present in the index table and the main table are the same in this case. It requires extra space to hold the index record. A pointer to the actual record on the disk and the search key are both included in the index records.</p>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#sparse-index","title":"Sparse Index","text":"<p>Only a few items in the data file have index records. Each and every item points to a certain block. Rather than pointing to each item in the main database, the index, in this case, points to the records that are present in the main table that is in a gap.</p>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#clustering-index","title":"Clustering Index","text":"<ul> <li>An ordered data file can be defined as a clustered index. Non-primary key columns, which may or may not be unique for each record, are sometimes used to build indices.</li> <li>In this situation, we\u2019ll join two or more columns to acquire the unique value and generate an index out of them to make it easier to find the record. A clustering index is a name for this method.</li> <li>Records with comparable properties are grouped together, and indices for these groups are constructed.</li> </ul> <p>Example</p> <p>Assume that each department in a corporation has numerous employees. Assume we utilise a clustering index, in which all employees with the same Dept_ID are grouped together into a single cluster, and index pointers refer to the cluster as a whole. Dept_Id is a non-unique key in this case.</p> <p></p> <p>Because one disk block is shared by records from various clusters, the previous structure is a little unclear. It is referred to as a better strategy when we employ distinct disk blocks for separate clusters.</p> <p></p>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#secondary-index","title":"Secondary Index","text":"<p>When using sparse indexing, the size of the mapping grows in sync with the size of the table. These mappings are frequently stored in primary memory to speed up address fetching. The secondary memory then searches the actual data using the address obtained through mapping. Fetching the address becomes slower as the mapping size increases. The sparse index will be ineffective in this scenario, so secondary indexing is used to solve this problem.</p> <p></p> <p>Another level of indexing is introduced in secondary indexing to reduce the size of the mapping. The massive range for the columns is chosen first in this method, resulting in a small mapping size at the first level. Each range is then subdivided into smaller groups. Because the first level\u2019s mapping is kept in primary memory, fetching the addresses is faster. The second-level mapping, as well as the actual data, are kept in secondary memory (or hard disk).</p> <p>Example</p> <ul> <li>In case we want to find the record for roll 111 in the diagram, it will look for the highest item in the first level index that is equal to or smaller than 111. At this point, it will get a score of 100.</li> <li>Then it does max (111) &lt;= 111 in the second index level and obtains 110. Using address 110, it now navigates to the data block and begins searching through each record until it finds 111.</li> <li>In this method, a search is carried out in this manner. In the same way, you can insert, update, or delete data.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#advantages-of-indexing","title":"Advantages of Indexing","text":"<ul> <li>Faster access and retrieval of data.</li> <li>IO is less.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#limitations-of-indexing","title":"Limitations of Indexing","text":"<ul> <li>Additional space to store index table</li> <li>Indexing Decrease performance in INSERT, DELETE, and UPDATE query.</li> </ul>"},{"location":"02-dbms/05-normalization-acid-and-indexing/04-indexing-in-dbms/#faqs-on-indexing-in-dbms","title":"FAQs on Indexing in DBMS","text":"Q1. What is Indexing in DBMS? <p>Indexing refers to a data structure technique that is used for quickly retrieving entries from database files using some attributes that have been indexed. In database systems, indexing is comparable to indexing in books. The indexing attributes are used to define the indexing.</p> Q2. Is indexing similar to hashing? <p>Hashing uses mathematical methods called hash functions to generate direct locations of data records on the disc, whereas indexing uses data references that contain the address of the disc block with the value corresponding to the key. As a result, there is a significant difference between hashing and indexing.</p> Q3. What are the types of Indexing in DBMS? <p>Indexing in DBMS is of the following types:</p> <ul> <li>Ordered Index</li> <li>Primary Index</li> <li>Clustering Index</li> <li>Sparsing Index</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/01-nosql-db/","title":"NoSQL (<code>not only SQL</code>)","text":"<p>NoSQL databases (aka \"not only SQL\") are non-tabular databases and store data differently than relational tables. NoSQL databases come in a variety of types based on their data model. The main types are document, key-value, wide-column, and graph. They provide flexible schemas and scale easily with large amounts of data and high user loads.</p> <ol> <li>They are schema free.</li> <li>Data structures used are not tabular, they are more flexible, has the ability to adjust dynamically.</li> <li>Can handle huge amount of data (big data).</li> <li>Most of the NoSQL are open sources and has the capability of horizontal scaling.</li> <li>It just stores data in some format other than relational.</li> </ol>"},{"location":"02-dbms/06-nosql-and-db-types/01-nosql-db/#history-of-nosql","title":"History of NoSQL","text":"<p>History of NoSQL</p> <ul> <li>In 2000s, hardware was really expensive, so to store data in DB, we were required to minimize space and store them effectively. This lead to development of least redundancy and normalization concepts.</li> <li>Over time, hardware prices dropped and now space is not a big concern, but serving customer without latency is the real challenge.</li> <li>To tackle this, new kind of DBs emerged with the intention to minimize the latency and maximize scalability, be it at the cost of data redundancy.</li> <li>These DBs were NoSQL (<code>No only SQL</code>).</li> <li>Cloud computing also rose in popularity, and developers began using public clouds to host their applications and data. They wanted the ability to distribute data across multiple servers and regions to make their applications resilient, to scale out out instead of scale up, and to intelligently geo-place their data. Some NoSQL databases like MongoDB provide these capabilities.</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/01-nosql-db/#nosql-db-advantages","title":"NoSQL DB advantages","text":"<ul> <li>Flexible Schema</li> <li>Horizontal scaling (<code>scale out</code>).<ul> <li>This is difficult with relational databases due to the difficulty in spreading out related data across nodes. With non-relational databases, this is made simpler since collections are self-contained and not coupled relationally. This allows them to be distributed across nodes more simply, as queries do not have to \u201cjoin\u201d them together across nodes.</li> </ul> </li> <li>Scaling horizontally is achieved through Sharding OR Replica-sets.</li> <li>High availability</li> <li>Easy insert and read operations<ul> <li>Queries in NoSQL databases can be faster than SQL databases. Why? Data in SQL databases is typically normalized, so queries for a single object or entity require you to join data from multiple tables. As your tables grow in size, the joins can become expensive. However, data in NoSQL databases is typically stored in a way that is optimized for queries.</li> <li>The rule of thumb when you use MongoDB is data that is accessed together should be stored together. Queries typically do not require joins, so the queries are very fast.</li> <li>But difficult delete or update operations.</li> </ul> </li> <li>Caching mechanism</li> <li>NoSQL use case is more for cloud application</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/01-nosql-db/#when-to-use-nosql","title":"When to use NoSQL?","text":"<ol> <li>Fast-paced Agile development</li> <li>Storage of structured and semi-structured data</li> <li>Huge volumes of data</li> <li>Requirements for scale-out architecture</li> <li>Modern application paradigms like micro-services and real-time streaming.</li> </ol>"},{"location":"02-dbms/06-nosql-and-db-types/01-nosql-db/#nosql-db-misconceptions","title":"NoSQL DB Misconceptions","text":"Relationship data is best suited for relational databases! <p>A common misconception is that NoSQL databases or non-relational databases don\u2019t store relationship data well. NoSQL databases can store relationship data \u2014 they just store it differently than relational databases do.</p> <ul> <li>In fact, when compared with relational databases, many find modelling relationship data in NoSQL databases to be easier than in relational databases, because related data doesn\u2019t have to be split between tables. NoSQL data models allow related data to be nested within a single data structure.</li> </ul> NoSQL databases don't support ACID transactions <p>Another common misconception is that NoSQL databases don't support ACID transactions.</p> <ul> <li>Some NoSQL databases like MongoDB do, in fact, support ACID transactions.</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/01-nosql-db/#types-of-nosql-data-models","title":"Types of NoSQL data models","text":"<ul> <li>Key-Value store</li> </ul> <ul> <li>use cases: <code>user preferences</code>, and <code>user profiles</code>.</li> <li>e.g., Oracle NoSQL, Amazon DynamoDB, MongoDB also supports Key-Value store, Redis.</li> </ul> <ul> <li>Column-Oriented / Columnar / C-Store / Wide-Column</li> </ul> <ul> <li>The data is stored such that each row of a column will be next to other rows from that same column.</li> <li>While a relational database stores data in rows and reads data row by row, a column store is organized as a set of columns.</li> <li>This means that when you want to run analytics on a small number of columns, you can read those columns directly without consuming memory with the unwanted data.</li> <li>Columns are often of the same type and benefit from more efficient compression, making reads even faster.</li> <li>Columnar databases can quickly aggregate the value of a given column (adding up the total sales for the year, for example).</li> <li>Use cases include analytics.</li> <li>e.g., Cassandra, RedShift, Snowflake.</li> </ul> <ul> <li>Document based store</li> </ul> <ul> <li>store data in documents similar to JSON</li> <li>Use cases include e-commerce platforms, trading platforms, and mobile app development across industries.</li> <li><code>Supports ACID</code> properties hence, suitable for Transactions.</li> <li>e.g., MongoDB, CouchDB.</li> </ul> <ul> <li>Graph based models</li> </ul> <ul> <li>A graph database focuses on the relationship between data elements. Each element is stored as a node (such as a person in a social media graph). The connections between elements are called links or relationships. In a graph database, connections are first-class elements of the database, stored directly. In relational databases, links are implied, using data to express the relationships.</li> <li>A graph database is optimized to capture and search the connections between data elements, overcoming the overhead associated with JOINing multiple tables in SQL.</li> <li>Very few real-world business systems can survive solely on graph queries. As a result graph databases are usually run alongside other more traditional databases.</li> <li>Use cases include fraud detection, social networks, and knowledge graphs.</li> <li>e.g., Neo4J</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/01-nosql-db/#nosql-db-disadvantages","title":"NoSQL DB Disadvantages \u26a0\ufe0f","text":"<ol> <li>Data Redundancy</li> <li>Since data models in NoSQL databases are typically <code>optimized for queries and not for reducing data duplication</code>, NoSQL databases can be larger than SQL databases. Storage is currently so cheap that most consider this a minor drawback and some NoSQL databases also support compression to reduce the storage footprint.</li> <li>Update &amp; Delete operations are costly.</li> <li>All type of NoSQL Data model doesn\u2019t fulfil all of your application needs</li> <li>Depending on the NoSQL database type you select, you may not be able to achieve all of your use cases in a single database. For example, graph databases are excellent for analyzing relationships in your data but may not provide what you need for everyday retrieval of the data such as range queries. When selecting a NoSQL database, consider what your use cases will be and if a general purpose database like MongoDB would be a better option.</li> <li>Doesn\u2019t support ACID properties in general (<code>mongodb exception</code>).</li> <li>Doesn\u2019t support data entry with consistency constraints. But, is eventually consistent.</li> </ol>"},{"location":"02-dbms/06-nosql-and-db-types/01-nosql-db/#sql-vs-nosql","title":"SQL Vs NoSQL","text":"<p>ACID compliant in MongoDB</p> <ul> <li>Most NoSQL aren't ACID compliant, but MongoDB is acid compliant.</li> </ul> <pre><code>s.start_transaction()\n    orders.insert_one(order, session=s)\n    stock.update_one(item, stockUpdate, session=s)\ns.commit_transaction()\n</code></pre> <ul> <li>SQL examples: MySQL, PostgreSQL, etc.</li> <li>NoSQL examples: MongoDB, CouchDB, DynamoDB, Redis, Cassandra, etc.</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/02-db-types/","title":"Types of Database","text":""},{"location":"02-dbms/06-nosql-and-db-types/02-db-types/#relational-databases","title":"Relational Databases","text":"<ol> <li>Based on Relational Model.</li> <li>Relational databases are quite popular, even though it was a system designed in the 1970s. Also known as relational database management systems (RDBMS), relational databases commonly use Structured Query Language (SQL) for operations such as creating, reading, updating, and deleting data. Relational databases store information in discrete tables, which can be JOINed together by fields known as foreign keys. For example, you might have a User table which contains information about all your users, and join it to a Purchases table, which contains information about all the purchases they\u2019ve made.</li> <li><code>MySQL</code>, <code>Microsoft SQL Server</code>, and <code>Oracle</code> are types of relational databases.</li> <li>they are ubiquitous, having acquired a steady user base since the 1970s</li> <li>they are highly optimized for working with structured data.</li> <li>they provide a stronger guarantee of data normalization</li> <li>they use a well-known querying language through SQL</li> <li>Scalability issues (Horizontal Scaling).</li> <li>Data become huge, system become more complex.</li> </ol>"},{"location":"02-dbms/06-nosql-and-db-types/02-db-types/#object-oriented-databases","title":"Object Oriented Databases","text":"<ol> <li>The object-oriented data model, is based on the object-oriented-programming paradigm, which is now in wide use. Inheritance, object-identity, and encapsulation (information hiding), with methods to provide an interface to objects, are among the key concepts of object-oriented programming that have found applications in data modelling. The object-oriented data model also supports a rich type system, including structured and collection types. While inheritance and, to some extent, complex types are also present in the E-R model, encapsulation and object-identity distinguish the object-oriented data model from the E-R model.</li> <li>Sometimes the database can be very complex, having multiple relations. So, maintaining a relationship between them can be tedious at times.<ul> <li>In Object-oriented databases data is treated as an object.</li> <li>All bits of information come in one instantly available object package instead of multiple tables.</li> </ul> </li> </ol> <p>Advantages</p> <ul> <li>Data storage and retrieval is easy and quick.</li> <li>Can handle complex data relations and more variety of data types that standard relational databases.</li> <li>Relatively friendly to model the advance real world problems</li> <li>Works with functionality of OOPs and Object Oriented languages.</li> </ul> <p>Disadvantages</p> <ul> <li>High complexity causes performance issues like read, write, update and delete operations are slowed down.</li> <li>Not much of a community support as isn\u2019t widely adopted as relational databases.</li> <li>Does not support views like relational databases.</li> <li>e.g., <code>ObjectDB</code>, <code>GemStone</code> etc.</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/02-db-types/#nosql-databases","title":"NoSQL Databases","text":"<ol> <li>NoSQL databases (aka \"not only SQL\") are non-tabular databases and store data differently than relational tables. NoSQL databases come in a variety of types based on their data model. The main types are document, key-value, wide-column, and graph. They provide flexible schemas and scale easily with large amounts of data and high user loads.</li> <li>They are schema free.</li> <li>Data structures used are not tabular, they are more flexible, has the ability to adjust dynamically.</li> <li>Can handle huge amount of data (big data).</li> <li>Most of the NoSQL are open sources and has the capability of horizontal scaling.</li> <li>It just stores data in some format other than relational.</li> </ol>"},{"location":"02-dbms/06-nosql-and-db-types/02-db-types/#hierarchical-databases","title":"Hierarchical Databases","text":"<ul> <li>As the name suggests, the hierarchical database model is most appropriate for use cases in which the main focus of information gathering is based on a concrete hierarchy, such as several individual employees reporting to a single department at a company.</li> <li>The schema for hierarchical databases is defined by its tree-like organization, in which there is typically a root \u201cparent\u201d directory of data stored as records that links to various other subdirectory branches, and each subdirectory branch, or child record, may link to various other subdirectory branches.</li> <li>The hierarchical database structure dictates that, while a parent record can have several child records, each child record can only have one parent record. Data within records is stored in the form of fields, and each field can only contain one value. Retrieving hierarchical data from a hierarchical database architecture requires traversing the entire tree, starting at the root node.</li> <li>Since the disk storage system is also inherently a hierarchical structure, these models can also be used as physical models.</li> <li>The key advantage of a hierarchical database is its ease of use. The one-to-many organization of data makes traversing the database simple and fast, which is ideal for use cases such as website drop-down menus or computer folders in systems like Microsoft Windows OS. Due to the separation of the tables from physical storage structures, information can easily be added or deleted without affecting the entirety of the database. And most major programming languages offer functionality for reading tree structure databases.</li> <li>The major disadvantage of hierarchical databases is their inflexible nature. The one-to-many structure is not ideal for complex structures as it cannot describe relationships in which each child node has multiple parents nodes. Also the tree-like organization of data requires top-to-bottom sequential searching, which is time consuming, and requires repetitive storage of data in multiple different entities, which can be redundant.</li> <li>e.g., IBM IMS.</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/02-db-types/#network-databases","title":"Network Databases","text":"<ul> <li>Extension of Hierarchical databases</li> <li>The child records are given the freedom to associate with multiple parent records.</li> <li>Organized in a Graph structure.</li> <li>Can handle complex relations.</li> <li>Maintenance is tedious.</li> <li>M:N links may cause slow retrieval.</li> <li>Not much web community support.</li> <li>e.g., Integrated Data Store (IDS), IDMS (Integrated Database Management System), Raima Database Manager, TurboIMAGE etc.</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/03-acid-vs-base/","title":"ACID vs BASE","text":"<ul> <li><code>ACID</code>: Atomicity, Consistency, Isolation, Durability</li> <li><code>BASE</code>: Basically available, soft-state &amp; eventually consistent</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/03-acid-vs-base/#base-compliant-dbs","title":"BASE compliant DBs","text":"<ul> <li>Basically Available: The system guarantees availability according to the CAP theorem, but without strict guarantees on immediate consistency.</li> <li>Soft state: The state of the system may change over time, even without input (due to eventual consistency).</li> <li>Eventual consistency: The system will become consistent over time, given that no new updates are made. It is not immediately consistent. Changes will be reflected over time (obviously withing acceptable range).</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/03-acid-vs-base/#acid-base","title":"ACID &amp; BASE","text":"<ul> <li>Most RDBMS (or SQL DBs) are ACID compliant.</li> <li>Whereas, NoSQL (not only SQL) are BASE compliant. (though, <code>MongoDB is acid compliant</code> too)</li> </ul>"},{"location":"02-dbms/06-nosql-and-db-types/03-acid-vs-base/#difference-bw-the-two","title":"Difference b/w the two","text":""},{"location":"02-dbms/06-nosql-and-db-types/03-acid-vs-base/#when-to-use-which-one","title":"When to use which one?","text":"<p>ACID V/S BASE compliant DBs</p> <ul> <li>For financial &amp; banking systems, where atomicity, consistency and durability is more preferred over availability, ACID compliant DBs should be preferred.</li> </ul> <ul> <li>For social media apps, where availability matters over slight delay in the updated value (<code>comments on a post being reflected after some seconds</code>), BASE compliant DBs should be preferred.</li> </ul>"},{"location":"02-dbms/07-scaling-database/01-clustering-and-replica-set-in-db/","title":"Clustering (<code>Replication set</code>)","text":"<ul> <li>CDN (CONTENT DELIVERY NETWORK)</li> </ul>"},{"location":"02-dbms/07-scaling-database/01-clustering-and-replica-set-in-db/#clustering","title":"Clustering","text":"<ul> <li>Database <code>Clustering</code> is the process of combining more than one servers or instances connecting a single database.</li> <li>Sometimes one server may not be adequate to manage the amount of data or the number of requests, that is when a Data Cluster is needed.</li> </ul>"},{"location":"02-dbms/07-scaling-database/01-clustering-and-replica-set-in-db/#replica-set","title":"Replica Set","text":"<ul> <li>Replicate the same dataset on different servers.</li> <li>We will perform write operation on one server, and over time propagate updates to other servers.</li> <li>Other servers will be used for read operations.</li> <li>Increases availability and fault tolerance in case one of the server goes down.</li> </ul> <p>Clustering &amp; Replica set</p> <p>Though both are different concepts, but are used interchangeably.</p>"},{"location":"02-dbms/07-scaling-database/01-clustering-and-replica-set-in-db/#advantages-of-replica-set-clustering","title":"Advantages of <code>Replica Set</code>/ <code>Clustering</code>","text":"<ul> <li>Data redundancy: in case one of the server goes down, data is still available on other servers.</li> <li>Load balancing: direct traffic to servers with least users and balance loads.</li> <li>High availability</li> </ul>"},{"location":"02-dbms/07-scaling-database/01-clustering-and-replica-set-in-db/#content-delivery-network-cdn","title":"Content Delivery Network (<code>CDN</code>)","text":"<ul> <li>CDN work on the principle of replica set.</li> <li>Has a local copy of the static data in the edge servers and can reduce server call or be available when server is down.</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/","title":"Partitioning &amp; Sharding","text":"<ul> <li>A big problem can be solved easily when it is chopped into several smaller sub-problems. That is what the partitioning technique does.</li> <li>It divides a big database containing data metrics and indexes into smaller and handy slices of data called partitions.</li> <li>The partitioned tables are directly used by SQL queries without any alteration.</li> <li>Once the database is partitioned, the data definition language can easily work on the smaller partitioned slices, instead of handling the giant database altogether.</li> <li>This is how partitioning cuts down the problems in managing large database tables.</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#partitioning","title":"Partitioning","text":"<ul> <li>technique used to divide stored database objects into separate servers.</li> <li>Due to this, there is an increase in performance, controllability of the data.</li> <li>We can manage huge chunks of data optimally. </li> </ul> <p>Relational V/s NOSQL DB on partitioning</p> <ul> <li>When we horizontally scale our machines/servers, we know that it gives us a challenging time dealing with relational databases as it\u2019s quite tough to maintain the relations.</li> <li>For performing joins, we will be required to fetch data from multiple servers and then perform join, which will be time-consuming.</li> <li>If instead, we used NOSQL DB, data that will be required together will be stored together. Also, we don't care much about normalization in NOSQL, which eventually leads to better performance and availability.</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#vertical-partitioning","title":"Vertical Partitioning","text":"<ul> <li>Slicing relation vertically / column-wise.</li> <li>Need to access different servers to get complete tuples.</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#horizontal-partitioning","title":"Horizontal Partitioning","text":"<ul> <li>Slicing relation horizontally / row-wise.</li> <li>Independent chunks of data tuples are stored in different servers.</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#when-partitioning-is-applied","title":"When Partitioning is Applied?","text":"<ul> <li>Dataset become much huge that managing and dealing with it become a tedious task.</li> <li>the number of requests are enough larger that the single DB server is taking huge time and hence the system's response time become high.</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#advantages-of-partitioning","title":"Advantages of Partitioning","text":"<ul> <li>Parallelism</li> <li>Availability</li> <li>Performance</li> <li>Manageability</li> <li>Reduce cost as scaling up (vertical scaling) might be costly.</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#scaling-up-vs-scaling-out","title":"Scaling Up Vs Scaling Out","text":"<ul> <li>Scaling up =&gt; Vertical scaling (adding more resources (ram, cpu, etc.))</li> <li>Scaling out =&gt; horizontal scaling (adding more servers)</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#distributed-database","title":"Distributed database","text":"<ul> <li>A single logical database that is spread across multiple locations (servers) and logically interconnected by network.</li> <li>This is the product of applying DB optimization techniques like, <code>Clustering</code>, <code>Partitioning</code> &amp; <code>Sharding</code>.</li> </ul> <p>Why is it needed?</p> <ul> <li>Dataset become much huge that managing and dealing with it become a tedious task.</li> <li>the number of requests are enough larger that the single DB server is taking huge time and hence the system's response time become high.</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#sharding","title":"Sharding","text":"<ul> <li>Technique to implement Horizontal scaling</li> <li>The idea is that, <code>instead of having all the data be present on one DB instance, we split it up and introduce a routing layer so that we can forward the request to the right instances that actually contain the data</code>.</li> </ul> <ul> <li>Let's say we split our DB into two DB, one will contains data of users from India, and other from USA.</li> <li>Now, on our backend server, we will be required to implement a routing layer, that will query the required DB based on the country of the user.</li> <li>This is <code>Sharding</code>.</li> </ul>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#pros","title":"Pros","text":"<ol> <li>Scalability</li> <li>Availability</li> </ol>"},{"location":"02-dbms/07-scaling-database/02-partitioning-and-sharding/#cons","title":"Cons","text":"<ol> <li> <p>Complexity, making partition mapping, Routing layer to be implemented in the system, Non-uniformity that creates the necessity of Re-Sharding</p> </li> <li> <p>Not well suited for Analytical type of queries, as the data is spread across different DB instances. (Scatter-Gather problem)</p> </li> </ol>"},{"location":"02-dbms/07-scaling-database/03-db-scaling-pattern/","title":"Database Scaling Patterns","text":"<ul> <li>step by step manner, when to choose which scaling option</li> </ul>"},{"location":"02-dbms/07-scaling-database/03-db-scaling-pattern/#case-study","title":"Case Study","text":""},{"location":"02-dbms/07-scaling-database/03-db-scaling-pattern/#pattern-1","title":"Pattern 1","text":""},{"location":"02-dbms/07-scaling-database/03-db-scaling-pattern/#pattern-2","title":"Pattern 2","text":""},{"location":"02-dbms/07-scaling-database/03-db-scaling-pattern/#pattern-3","title":"Pattern 3","text":""},{"location":"02-dbms/07-scaling-database/03-db-scaling-pattern/#pattern-4","title":"Pattern 4","text":""},{"location":"02-dbms/07-scaling-database/03-db-scaling-pattern/#pattern-5","title":"Pattern 5","text":""},{"location":"02-dbms/07-scaling-database/03-db-scaling-pattern/#pattern-6","title":"Pattern 6","text":""},{"location":"02-dbms/07-scaling-database/03-db-scaling-pattern/#pattern-7","title":"Pattern 7","text":""},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/01-cap-theorem/","title":"CAP theorem (<code>Brewer's theorem</code>)","text":"<ul> <li>Basic and one of the most important concept in Distributed Databases.</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/01-cap-theorem/#cap-consistency-availability-partition-tolerance","title":"CAP (<code>Consistency</code>, <code>Availability</code>, <code>Partition-tolerance</code>)","text":"<ul> <li>Let's suppose we have two nodes, on one we will perform write operation, and from other node we will perform read operation.</li> </ul> <p>Consistency</p> <ul> <li> <p>In a consistent system, all nodes see the same data simultaneously.</p> </li> <li> <p>If we perform a read operation on a consistent system, it should return the value of the most recent write operation.</p> </li> <li> <p>The read should cause all nodes to return the same data.</p> </li> <li> <p>All users see the same data at the same time, regardless of the node they connect to.</p> </li> <li> <p>When data is written to a single node, it is then replicated across the other nodes in the system.</p> </li> </ul> <p>Availability</p> <ul> <li>When availability is present in a distributed system, it means that the system remains operational all of the time.</li> <li>Every request will get a response regardless of the individual state of the nodes.</li> <li>This means that the system will operate even if there are multiple nodes down.</li> <li>Unlike a consistent system, there\u2019s <code>no guarantee that the response will be the most recent write operation, but we will get response</code>.</li> </ul> <p>Partition-tolerance</p> <ul> <li>What is partition?</li> <li>In a distributed DB system, multiple nodes are connected. If the linkage between two nodes breaks, we say a partition has taken place.</li> </ul> <ul> <li>When a system is partition-tolerance, the system does not fail, regardless of whether messages are dropped or delayed between nodes within the system.</li> <li>To have partition tolerance, the system must replicate records across combinations of nodes and networks.</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/01-cap-theorem/#what-is-cap-theorem","title":"What is <code>CAP theorem</code>?","text":"<p>The CAP theorem states that a distributed system can only provide <code>two of three properties</code> simultaneously: consistency, availability, and partition tolerance.</p> <ul> <li>The theorem formalizes the tradeoff between consistency and availability when there\u2019s a partition.</li> </ul> Explanation <ul> <li>Suppose we have two distributed DBs, and we perform write on one node, and read from another node.</li> <li>Let's say, partition happen and the linkage between the two nodes is broken. Now, if the system is partition-tolerance (means if the system is still working), then we can only have either <code>consistency</code> or <code>availability</code>.</li> <li>If we choose to go with availability, user will perform write operation on one node, and when it will read from another node, it will read stale data (not the most updated data, since, linkage is broken). So, the system is available, but is not consistent.</li> <li>In case, we decide to go ahead with consistency, then, we will have to turn off the reading node, as we can't update another node, since linkage is broken, and so, the one running db has the latest values, but the system is not available (in case writing DB goes down, there's nothing for availability).</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/01-cap-theorem/#different-databases-bcoz-of-cap-theorem","title":"Different databases bcoz of CAP theorem","text":"<ul> <li>NoSQL databases are great for distributed networks. They allow for horizontal scaling, and they can quickly scale across multiple nodes. When deciding which NoSQL database to use, it\u2019s important to keep the CAP theorem in mind.</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/01-cap-theorem/#ca-databases","title":"CA databases","text":"<ul> <li>CA databases enable consistency and availability across all nodes.</li> <li>Unfortunately, CA databases can\u2019t deliver fault tolerance.</li> <li>In any distributed system, partitions are bound to happen, which means this type of database isn\u2019t a very practical choice.</li> <li>That being said, you still can find a CA database if you need one. Some relational databases, such as MySQL or PostgreSQL, allow for consistency and availability. You can deploy them to nodes using replication, sharding, etc.</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/01-cap-theorem/#cp-databases","title":"CP databases","text":"<ul> <li>CP databases enable <code>consistency</code> and <code>partition tolerance</code>, but not availability.</li> <li>When a partition occurs, the system has to turn off inconsistent nodes until the partition can be fixed.</li> <li>MongoDB is an example of a CP database. It\u2019s commonly used in big data and applications running in different locations.</li> <li>The CP system is structured so that there\u2019s only one primary node that receives all of the write requests in a given replica set.</li> <li>Secondary nodes replicate the data in the primary nodes, so if the primary node fails, a secondary node can stand-in.</li> <li>In banking system Availability is not as important as consistency, so we can opt it (MongoDB).</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/01-cap-theorem/#ap-databases","title":"AP databases","text":"<ul> <li>AP databases enable <code>availability</code> and <code>partition tolerance</code>, but not consistency.</li> <li>In the event of a partition, all nodes are available, but they\u2019re not all updated.</li> <li>For example, if a user tries to access data from a bad node, they won\u2019t receive the most up-to-date version of the data.</li> <li>When the partition is eventually resolved, most AP databases will sync the nodes to ensure consistency across them.</li> <li>Apache Cassandra is an example of an AP database. It\u2019s a NoSQL database with no primary node, meaning that all of the nodes remain available.</li> <li>Cassandra allows for eventual consistency because users can re-sync their data right after a partition is resolved.</li> <li>For apps like Facebook, we value availability more than consistency, we\u2019d opt for AP Databases like Cassandra or Amazon DynamoDB.</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/01-cap-theorem/#so-rdbms-is-not-used-at-all-in-large-scale-systems","title":"So, RDBMS is not used at all in large-scale systems?","text":"<ul> <li> <p>Obviously, this is false statement. They are very old and mature DBs and been in the industry for years.</p> </li> <li> <p>Despite the CAP theorem's constraints, MySQL and PostgreSQL are indeed used at a very large scale in the real world. Here are some strategies employed:</p> </li> </ul> <p>Hybrid Approaches</p> <p>Read replicas: Using read replicas to handle high read traffic, while the primary node handles writes. This can improve availability and distribute the load but might introduce eventual consistency for reads. Multi-master replication: Allows writes on multiple nodes but comes with complex conflict resolution mechanisms to maintain consistency.</p> <p>Use Cases</p> <ul> <li> <p>Financial Systems: Often use CP configurations with strong consistency guarantees, such as synchronous replication. For example, a payment processing system might use PostgreSQL with synchronous replication to ensure that all transactions are consistent.</p> </li> <li> <p>Web Applications: Often use AP configurations with asynchronous replication to ensure high availability. For example, a social media platform might use MySQL with asynchronous replication and read replicas to handle high traffic volumes.</p> </li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/01-cap-theorem/#acid-vs-base-db-systems","title":"ACID v/s BASE DB systems","text":"<ul> <li>Banking applications typically require ACID compliant databases.</li> <li>Social media applications typically require BASE compliant databases.</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/02-master-slave-architecture/","title":"Master-Slave architecture","text":"<ul> <li>We have one master node, to which we perform write operation.</li> <li>Master node is connected with multiple slave nodes.</li> <li>If the system prefers consistency, then it will first update the master node, then perform update on slave nodes, and then mark the transaction as successful.</li> <li>Else, if the availability matters more, then it will defer the updation for some time.</li> </ul> <ul> <li>Its a Pattern 3 in Database Scaling Pattern. (Command Query Responsibility Segregation)</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/02-master-slave-architecture/#what-if-a-update-request-comes-at-a-slave-node","title":"What if a update request comes at a slave node?","text":"<ul> <li>Simply ignore the request.</li> <li>If we are updating the db, then we need some way to propagate the updation to master node.</li> <li>But, this architecture won't be called Master-slave architecture.</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/02-master-slave-architecture/#tip-in-master-slave-architecture","title":"Tip in Master-Slave Architecture","text":"<p><code>Write-&gt;Master</code>, <code>Read=&gt;Slave</code></p> <ul> <li>Perform write operation to Master node.</li> <li>Perform read operation on Slave node.</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/02-master-slave-architecture/#advantages","title":"Advantages","text":"<ul> <li>BackUP (even if master node goes down, we can still read data)</li> <li>Scale out read operations, reduces latency</li> <li>availability</li> <li>reliable</li> <li>parallelly execute multiple incoming requests (since, multiple read nodes)</li> </ul>"},{"location":"02-dbms/08-cap-theorem-and-master-slave-architecture/02-master-slave-architecture/#different-dbs-for-master-slave-node","title":"Different DBs for master &amp; slave node","text":"<ul> <li>We can also use different DBs for master &amp; slave node.</li> <li>But, in this case, we will also have to write interface.</li> </ul>"},{"location":"04-dsa/","title":"Data Structures &amp; algorithm","text":""},{"location":"04-dsa/#contents","title":"Contents","text":"<ol> <li>Graph</li> <li>Dynamic Programming</li> </ol>"},{"location":"04-dsa/00-basic/01-sorting/01-introduction/","title":"Sorting","text":""},{"location":"04-dsa/00-basic/02-binary-search/01-introduction/","title":"Binary Search","text":""},{"location":"04-dsa/00-basic/03-bit-manipulation/01-introduction/","title":"Bit Manipulation","text":""},{"location":"04-dsa/00-basic/04-recursion-and-backtracking/01-introduction/","title":"Recursion &amp; Backtracking","text":""},{"location":"04-dsa/01-graph/","title":"Graph","text":""},{"location":"04-dsa/01-graph/#contents","title":"Contents","text":"<ol> <li> <p>Introduction, BFS &amp; DFS:</p> <ul> <li>Basic Concepts &amp; representation</li> <li>Disconnected components</li> <li>Breadth-first-search (BFS)</li> <li>Depth-first-search (DFS)</li> <li>Bipartite Graph</li> </ul> </li> <li> <p>Cycle detection &amp; topo sort:</p> <ul> <li>Cycle detection in Undirected (BFS &amp; DFS)</li> <li>Cycle detection in Directed (DFS)</li> <li>Topological sort (DFS)</li> <li>Topological sort (Kahn's algorithm)</li> <li>Cycle detection in Directed (BFS)</li> </ul> </li> <li> <p>Shortest path in Graph:</p> <ul> <li>Undirected Graph</li> <li>Directed acyclic graph (DAG)</li> <li>Dijkstra's algorithm</li> <li>Bellman-Ford algorithm</li> <li>Floyd Warshall algorithm</li> </ul> </li> <li> <p>Minimum spanning tree:</p> <ul> <li>Minimum spanning tree</li> <li>Prim's algorithm</li> <li>Disjoint set union (by Rank &amp; size)</li> <li>Kruskal's algorithm</li> </ul> </li> <li> <p>Important graph algorithms:</p> <ul> <li>SCC- Kosaraju's algorithm</li> <li>Bridges in graph</li> <li>Articulation point in Graph</li> </ul> </li> </ol>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/01-introduction/","title":"Basic Graph concepts &amp; Graph representation","text":""},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/01-introduction/#terminologies","title":"Terminologies","text":""},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/01-introduction/#types-of-graph","title":"Types of Graph","text":""},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/01-introduction/#graph-representation","title":"Graph representation","text":""},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/01-introduction/#1-adjacency-matrix","title":"1. Adjacency Matrix","text":"<ul> <li>A matrix of (n X n) nodes, where value at <code>mat[i][j]</code> represents if the connection between the two nodes exists or not.</li> <li>If it is weighted graph &amp; <code>mat[i][j]</code> is non-zero, it <code>represents the weight of the corresponding edge</code>.</li> </ul>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/01-introduction/#2-adjacency-list","title":"2. Adjacency List","text":"<ul> <li>An adjacency list is a 2d-array <code>vector&lt;int&gt; adjList[n]</code>. An array of n vectors. Each vector will represent the connected nodes.</li> <li>For weighted graph, it can be <code>vector&lt;pair&lt;int,int&gt;&gt; adjList[n]</code>. 1<sup>st</sup> item can represent the node, and 2<sup>nd</sup> item can represent the weight associated with edge.</li> </ul>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/01-introduction/#code-for-graph-representation","title":"Code for graph representation","text":"How the input will be passed? <p>You will be given three integers n, m and p (a boolean integer), representing <code>no. of nodes</code>, <code>no. of edges</code> and <code>if the graph is directed (p=1) or undirected (p=0)</code>, respectively.</p> <p>Following that, you will be given m lines as input, and each line will have two numbers, x &amp; y, representing an edge exists between x and y.</p> <p>All the nodes are using 0-based indexing.</p> <pre><code>3 2 1   // 3 nodes, 2 edges &amp; directed\n1 2     // 1 is connected to 2 (but 2 not connected with 1)\n2 0     // 2 is connected to 0\n</code></pre>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/01-introduction/#1-adjacency-matrix-code","title":"1. Adjacency Matrix code","text":"<p>Code</p> C++Python <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\nusing namespace std;\n\nint main()\n{\n    int n, m, p;\n    cin &gt;&gt; n &gt;&gt; m &gt;&gt; p;\n\n    // create a 2d matrix of size\n    vector&lt;vector&lt;int&gt;&gt; adj_matrix(n, vector&lt;int&gt;(n));\n\n    while (m--)\n    {\n        int x, y;\n        cin &gt;&gt; x &gt;&gt; y;\n\n        // an edge exists between x &amp; y\n        // if it were a weighted graph, we would have used weight instead of 1\n        adj_matrix[x][y] = 1;\n\n        // if undirected, an edge exists between y &amp; x\n        if (p == 0)\n            adj_matrix[y][x] = 1;\n    }\n\n    // print the adjacency matrix\n    for (int i = 0; i &lt; n; i++)\n    {\n        for (int j = 0; j &lt; n; j++)\n        {\n            cout &lt;&lt; adj_matrix[i][j] &lt;&lt; \" \";\n        }\n        cout &lt;&lt; endl;\n    }\n}\n</code></pre> <pre><code>print(\"Hello World\")\n</code></pre>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/01-introduction/#2-adjacency-list-code","title":"2. Adjacency List code","text":"<p>Code</p> C++Python <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;unordered_map&gt;\nusing namespace std;\n\nclass AdjacencyList\n{\nprivate:\n    int num_of_nodes;\n    bool is_directed;\n\n    // for weighted graph, it can be\n    // unordered_map&lt;int, vector&lt;pair&lt;int,int&gt;&gt;&gt; adj_list;\n    unordered_map&lt;int, vector&lt;int&gt;&gt; adj_list;\n\npublic:\n    AdjacencyList(int n, bool is_directed)\n    {\n        this-&gt;num_of_nodes = n;\n        this-&gt;is_directed = is_directed;\n    }\n\n    void add_edge(int x, int y)\n    {\n        // add an edge from x to y\n        this-&gt;adj_list[x].push_back(y);\n\n        // if undirected, an edge should also be from y to x\n        if (this-&gt;is_directed == false)\n            this-&gt;adj_list[y].push_back(x);\n    }\n\n    void print_graph()\n    {\n        for (auto node : this-&gt;adj_list)\n        {\n            cout &lt;&lt; node.first &lt;&lt; \" ==&gt; \";\n            for (auto e : node.second)\n            {\n                cout &lt;&lt; e &lt;&lt; \", \";\n            }\n            cout &lt;&lt; endl;\n        }\n    }\n};\n\nint main()\n{\n    int n, m, p;\n    cin &gt;&gt; n &gt;&gt; m &gt;&gt; p;\n\n    // create an instance of the adj_list class\n    AdjacencyList adj_list = AdjacencyList(n, p);\n\n    while (m--)\n    {\n        int x, y;\n        cin &gt;&gt; x &gt;&gt; y;\n\n        // add edge between x &amp; y\n        adj_list.add_edge(x, y);\n    }\n\n    // print the adjacency matrix\n    adj_list.print_graph();\n}\n</code></pre> <pre><code>print(\"Hello World\")\n</code></pre>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/02-disconnected-components/","title":"Disconnected components in Graph","text":"<ul> <li> <p>For such disconnected graph, while doing any traversal, we need to keep track of visited nodes (use <code>boolean visited_node[]</code>).</p> </li> <li> <p>Iterate the non-visited nodes and traverse them (they are disconnected component of the graph).</p> </li> </ul> <pre><code>// let n = no. of nodes in graph\nbool visited_nodes[n]={false};\n\nfor(int i=0; i&lt;n; i++){\n    if(visited_nodes[i]==false){\n        // mark the node visited and then traverse it\n        visited_nodes[i]=true;\n\n        TRAVERSE_GRAPH_FUNCTION(node=i);\n    }\n}\n</code></pre> <p>Important</p> <p>Always make sure to use the above piece of code, to prevent edge cases of disconnected graphs.</p>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/03-bfs/","title":"Breadth-First Search (BFS)","text":"<ul> <li>BFS is the level order traversal of tree.</li> </ul>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/03-bfs/#bfs-vs-dfs","title":"BFS Vs DFS","text":""},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/03-bfs/#trick-to-remember","title":"Trick to remember","text":"<p>Totka \ud83e\uddb9\u200d\u2642\ufe0f</p> <p>bfs queue (kyu)?</p> <p>dfs queue (kyu) nhi!</p> <p>BFS - queue \u2705</p> <p>DFS - stack (or recursion) \u2705</p>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/03-bfs/#bfs-code-using-queue","title":"BFS Code (<code>using Queue</code>)","text":"<ul> <li>Time complexity of BFS traversal is: <code>O (n + e)</code>.</li> </ul> <p>Code</p> C++Python <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass Solution {\npublic:\n    vector&lt;int&gt; bfsOfGraph(int V, vector&lt;int&gt; adj[])\n    {\n        // V: no of vertex (nodes)\n\n        int vis[V] = {0};\n        vector&lt;int&gt; bfs;\n\n        // iterate for non-visited nodes (to handle disconnected components)\n        for (int currIdx = 0; currIdx &lt; V; currIdx++)\n        {\n            if (vis[currIdx] == 1)\n                continue;\n            vis[currIdx] = 1;\n            queue&lt;int&gt; q;\n            // push the initial starting node\n            q.push(currIdx);\n            // iterate till the queue is empty\n            while (!q.empty())\n            {\n                // get the topmost element in the queue\n                int node = q.front();\n                q.pop();\n                bfs.push_back(node);\n                // traverse for all its neighbors\n                for (auto it : adj[node])\n                {\n                    // if the neighbor has previously not been visited,\n                    // store in Q and mark as visited\n                    if (!vis[it])\n                    {\n                        vis[it] = 1;\n                        q.push(it);\n                    }\n                }\n            }\n        }\n        return bfs;\n    }\n\n};\n\nvoid addEdge(vector &lt;int&gt; adj[], int u, int v) {\n    adj[u].push_back(v);\n    adj[v].push_back(u);\n}\n\nvoid printAns(vector &lt;int&gt; &amp;ans) {\n    for (int i = 0; i &lt; ans.size(); i++) {\n        cout &lt;&lt; ans[i] &lt;&lt; \" \";\n    }\n}\n\nint main() \n{\n\n    vector &lt;int&gt; adj[6];\n\n    addEdge(adj, 0, 1);\n    addEdge(adj, 1, 2);\n    addEdge(adj, 1, 3);\n    addEdge(adj, 0, 4);\n\n    Solution obj;\n    vector &lt;int&gt; ans = obj.bfsOfGraph(5, adj);\n    printAns(ans);\n\n    return 0;\n}\n</code></pre> <pre><code>print(\"Hello World\")\n</code></pre>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/04-dfs/","title":"Depth-First Search (DFS)","text":""},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/04-dfs/#visualization","title":"Visualization","text":""},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/04-dfs/#bfs-vs-dfs","title":"BFS Vs DFS","text":""},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/04-dfs/#trick-to-remember","title":"Trick to remember","text":"<p>Totka \ud83e\uddb9\u200d\u2642\ufe0f</p> <p>bfs queue (kyu)?</p> <p>dfs queue (kyu) nhi!</p> <p>BFS - queue \u2705</p> <p>DFS - stack (or recursion) \u2705</p>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/04-dfs/#dfs-code-recursive-stack","title":"DFS code (<code>recursive &amp; stack</code>)","text":"<ul> <li>Time complexity of BFS traversal is also: <code>O (n + e)</code>.</li> </ul>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/04-dfs/#recursive-code","title":"Recursive Code","text":"<p>Code</p> C++Python <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass Solution {\nprivate: \n    void dfs(int node, vector&lt;int&gt; adj[], int vis[], vector&lt;int&gt; &amp;ls) {\n        vis[node] = 1; \n        ls.push_back(node); \n        // traverse all its neighbours\n        for(auto it : adj[node]) {\n            // if the neighbour is not visited\n            if(!vis[it]) {\n                dfs(it, adj, vis, ls); \n            }\n        }\n    }\npublic:\n    // Function to return a list containing the DFS traversal of the graph.\n    vector&lt;int&gt; dfsOfGraph(int V, vector&lt;int&gt; adj[]) {\n        int vis[V] = {0}; \n\n        // create a list to store dfs\n        vector&lt;int&gt; ls; \n        // call dfs for non-visited nodes (to handle disconnected components)\n        for(int i=0; i&lt;V; i++){\n            if(vis[i]==0)\n                dfs(i, adj, vis, ls);   \n        }\n        return ls; \n    }\n};\n\nvoid addEdge(vector &lt;int&gt; adj[], int u, int v) {\n    adj[u].push_back(v);\n    adj[v].push_back(u);\n}\n\nvoid printAns(vector &lt;int&gt; &amp;ans) {\n    for (int i = 0; i &lt; ans.size(); i++) {\n        cout &lt;&lt; ans[i] &lt;&lt; \" \";\n    }\n}\n\nint main() \n{\n    vector &lt;int&gt; adj[5];\n\n    addEdge(adj, 0, 2);\n    addEdge(adj, 2, 4);\n    addEdge(adj, 0, 1);\n    addEdge(adj, 0, 3);\n\n    Solution obj;\n    vector &lt;int&gt; ans = obj.dfsOfGraph(5, adj);\n    printAns(ans);\n\n    return 0;\n}\n</code></pre> <pre><code>print(\"Hello World\")\n</code></pre>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/04-dfs/#iterative-code-using-stack","title":"Iterative code (<code>using stack</code>)","text":"<p>Code</p> C++Python <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass Solution {\npublic:\n    // Function to return Breadth First Traversal of given graph.\n    vector&lt;int&gt; dfsOfGraph(int V, vector&lt;int&gt; adj[])\n    {\n        // V: no of vertex (nodes)\n\n        int vis[V] = {0};\n\n        vector&lt;int&gt; dfs;\n\n        // iterate for non-visited nodes (to handle disconnected components)\n        for (int currIdx = 0; currIdx &lt; V; currIdx++)\n        {\n            if (vis[currIdx] == 1)\n                continue;\n            vis[currIdx] = 1;\n            stack&lt;int&gt; st;\n            // push the initial starting node\n            st.push(currIdx);\n            // iterate till the queue is empty\n            while (!st.empty())\n            {\n                // get the topmost element in the queue\n                int node = st.top();\n                st.pop();\n                dfs.push_back(node);\n                // traverse for all its neighbors\n                for (auto it : adj[node])\n                {\n                    // if the neighbor has previously not been visited,\n                    // store in Q and mark as visited\n                    if (!vis[it])\n                    {\n                        vis[it] = 1;\n                        st.push(it);\n                    }\n                }\n            }\n        }\n        return dfs;\n    }\n};\n\nvoid addEdge(vector &lt;int&gt; adj[], int u, int v) {\n    adj[u].push_back(v);\n    adj[v].push_back(u);\n}\n\nvoid printAns(vector &lt;int&gt; &amp;ans) {\n    for (int i = 0; i &lt; ans.size(); i++) {\n        cout &lt;&lt; ans[i] &lt;&lt; \" \";\n    }\n}\n\nint main() \n{\n\n    vector &lt;int&gt; adj[6];\n\n    addEdge(adj, 0, 1);\n    addEdge(adj, 1, 2);\n    addEdge(adj, 1, 3);\n    addEdge(adj, 0, 4);\n\n\n    Solution obj;\n    vector &lt;int&gt; ans = obj.dfsOfGraph(5, adj);\n    printAns(ans);\n\n    return 0;\n}\n</code></pre> <pre><code>print(\"Hello World\")\n</code></pre>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/05-bipartite-graph/","title":"Bipartite Graph (<code>partition graph in two sects</code>)","text":"<ul> <li> <p>Coloring graph nodes with two different colors, such that no two connected nodes have the same color.</p> </li> <li> <p>A graph is bipartite if the nodes can be partitioned into two independent sets A and B such that every edge in the graph connects a node in set A and a node in set B.</p> </li> </ul>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/05-bipartite-graph/#approach","title":"Approach","text":"<ul> <li>We will stick with our color analogy.</li> <li>Create a vector color(n,-1). {n size, color: -1}</li> <li>(-1) means no color, (0) means color1, (1) means color2.</li> <li> <p>We will simply do BFS traversal, and if a node is not visited, it will have no color, so we will color it with (1-parent_node_col).</p> </li> <li> <p>If a node is already visited, then we will simply check if indeed the child node color is different from parent node or not.</p> </li> <li>If not, means, the graph isn't Bipartite.</li> </ul>"},{"location":"04-dsa/01-graph/01-intro-bfs-dfs/05-bipartite-graph/#code","title":"Code","text":"<p>Leetcode Bipartite graph question link</p> <p>Leetcode Bipartite graph question link</p> <pre><code>bool isBipartite(vector&lt;vector&lt;int&gt;&gt;&amp; graph) {\n        int n=graph.size();\n\n        // initialize color with -1.\n        // -1 = no color\n        // 0 = color1\n        // 1 = color2\n        vector&lt;int&gt; color(n,-1);\n\n        // to handle disconnected components\n        vector&lt;bool&gt; visited(n,false); \n\n        for(int i=0;i&lt;n;i++){\n            if(visited[i]==true)continue;\n\n            queue&lt;int&gt; q;\n            q.push(i);\n            visited[i]=true;\n\n            int current_col = 0;\n            // we will update with (1-current_col),\n            // so that it will keep oscillating in {0,1}\n\n            color[i]=current_col;\n\n            while(!q.empty()){\n                int node = q.front();\n                q.pop();\n\n                for(auto&amp;e: graph[node]){\n                    if(visited[e]==false){\n                        visited[e]=true;\n                        color[e]=1-color[node];\n\n                        q.push(e);\n                    }else{\n                        if(color[e]==color[node]){return false;}\n                    }\n                }\n            }\n\n        }\n        return true;\n\n    }\n</code></pre>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/01-cycle-detection-undirected-bfs-and-dfs/","title":"Cycle detection in Undirected Graph (BFS &amp; DFS)","text":"<ul> <li>Simply check if a node is not already visited.</li> <li>If it's already visited, just check if it's not the parent of the node (that called it).</li> <li>If it's not, it is indeed a cyclic undirected graph.</li> </ul> <p>Question link</p> <p>Code Studio question link</p>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/01-cycle-detection-undirected-bfs-and-dfs/#bfs-code","title":"BFS code","text":"<pre><code>bool bfs_cycle_detection( vector&lt;int&gt; adj_list[], int n){\n    bool visited[n];\n    for(auto &amp;e:visited)e=false;\n    unordered_map&lt;int,int&gt; parent;\n\n    for(int i=0;i&lt;n;i++){\n        if(visited[i]==true)continue;\n\n        queue&lt;int&gt; q;\n        q.push(i);\n        visited[i]=true;\n        parent[i]=-1;\n\n        while(!q.empty()){\n            int node = q.front();\n            q.pop();\n            for(auto &amp;e: adj_list[node]){\n                if(visited[e]==false){\n                    visited[e]=true;\n                    q.push(e);\n                    parent[e]=node;\n                }\n                else if(parent[node]==e){\n                    continue;\n                }\n                else{\n                    // current node is already visited, and it's not the parent of node.\n                    // means, cycle exists\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n</code></pre>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/01-cycle-detection-undirected-bfs-and-dfs/#dfs-code-recursive","title":"DFS code (recursive)","text":"<pre><code>bool dfs_is_visited_and_not_parent(vector&lt;int&gt; adj_list[], int n, int curr, int parent, bool visited[]){\n    visited[curr]=true;\n\n    for(auto &amp;e:adj_list[curr]){\n        if(visited[e]==false){\n            bool return_val = dfs_is_visited_and_not_parent(adj_list, n, e, curr, visited);\n            if(return_val==true)return true;\n        }\n        else if(e == parent)continue;\n        else{\n            // already visited and is not parent\n            // means, cyclic undirected graph\n            return true;\n        }\n    }\n    return false;\n}\n\nbool dfs_cycle_detection_recursion(vector&lt;int&gt; adj_list[], int n){\n    bool visited[n];\n    for(auto &amp;e:visited)e=false;\n\n    // handling disconnected components\n    for(int i=0; i&lt;n; i++){\n        if(visited[i]==true)continue;\n\n        bool return_val = dfs_is_visited_and_not_parent(adj_list,n,i,-1,visited);\n        if(return_val==true)return true;\n    }\n    return false;\n}\n</code></pre>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/01-cycle-detection-undirected-bfs-and-dfs/#dfs-code-iterative-stack","title":"DFS code (iterative <code>stack</code>)","text":"<pre><code>bool dfs_cycle_detection_iterative(vector&lt;int&gt; adj_list[], int n){\n    bool visited[n];\n    for(auto &amp;e:visited)e=false;\n\n    unordered_map&lt;int,int&gt; parent;\n\n    // handling disconnected components\n    for(int i=0; i&lt;n; i++){\n        if(visited[i]==true)continue;\n\n        parent[i]=-1;\n        stack&lt;int&gt; st;\n        st.push(i);\n        visited[i]=true;\n\n        while(!st.empty()){\n            int node = st.top();\n            st.pop();\n\n            for(auto &amp;e:adj_list[node]){\n                if(visited[e]==false){\n                    visited[e]=true;\n                    parent[e]=node;\n                    st.push(e);\n                }\n                else if(parent[node]==e)continue;\n                else{\n                    // current node already visited, and is not the parent of node.\n                    // means cyclic undirected graph\n                    return true; \n                }\n            }\n        }\n    }\n    return false;\n}\n</code></pre>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/02-cycle-detection-directed-dfs/","title":"Cycle detection in Directed Graph (DFS)","text":""},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/02-cycle-detection-directed-dfs/#why-cant-we-use-the-same-algorithm-as-in-undirected-graph","title":"Why can't we use the same algorithm as in undirected graph?","text":"Explanation <p>Look at (3,4,8) section.</p> <p>First, we will visit 3, and mark it as visited. Then, we will go to 4, and mark it as visited. We will return back to 3, and go to 8, and mark it as visited. Now, 8 will try to visit 4, but it's already visited, and 4 is not the parent of 8. So, our algorithm will conclude a cycle is present.</p> <p>But, actually it's not (in {3,4,8}).</p> <p>So, what went wrong?</p> <p>We're not reaching to 8 by following the same path in which 8 was earlier found. To account for this, we need to create a <code>dfs_visited</code> array, that will store the visited nodes in the current paths.</p>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/02-cycle-detection-directed-dfs/#hint","title":"Hint \ud83e\udd42","text":"<ul> <li>We need to create an extra <code>dfs_visited[n]</code> array to keep track of visited nodes in the current path.</li> </ul>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/02-cycle-detection-directed-dfs/#code","title":"Code","text":"<pre><code>bool dfs_recursive_cyclic(vector&lt;int&gt; adj_list[], int n, bool visited[], bool dfs_visited[], int node){\n  visited[node]=true;\n  dfs_visited[node]=true;\n\n  for(auto&amp;e:adj_list[node]){\n    if(visited[e]==false){\n      bool return_val = dfs_recursive_cyclic(adj_list, n, visited, dfs_visited,e);\n      if(return_val==true)return true;\n    }\n    else if(dfs_visited[e]==true){\n      return true;\n    }\n  }\n  dfs_visited[node]=false;\n  return false;\n}\n\nint detectCycleInDirectedGraph(int n, vector &lt; pair &lt; int, int &gt;&gt; &amp; edges) {\n  // Write your code here.\n  vector&lt;int&gt; adj_list[n+1];\n  for(auto &amp;e:edges){\n    int x= e.first;\n    int y= e.second;\n    adj_list[x].push_back(y);\n  }\n\n  bool visited[n+1]={false};\n\n  for(int i=0;i&lt;n;i++){\n    if(visited[i]==true)continue;\n    bool dfs_visited[n+1]={false};\n    bool return_val = dfs_recursive_cyclic(adj_list, n+1, visited, dfs_visited,i);\n    if(return_val==true)return true;\n  }\n  return false;\n\n}\n</code></pre>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/03-topological-sort-dfs/","title":"Topological Sort (using <code>DFS</code>)","text":""},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/03-topological-sort-dfs/#what-is-topological-sorting","title":"What is topological sorting?","text":"<ul> <li>Topological sorting for Directed Acyclic Graph (DAG) is a linear ordering of vertices such that for every directed edge u-v, vertex u comes before v in the ordering.</li> <li>not possible if the graph is not a DAG.</li> </ul> <p>Topo sort of the above graph:     5 4 2 3 1 0</p> <pre><code>Explanation:\n    since, there's an edge from (5-&gt;0),\n    so in topo sort of the graph, 5 must come become 0.\n</code></pre>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/03-topological-sort-dfs/#approach-using-dfs","title":"Approach (using DFS)","text":"<ol> <li>Create an empty stack, we will use it store the nodes in their topo sort.</li> <li>Use DFS traversal to traverse the graph (same code as you would for cycle detection (<code>bool dfs_visited[]</code>)).</li> <li>When a node has traversed all its connected nodes, push the node into the stack.</li> <li>Repeat.</li> </ol> <p>\u2705 Stack from top contains one of the possible topo sort of the graph.</p> Hint <ul> <li>Instead of stack, you can also use vector.</li> <li>If you already know <code>graph is not cyclic</code>, you can push the nodes from end in vector.</li> <li>If you're not sure, push nodes in vector, and once done, reverse the vector.</li> </ul>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/03-topological-sort-dfs/#leetcode-question","title":"Leetcode question","text":"<p>Leetcode topological sort question</p> <p>Course Schedule-2 leetcode medium</p> <pre><code>class Solution {\npublic:\n\n    bool dfs_topo_sort(vector&lt;int&gt; adj_list[], int n, bool visited[], bool dfs_visited[], int node, vector&lt;int&gt; &amp;ans){\n        visited[node]=true;\n        dfs_visited[node]=true;\n\n        for(auto&amp;e:adj_list[node]){\n            if(visited[e]==false){\n                bool return_val = dfs_topo_sort(adj_list,n,visited,dfs_visited,e, ans);\n                if(return_val==false){return false;}\n            }\n            else if(dfs_visited[e]==true){\n                ans.clear();\n                // false return - cyclic graph (no topo sort possible)\n                return false;\n            }\n        }\n        ans.push_back(node);\n        dfs_visited[node]=false;\n        return true;\n    }\n\n    vector&lt;int&gt; findOrder(int numCourses, vector&lt;vector&lt;int&gt;&gt;&amp; prerequisites) {\n        vector&lt;int&gt; adj_list[numCourses];\n        for(auto &amp;e:prerequisites){\n            int x = e[0], y = e[1];\n\n            //  for pair [0, 1] =&gt; 1 before 0\n            adj_list[y].push_back(x);\n        }\n\n        bool visited[numCourses];\n        bool dfs_visited[numCourses];\n        for(auto&amp;e:visited)e=false;\n        for(auto&amp;e:dfs_visited)e=false;\n\n        vector&lt;int&gt; ans;\n\n\n        for(int i=0;i&lt;numCourses;i++){\n            if(visited[i]==true)continue;\n            bool return_val = dfs_topo_sort(adj_list,numCourses,visited,dfs_visited,i,ans);\n            if(return_val==false)break;\n        }\n\n        reverse(ans.begin(),ans.end());\n        return ans;\n    }\n};\n</code></pre>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/04-topological-sort-kahn-algorithm/","title":"Topological Sort (<code>Kahn's algorithm</code>)","text":"<p>An iterative approach to get topological sort of the graph.</p> <p>Note</p> <p>We don't need to worry about disconnect components in Kahn's algorithm.</p> <ul> <li>As all we care about is in-degree to be 0, and cycle can be present in any component.</li> <li>Our in-degree calculation will take care of this itself.</li> </ul>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/04-topological-sort-kahn-algorithm/#algorithm","title":"Algorithm","text":"<pre><code>in_degree_list \u2190 Vector containing in-degree of all the nodes at index\nL \u2190 Empty list that will contain the topologically sorted elements\nQ \u2190 Queue of all nodes with no incoming edge (in-degree 0)\n\nwhile Q is not empty do\n    remove a node n from Q\n    add n to L\n    for each node m with an edge e from n to m do\n        remove edge e from the graph (in_degree_list[m]--;)\n        if m has no other incoming edges (in_degree_list[m]==0);\n            then insert m into Q\n\nif graph has edges (`len(L) != no. of nodes`) then\n    return error   (graph has at least one cycle)\nelse \n    return L   (a topologically sorted order)\n</code></pre>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/04-topological-sort-kahn-algorithm/#code","title":"Code","text":"<pre><code>// Including necessary header file\n#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\n// Function to return list containing vertices in\n// Topological order.\nvector&lt;int&gt; topologicalSort(vector&lt;vector&lt;int&gt; &gt;&amp; adj, int V)\n{\n    // Vector to store indegree of each vertex\n    vector&lt;int&gt; indegree(V);\n    for (int i = 0; i &lt; V; i++) {\n        for (auto it : adj[i]) {\n            indegree[it]++;\n        }\n    }\n\n    // Queue to store vertices with indegree 0\n    queue&lt;int&gt; q;\n    for (int i = 0; i &lt; V; i++) {\n        if (indegree[i] == 0) {\n            q.push(i);\n        }\n    }\n    vector&lt;int&gt; result;\n    while (!q.empty()) {\n        int node = q.front();\n        q.pop();\n        result.push_back(node);\n\n        // Decrease indegree of adjacent vertices as the\n        // current node is in topological order\n        for (auto it : adj[node]) {\n            indegree[it]--;\n\n            // If indegree becomes 0, push it to the queue\n            if (indegree[it] == 0)\n                q.push(it);\n        }\n    }\n\n    // Check for cycle\n    if (result.size() != V) {\n        cout &lt;&lt; \"Graph contains cycle!\" &lt;&lt; endl;\n        return {};\n    }\n\n    return result;\n}\n</code></pre>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/05-cycle-detection-directed-bfs/","title":"Cycle detection in Directed Graph (BFS)","text":"<p>We use the very same code as in <code>Kahn's algorithm</code>.</p> <ul> <li>If the length of the topo sort array is equal to no. of nodes, no cycle is present.</li> <li>Else, graph is cyclic.</li> </ul> <p>Note</p> <p>We don't need to worry about disconnect components in Kahn's algorithm.</p> <ul> <li>As all we care about is in-degree to be 0, and cycle can be present in any component.</li> <li>Our in-degree calculation will take care of this itself.</li> </ul>"},{"location":"04-dsa/01-graph/02-cycle-detection-and-topo-sort/05-cycle-detection-directed-bfs/#code","title":"Code","text":"<p>Code studio detect cycle in a directed graph question</p> <p>CodeStudio detect cycle in a directed graph</p> <pre><code>// Function to return list containing vertices in\n// Topological order.\nbool bfs_cycle_detection_kahn_algorithm_topologicalSort(vector&lt;int&gt; adj[], int V)\n{\n    // Vector to store indegree of each vertex\n    vector&lt;int&gt; indegree(V);\n    for (int i = 0; i &lt; V; i++) {\n        for (auto it : adj[i]) {\n            indegree[it]++;\n        }\n    }\n\n    // Queue to store vertices with indegree 0\n    queue&lt;int&gt; q;\n    for (int i = 0; i &lt; V; i++) {\n        if (indegree[i] == 0) {\n            q.push(i);\n        }\n    }\n    vector&lt;int&gt; result;\n    while (!q.empty()) {\n        int node = q.front();\n        q.pop();\n        result.push_back(node);\n\n        // Decrease indegree of adjacent vertices as the\n        // current node is in topological order\n        for (auto it : adj[node]) {\n            indegree[it]--;\n\n            // If indegree becomes 0, push it to the queue\n            if (indegree[it] == 0)\n                q.push(it);\n        }\n    }\n\n    // Check for cycle\n    if (result.size() != V) {\n        return true;\n    }\n\n    return false;\n}\n\nint detectCycleInDirectedGraph(int n, vector &lt; pair &lt; int, int &gt;&gt; &amp; edges) {\n  // Write your code here.\n  vector&lt;int&gt; adj_list[n+1];\n  for(auto &amp;e:edges){\n    int x= e.first;\n    int y= e.second;\n    adj_list[x].push_back(y);\n  }\n\n return bfs_cycle_detection_kahn_algorithm_topologicalSort(adj_list, n+1);\n\n}\n</code></pre>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/01-shortest-path-in-undirected/","title":"Shortest path in Undirected graph","text":"<ul> <li>In undirected graph, shortest path can be easily found via BFS (breadth-first-search).</li> <li>If you want to get the no. of steps, you can simply do so by keeping track of number of steps taken from source (queue length after traversing all the child/connected nodes).</li> <li>If you need the shortest path, we can easily do so by just creating a <code>parent map</code>, that stores the parent of each node.</li> <li><code>Backtrack from target node to source node using the parent map</code>.</li> </ul> <p>Code studio: Shortest path in an unweighted graph</p> <p>CodeStudio: Shortest path in an unweighted graph</p> <pre><code># include &lt;unordered_map&gt;\nvector&lt;int&gt; shortestPath(vector&lt;pair&lt;int, int&gt;&gt; edges, int n, int m, int s,\n                         int t) {\n\n\n  // Write your code here\n  vector&lt;int&gt; adj_list[n + 1];\n  for (auto &amp;e : edges) {\n    int x = e.first, y = e.second;\n\n    adj_list[x].push_back(y);\n    adj_list[y].push_back(x);\n  }\n\n  bool visited[n + 1]; \n  // we only need it to check if a node is visited, not for disconnected component.\n  // as src is fixed.\n\n  for (auto &amp;e : visited)\n    e = false;\n\n  unordered_map&lt;int, int&gt; parent;\n\n  // source is visited, and its parent is -1.\n  visited[s] = true;\n  parent[s] = -1; // no parent\n\n\n\n  queue&lt;int&gt; q;\n  q.push(s);\n\n  while (!q.empty()) {\n    int node = q.front();\n    q.pop();\n\n    for (auto &amp;e : adj_list[node]) {\n      if (visited[e] == false) {\n        visited[e] = true;\n        q.push(e);\n        parent[e] = node;\n      }\n    }\n  }\n\n  // walk back from destination to source\n  // in end, we will reverse the vector\n  int curr_node = t;\n  vector&lt;int&gt; ans;\n\n  while (curr_node!=-1 &amp;&amp; curr_node!=s) {\n    //   cout&lt;&lt;\"curr_node: \"&lt;&lt;curr_node&lt;&lt;endl;\n      ans.push_back(curr_node);\n      curr_node = parent[curr_node];\n\n  }\n    if(curr_node==s)ans.push_back(curr_node);\n        reverse(ans.begin(),ans.end());\n        return ans;\n}\n</code></pre>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/02-shortest-path-in-directed-acyclic-graph/","title":"Shortest path in DAG (<code>directed acyclic graph</code>)","text":"<ul> <li>Do standard BFS traversal, just don't use a boolean visited array.</li> <li>Rather, create a distance array, which by default is -1, but stores the minimum distance between source node &amp; index node.</li> </ul> <p>Warning</p> <ul> <li>In the below code, we're using queue, which increases time complexity.</li> <li>The better approach is to simply use priority queue, and the algorithm is called, <code>Dijkstra algorithm</code>.</li> <li>The code won't work for graphs having negative weights.</li> </ul>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/02-shortest-path-in-directed-acyclic-graph/#code-to-calculate-distance-from-source-node","title":"Code to calculate distance from source node","text":"<p>Geeks for Geeks question</p> <p>Shortest path in Directed Acyclic Graph <p></p> <pre><code>class Solution {\n  public:\n     vector&lt;int&gt; shortestPath(int N,int M, vector&lt;vector&lt;int&gt;&gt;&amp; edges){\n        // code here\n        vector&lt;pair&lt;int,int&gt;&gt; adj[N];\n        for(auto &amp;e:edges){\n            int x=e[0], y=e[1], w=e[2];\n             vector&lt;int&gt; shortestPath(int N, int M, vector&lt;vector&lt;int&gt;&gt; &amp;edges)\n            adj[x].push_back({y,w});\n        }\n\n        // initialize `ans` with -1.\n        vector&lt;int&gt; ans(N,-1);\n        ans[0]=0; // 0 is the src node.\n\n        queue&lt;int&gt; q;\n        q.push(0);\n\n        while(!q.empty()){\n            int node = q.front();\n            q.pop();\n\n            for(auto&amp;e:adj[node]){\n                if(ans[e.first]==-1){\n                    ans[e.first]=ans[node]+e.second;\n                    q.push(e.first);\n                }else if(ans[e.first]&gt;ans[node]+e.second){\n                    ans[e.first]=ans[node]+e.second;\n                    q.push(e.first);\n                }\n            }\n        }\n\n        return ans;\n    }\n};\n</code></pre>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/02-shortest-path-in-directed-acyclic-graph/#exact-route-followed-for-shortest-path","title":"Exact  route followed for shortest path","text":"<ul> <li> <p>We can simply use <code>unordered_map parent</code> to keep track of the parent node that lead the current node to its shortest path.</p> </li> <li> <p>Whenever we need to update the distance array, we will also update the <code>parent</code>, to account for new parent with shortest route.</p> </li> <li> <p>Finally, simply backtrack from destination to source node.</p> </li> </ul> <pre><code>    vector&lt;int&gt; shortestPath(int N, int M, vector&lt;vector&lt;int&gt;&gt; &amp;edges)\n    {\n        // code here\n        vector&lt;pair&lt;int, int&gt;&gt; adj[N];\n        for (auto &amp;e : edges)\n        {\n            int x = e[0], y = e[1], w = e[2];\n\n            adj[x].push_back({y, w});\n        }\n\n        vector&lt;int&gt; ans(N, -1);\n        ans[0] = 0;\n\n\n        // to keep track of exact path, use parent map\n        unordered_map&lt;int, int&gt; parent;\n        parent[0] = -1;\n\n        queue&lt;int&gt; q;\n        q.push(0);\n\n        while (!q.empty())\n        {\n            int node = q.front();\n            q.pop();\n\n            for (auto &amp;e : adj[node])\n            {\n                if (ans[e.first] == -1)\n                {\n                    ans[e.first] = ans[node] + e.second;\n                    q.push(e.first);\n                    parent[e.first] = node;\n                }\n                else if (ans[e.first] &gt; ans[node] + e.second)\n                {\n                    ans[e.first] = ans[node] + e.second;\n                    q.push(e.first);\n                    parent[e.first] = node;\n                }\n            }\n        }\n\n        // print minimum path between 0 to 2. (should be 0 =&gt; 4 =&gt; 2)\n        int curr = 2;\n        cout &lt;&lt; \"shortest route from (0=&gt;2):\\n\";\n        while (curr != -1 &amp;&amp; curr != 0)\n        {\n            cout &lt;&lt; curr &lt;&lt; \" =&gt; \";\n            curr = parent[curr];\n        }\n        if(curr==0)cout &lt;&lt; curr &lt;&lt; endl;\n\n        return ans;\n    }\n</code></pre>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/03-dijkstra-algorithm/","title":"Dijkstra's Algorithm","text":"<ul> <li>Use <code>priority queue</code>.</li> <li>Time complexity: O(E *log(V))<ul> <li><code>E: number of edges;</code></li> <li><code>V: number of vertices</code></li> </ul> </li> </ul> <p>No negative weights</p> <ul> <li>Dijkstra's algorithm doesn't works for graphs containing negative weights.</li> <li>It can't detect negative cycles and will stuck in the loop forever.</li> <li>Bellman-ford algorithm will tackle these shortcomings, but will have more time complexity.</li> </ul>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/03-dijkstra-algorithm/#code","title":"Code","text":"<p>Codestudio question: Dijkstra's shortest path</p> <p>Shortest path in Directed Acyclic Graph </p> <pre><code>vector&lt;int&gt; shortestPath(int N,int M, vector&lt;vector&lt;int&gt;&gt;&amp; edges){\n        // code here\n        vector&lt;pair&lt;int,int&gt;&gt; adj[N];\n        for(auto &amp;e:edges){\n            int x=e[0], y=e[1], w=e[2];\n\n            adj[x].push_back({y,w});\n        }\n\n\n        vector&lt;int&gt; ans(N,-1);\n        ans[0]=0;\n\n        priority_queue&lt;int&gt; q;\n        q.push(0);\n\n        while(!q.empty()){\n            int node = q.top();\n            q.pop();\n\n            for(auto&amp;e:adj[node]){\n                if(ans[e.first]==-1){\n                    ans[e.first]=ans[node]+e.second;\n                    q.push(e.first);\n                }else if(ans[e.first]&gt;ans[node]+e.second){\n                    ans[e.first]=ans[node]+e.second;\n                    q.push(e.first);\n                }\n            }\n        }\n\n        return ans;\n    }\n</code></pre>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/03-dijkstra-algorithm/#why-priority-queue-is-preferred-over-queue","title":"Why <code>priority queue</code> is preferred over <code>queue</code>?","text":"<ul> <li> <p>If (node: 1) was connected with 100s of nodes, all of them were to be updated twice, and this happened simply bcoz, queue traverses in FIFO orders and doesn't cares about distance.</p> </li> <li> <p>If we would have used priority queue, it would have given more preference to the shorter distant node, and we would have prevented unnecessary updation.</p> </li> </ul>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/03-dijkstra-algorithm/#using-set-instead-of-priority-queue","title":"Using <code>Set</code> instead of <code>priority queue</code>","text":"<ul> <li>We can also Set instead of Priority queue.</li> <li>Set stores data in sorted order.</li> <li>But, when we will find if a shorter distance to a node exists, we would be required to delete that from the set.</li> <li>The performance gain is not significant.</li> </ul>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/03-dijkstra-algorithm/#time-complexity","title":"Time complexity \u23f2\ufe0f","text":"<p>Info</p> <ul> <li>Time complexity: O(E *log(V))<ul> <li><code>E: number of edges;</code></li> <li><code>V: number of vertices</code></li> </ul> </li> </ul> Explanation <ul> <li>In worst case, all vertices of graph will be connected to each other.</li> <li>So, E = V * (V-1) = V^2</li> <li>Now, we need to traverse the graph through edge, so complexity <code>O(V^2)</code>.</li> <li>And, while traversing, we also need to insert in priority queue or do some operations.</li> <li>In worst case, we will push all the edges <code>(weight,node,parent)</code>, so time complexity: <code>O(log(V^2))</code>.</li> </ul> <p>So, overall complexity is:</p> <p>= O(V^2 * log(V^2))</p> <p>= O(V^2 * 2*log(V)) # log properties</p> <p>= O(E * log(V)) # since, E = V^2</p>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/04-bellman-ford-algorithm/","title":"Bellman-Ford algorithm","text":"<p><code>Bellman-ford</code> V/s <code>Dijkstra</code></p> <ul> <li>Dijkstra's algorithm doesn't works for graphs containing negative weights.</li> <li>Dijkstra can't detect negative cycles and will stuck in the loop forever.</li> <li>Bellman-ford algorithm will tackle these shortcomings, but will have more time complexity.</li> </ul> <ul> <li>single source shortest path algorithm</li> <li>can work with negative weights</li> <li>and can also detect negative cycles.</li> </ul>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/04-bellman-ford-algorithm/#idea","title":"Idea \ud83e\udd14","text":"<ul> <li> <p>The Bellman-Ford algorithm\u2019s primary principle is that it starts with a single source and calculates the distance to each node.</p> </li> <li> <p>The distance is initially unknown and assumed to be infinite, but as time goes on, the algorithm relaxes those paths by identifying a few shorter paths.</p> </li> <li> <p>Hence it is said that Bellman-Ford is based on <code>Principle of Relaxation</code>.</p> </li> <li> <p>Iterate through all the edges for (n-1) times, do relaxation.</p> </li> <li> <p>To detect negative cycle, iterate for the one last time (n time), and if a single relaxation is possible, means the graph contains negative cycles, and hence shortest distance can't be found.</p> </li> </ul>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/04-bellman-ford-algorithm/#what-is-relaxation-in-bellman-ford-algorithm","title":"What is relaxation in Bellman-ford algorithm?","text":"<pre><code>// dist[] &lt;= distance of nodes from a source node\n// if there's an edge from x to y, and the dist can be reduced, do it.\n// this is called relaxation.\nif (dist[x]+wt &lt; dist[y]){\n    dist[y]=dist[x]+wt;\n}\n</code></pre>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/04-bellman-ford-algorithm/#why-iterate-for-n-1-times","title":"Why iterate for (n-1) times?","text":"<ul> <li>In the worst case, for a graph with n nodes, the farthest node from source node can be at the (n-1 edge) (if they are in one component).</li> <li>So, if we have iterated for (n-1) times and did the relaxation, we can be sure that we have covered the worst case. Now, either some nodes will be in another component (which can't be visited from source node), or a negative cycle will be present in the graph.</li> </ul> <ul> <li>If the other nodes are in another component, then again no updation in the distance array will happen.</li> <li>But, if the graph have negative cycle, our distance array will again be updated (in other words, relaxation condition will be true).</li> </ul> <ul> <li>So, when we are iterating through all the edges for the nth time, a single relaxation condition is sufficient to indicate the graph contains negative cycle.</li> </ul>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/04-bellman-ford-algorithm/#code","title":"Code","text":"<pre><code>    /*  Function to implement Bellman Ford\n    *   edges: vector of vectors which represents the graph edge (node1, node2, weight)\n    *   S: source vertex to start traversing graph with\n    *   V: number of vertices\n    */\n    vector&lt;int&gt; bellman_ford(int V, vector&lt;vector&lt;int&gt;&gt;&amp; edges, int S) {\n        vector&lt;int&gt; dist(V, 1e8);\n        dist[S] = 0;\n        for (int i = 0; i &lt; V - 1; i++) {\n            for (auto it : edges) {\n                int u = it[0];\n                int v = it[1];\n                int wt = it[2];\n                if (dist[u] != 1e8 &amp;&amp; dist[u] + wt &lt; dist[v]) {\n                    dist[v] = dist[u] + wt;\n                }\n            }\n        }\n        // Nth relaxation to check negative cycle\n        for (auto it : edges) {\n            int u = it[0];\n            int v = it[1];\n            int wt = it[2];\n            if (dist[u] != 1e8 &amp;&amp; dist[u] + wt &lt; dist[v]) {\n                return { -1};\n            }\n        }\n\n        return dist;\n    }\n</code></pre>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/04-bellman-ford-algorithm/#time-complexity","title":"Time complexity \ud83d\udd65","text":"<ul> <li> <p>Since, we're iterating through all the edges for (n-1) times, so complexity:</p> </li> <li> <p>(n-1) is roughly same as n, which is number of vertices (V).</p> </li> </ul> <p></p>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/04-bellman-ford-algorithm/#dijkstra-vs-bellman-ford","title":"Dijkstra Vs Bellman-ford","text":"<p>Time complexity of Dijkstra &amp; Bellman-ford</p> <ul> <li>Dijkstra's time complexity is: O(E*log(V))</li> <li>Bellman-ford's time complexity is: O(E*V)</li> </ul> <p>So obviously, Dijkstra is more efficient,</p> <ul> <li>but can't handle negative weights </li> <li>&amp; if a negative cycle is present, it will be stuck in the loop forever.</li> </ul> <p>Bellman-ford is more time-consuming,</p> <ul> <li>but, can handle negative weights</li> <li>and will be able to detect negative cycle.</li> </ul>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/05-floyd-warshall-algorithm/","title":"Floyd-Warshall algorithm","text":"<ul> <li>Multi-source shortest path algorithm</li> <li>Can detect negative cycles</li> </ul> <p>It is used to calculate the shortest path from each node to another node.</p>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/05-floyd-warshall-algorithm/#algorithm","title":"Algorithm","text":"<ol> <li>We'll create a adjacency matrix representation of the graph.</li> <li>Each cell with index {i,j} will represent distance from <code>node i</code> to <code>node j</code>.</li> <li>We'll initialize the matrix with a very large number (<code>1e9 or INT_MAX</code>).</li> <li>Update all the diagonal elements to be 0. <code>mat[i][i]=0</code>. Since to go from node-0 to node-0, distance will be 0.</li> <li>Now, traverse all the edges and update the matrix accordingly.</li> <li>Once done, now the matrix contains distance by direct route (from i to j). Now, we will follow the intermediate approach.</li> <li>Instead of directly going from node-i to node-j, we will go via node-k. So, <code>new_dist=node[i][k]+node[k][j]</code>. And, if this new distance is smaller than the existing distance, we will update it.</li> <li><code>For k, we will start from 0 and go till last node (n-1)</code>.</li> <li>In the end, our matrix with cell {i,j} will contain shortest distance from node-i to node-j.</li> <li>To detect if the graph contains negative cycle, simply check if diagonal element are non-zero. If they are, the graph contains a <code>negative cycle</code>.</li> </ol> <p>This is so because, we initialized the diagonals with 0, and our graph started traversing from some node and reached back to itself with negative weight, means, negative cycle.</p>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/05-floyd-warshall-algorithm/#code","title":"Code","text":"<p>GFG Floyd-Warshall algorithm question link</p> <p>GFG Floyd-Warshall algorithm question link</p> <pre><code>class Solution {\n  public:\n    void shortest_distance(vector&lt;vector&lt;int&gt;&gt;&amp;matrix){\n        // Code here\n        int n = matrix.size();\n\n        for(int k=0;k&lt;n;k++){\n            for(int i=0;i&lt;n;i++){\n                for(int j=0;j&lt;n;j++){\n                    int dist_ij = matrix[i][j];\n                    int dist_ik = matrix[i][k];\n                    int dist_kj = matrix[k][j];\n\n                    // if there exists a route from {i =&gt; k =&gt; j}\n                    if(dist_ik!=-1 &amp;&amp; dist_kj!=-1){\n\n                        // if no route b/w {i=&gt;j} or smaller distance through k\n                        if(dist_ij==-1 || (dist_ij &gt; dist_ik + dist_kj)){\n                            matrix[i][j] = dist_ik+dist_kj;\n                        }\n                    }\n                }\n            }\n        }\n\n        // if we were required to check if the graph contains negative cycle,\n        // simply check if diagonals are non-zero (negative mainly).\n        //\n        // for(int i=0;i&lt;n;i++)\n            // if(matrix[i][i]&lt;0)\n                    // cout&lt;&lt;\"Graph contains negative cycle\"&lt;&lt;endl;\n    }\n};\n</code></pre>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/05-floyd-warshall-algorithm/#another-leetcode-medium-problem","title":"Another Leetcode medium problem","text":"<p>Leetcode Floyd-warshall algorithm problem</p> <p>Find the city with the smallest number of neighbors at a threshold distance</p>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/05-floyd-warshall-algorithm/#check-if-graph-contains-negative-cycle","title":"Check if graph contains negative cycle","text":"<ul> <li>If we were required to check if the graph contains negative cycle,</li> <li>simply check if diagonals are non-zero (negative mainly).</li> </ul> <pre><code>for(int i=0;i&lt;n;i++)\n    if(matrix[i][i]&lt;0)\n        cout&lt;&lt;\"Graph contains negative cycle\"&lt;&lt;endl;\n</code></pre>"},{"location":"04-dsa/01-graph/03-shortest-path-in-graph/05-floyd-warshall-algorithm/#time-complexity","title":"Time complexity \u23f2\ufe0f","text":"<ul> <li>Time complexity of Floyd-Warshall algorithm is: <code>O(V^3)</code></li> </ul> <p>Info</p> <p>Since we're travelling through all the intermediate nodes and from each node to another node, time complexity is:</p> <ul> <li> <p>O(n^3) // or we could say O(V^3)</p> </li> <li> <p>If instead of using floyd-warshall algorithm, we have used Dijkstra's algorithm for each node as source node, time complexity would have been:</p> </li> <li> <p>O(V) * O(E* log(V)) // time-complexity of dijkstra * no. of nodes</p> </li> </ul> <p><code>Dijkstra</code> V/s <code>Floyd-Warshall</code> algorithm</p> <ul> <li>So, Dijkstra with each node as source node, will have better time-complexity than floyd-warshall algorithm.</li> <li>But, <code>Dijkstra</code> will be stuck in forever loop if the graph contains negative cycles and it won't be useful if the graph contains <code>negative weights</code>.</li> <li>So, for such situations, Floyd-Warshall will be preferred.</li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/01-minimum-spanning-tree/","title":"Minimum spanning trees","text":""},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/01-minimum-spanning-tree/#what-are-spanning-trees","title":"What are spanning trees?","text":"<p>A spanning tree is a subset of Graph G, such that all the vertices are connected using minimum possible number of edges.</p> <ul> <li>Hence, a spanning tree does not have cycles</li> <li>a graph may have more than one spanning tree</li> <li>Every node is reachable by another node.</li> </ul> <p>Info</p> <p>Spanning tree</p> <ul> <li>n nodes (vertices)</li> <li>(n-1) edges</li> </ul> <p></p>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/01-minimum-spanning-tree/#properties-of-spanning-tree","title":"Properties of Spanning tree","text":"<ul> <li>A Spanning tree does not exist for a disconnected graph.</li> <li>For a connected graph having N vertices then the number of edges in the spanning tree for that graph will be N-1.</li> <li>A Spanning tree does not have any cycle.</li> <li>We can construct a spanning tree for a complete graph by removing E-N+1 edges, where E is the number of Edges and N is the number of vertices.</li> <li>Algorithms like <code>Dijkstra</code> &amp; <code>A* search</code> algorithm internally build a spanning tree as an intermediate step.</li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/01-minimum-spanning-tree/#minimum-spanning-tree","title":"Minimum Spanning tree","text":"<ul> <li>A spanning tree with minimum sum of weights.</li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/02-prims-algorithm/","title":"Prim's Algorithm (<code>minimum spanning tree</code>)","text":""},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/02-prims-algorithm/#algorithm","title":"Algorithm","text":"<ol> <li>Create a boolean visited array that stores if the node is already present in MST.</li> <li>Create an empty min-priority queue.</li> <li>Priority queue should store three numbers: {weight, node, parent_node}.</li> <li>This structure makes sure, at the top of the priority queue, we have the least weighted node.</li> <li>Push first node into priority queue and mark it as visited.</li> <li>Now, iterate till the priority queue is not empty.</li> <li>Pick the top item from priority queue and pop it. Now, iterate for all the nodes connected with it and insert them into priority queue in the order: {weight, child_node, pq_top_node}</li> <li>Once done, check if pq_top_node is not already visited, and then either insert into your MST vector answer (node, parent_node) or add to the sum of MST (add weight).</li> <li>Repeat from step 6.</li> </ol>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/02-prims-algorithm/#code","title":"Code","text":"<p>Codestudio Prims algorithm MST</p> <p>Codestudio Prim's algorithm MST</p> <pre><code>#include &lt;bits/stdc++.h&gt; \nvector&lt;pair&lt;pair&lt;int, int&gt;, int&gt;&gt; calculatePrimsMST(int n, int m, vector&lt;pair&lt;pair&lt;int, int&gt;, int&gt;&gt; &amp;g)\n{\n    // Write your code here.\n    int mst_sum = 0;\n    vector&lt;pair&lt;pair&lt;int, int&gt;, int&gt;&gt; ans;\n\n   vector&lt;pair&lt;int,int&gt;&gt; adj[n+1];\n    for(auto &amp;e:g){\n        int x =e.first.first, y=e.first.second, w = e.second;\n\n\n        adj[x].push_back({y, w});\n        adj[y].push_back({x, w});\n    }\n\n    bool visited[n+1]={false};\n\n    // max heap code\n    // priority_queue&lt;pair&lt;pair&lt;int,int&gt;,int&gt;&gt; pq; // weight, node, parent\n\n    // min heap code\n    priority_queue&lt;pair&lt;pair&lt;int,int&gt;,int&gt;, vector&lt;pair&lt;pair&lt;int,int&gt;,int&gt;&gt;, greater&lt;pair&lt;pair&lt;int,int&gt;,int&gt;&gt;&gt; pq;\n\n    pq.push({{1,1},-1});\n    visited[1]=true;\n\n    while(!pq.empty()){\n        auto node = pq.top();\n        pq.pop();\n\n        int weight = node.first.first;\n        int curr_node = node.first.second;\n        int parent_node=node.second;\n\n        for(auto&amp;e:adj[curr_node]){\n            if (visited[e.first] == false)\n                pq.push({{e.second, e.first}, curr_node});\n        }\n\n        if(visited[curr_node]==false){\n            visited[curr_node]=true;\n            ans.push_back({{curr_node,parent_node},weight});\n            mst_sum+=weight;\n        }\n    }\n\n    // or return mst_sum (depending on the problem statement)\n    return ans;\n}\n</code></pre>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/","title":"Disjoint Set (<code>Union By Rank | Union by Size</code>)","text":"<ul> <li>Disjoint Set data structure which is a <code>very important topic</code> in the entire graph series.</li> </ul> <p>Question: Given two components of an undirected graph</p> <p></p> <p>The question is whether node 1 and node 5 are in the same component or not.</p> <p>Approach:</p> <ul> <li> <p>Now, in order to solve this question we can use either the DFS or BFS traversal technique like if we traverse the components of the graph we can find that node 1 and node 5 are not in the same component. This is actually the brute force approach whose time complexity is O(N+E)(N = no. of nodes, E = no. of edges). </p> </li> <li> <p>But using a Disjoint Set data structure we can solve this same problem in <code>constant time</code>.</p> </li> </ul> <ul> <li>The disjoint Set data structure is generally used for dynamic graphs.</li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#dynamic-graphs","title":"Dynamic graphs","text":"<p>A dynamic graph generally refers to a graph that keeps on changing its configuration. Let\u2019s deep dive into it using an example:</p> <ul> <li> <p>Let\u2019s consider the edge information for the given graph as: {{1,2}, {2,3}, {4,5}, {6,7}, {5,6}, {3,7}}. Now if we start adding the edges one by one, in each step the structure of the graph will change. So, after each step, if we perform the same operation on the graph while updating the edges, the result might be different. In this case, the graph will be considered a dynamic graph.</p> </li> <li> <p>For example, after adding the first 4 edges if we look at the graph, we will find that node 4 and node 1 belong to different components but after adding all 6 edges if we search for the same we will figure out that node 4 and node 1 belong to the same component.</p> </li> </ul> <p></p> <ul> <li>So, after any step, if we try to figure out whether two arbitrary nodes u and v belong to the same component or not, Disjoint Set will be able to answer this query in constant time.</li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#functionalities-of-disjoint-set-data-structure","title":"Functionalities of Disjoint Set data structure","text":"<p>The disjoint set data structure generally provides two types of functionalities:</p> <ul> <li> <p>Finding the ultimate parent for a particular node (findPar())</p> </li> <li> <p>Union (in broad terms this method basically adds an edge between two nodes)</p> <ul> <li>Union by rank</li> <li>Union by size</li> </ul> </li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#rank","title":"Rank","text":"<p>The rank of a node generally refers to the distance (the number of nodes including the leaf node) between the furthest leaf node and the current node. Basically rank includes all the nodes beneath the current node.</p> <p></p>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#ultimate-parent","title":"Ultimate parent","text":"<p>The parent of a node generally refers to the node right above that particular node. But the ultimate parent refers to the topmost node or the root node.</p> <p></p>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#path-compression","title":"Path compression","text":"<p>Basically, connecting each node in a particular path to its ultimate parent refers to path compression. Let\u2019s understand it using the following illustration:</p> <p></p>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#algorithm","title":"Algorithm","text":"<p>Initial configuration</p> <p>rank array: This array is initialized with zero.</p> <p>parent array: The array is initialized with the value of nodes i.e. parent[i] = i.</p> <p>The algorithm steps</p> <ul> <li> <p>Firstly, the Union function requires two nodes(let\u2019s say u and v) as arguments. Then we will find the ultimate parent (using the findPar() function that is discussed later) of u and v. Let\u2019s consider the ultimate parent of u is pu and the ultimate parent of v is pv.</p> </li> <li> <p>After that, we will find the rank of pu and pv.</p> </li> <li> <p>Finally, we will connect the ultimate parent with a smaller rank to the other ultimate parent with a larger rank. But if the ranks are equal, we can connect any parent to the other parent and we will increase the rank by one for the parent node to whom we have connected the other one.</p> </li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#code","title":"Code","text":"<pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\nclass DisjointSet {\n    vector&lt;int&gt; rank, parent;\npublic:\n    DisjointSet(int n) {\n        rank.resize(n + 1, 0);\n        parent.resize(n + 1);\n\n        // initially, everyone is self-parent.\n        for (int i = 0; i &lt;= n; i++) {\n            parent[i] = i;\n        }\n    }\n\n    int findUPar(int node) {\n        if (node == parent[node])\n            return node;\n        return parent[node] = findUPar(parent[node]); // path compression\n    }\n\n    void unionByRank(int u, int v) {\n        int ulp_u = findUPar(u);\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (rank[ulp_u] &lt; rank[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n        }\n        else if (rank[ulp_v] &lt; rank[ulp_u]) {\n            parent[ulp_v] = ulp_u;\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            rank[ulp_u]++;\n        }\n    }\n};\nint main() {\n    DisjointSet ds(7);\n    ds.unionByRank(1, 2);\n    ds.unionByRank(2, 3);\n    ds.unionByRank(4, 5);\n    ds.unionByRank(6, 7);\n    ds.unionByRank(5, 6);\n    // if 3 and 7 same or not\n    if (ds.findUPar(3) == ds.findUPar(7)) {\n        cout &lt;&lt; \"Same\\n\";\n    }\n    else cout &lt;&lt; \"Not same\\n\";\n\n    ds.unionByRank(3, 7);\n\n    if (ds.findUPar(3) == ds.findUPar(7)) {\n        cout &lt;&lt; \"Same\\n\";\n    }\n    else cout &lt;&lt; \"Not same\\n\";\n    return 0;\n}\n</code></pre>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#time-complexity","title":"Time complexity \u23f2\ufe0f","text":"<p>The actual time complexity is O(4* alpha) which is very small and close to 1.</p> <ul> <li>So, we assume it to be of <code>constant time-complexity</code>.</li> <li>Exact derivation of the time-complexity is a very long &amp; tedious mathematical proof. So, don't worry!</li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#follow-up-in-the-union-by-rank-method-why-do-we-need-to-connect-the-smaller-rank-to-the-larger-rank","title":"Follow up: In the union by rank method, why do we need to connect the smaller rank to the larger rank? \ud83e\udd14","text":"<ul> <li>In this case, the traversal time to find the ultimate parent for nodes 3, 4, 5, 6, 7, and 8 increases and so the path compression time also increases. But if we do the following</li> </ul> <ul> <li>the traversal time to find the ultimate parent for only nodes 1 and 2 increases. So the path compression time becomes relatively lesser than in the previous case. So, we can conclude that we should always connect a smaller rank to a larger one with the goal of<ul> <li>shrinking the height of the graph.</li> <li>reducing the time complexity as much as we can.</li> </ul> </li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#disjoint-set-union-by-size","title":"Disjoint Set <code>Union by size</code>","text":"<p>Sorry, What was the meaning of Rank, again?</p> <p>After applying path compression the rank of the graphs becomes distorted. So, rather than storing the rank, we can just store the size of the components for comparing which component is greater or smaller.</p> <ul> <li>So, rather than storing the rank, we can just store the size of the components for comparing which component is greater or smaller.</li> </ul> <ul> <li>Algorithm is very same as <code>Union by Rank</code>, only the <code>Size</code> word is used, which indicates the size of each node.</li> <li>We will initialize size vector with 1, and unlike in rank when doing union, we will increment size by the size of node we are appending.</li> </ul> <pre><code>class DisjointSet {\n    vector&lt;int&gt; parent, size;\npublic:\n    DisjointSet(int n) {\n        parent.resize(n + 1); // (n+1) will handle both 0-bases &amp; 1-based indexing graph\n        size.resize(n + 1);\n        for (int i = 0; i &lt;= n; i++) {\n            parent[i] = i;\n            size[i] = 1;\n        }\n    }\n\n    int findUPar(int node) {\n        if (node == parent[node])\n            return node;\n        return parent[node] = findUPar(parent[node]); // path compression\n    }\n\n    void unionByRank(int u, int v) {\n        int ulp_u = findUPar(u);\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (rank[ulp_u] &lt; rank[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n        }\n        else if (rank[ulp_v] &lt; rank[ulp_u]) {\n            parent[ulp_v] = ulp_u;\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            rank[ulp_u]++;\n        }\n    }\n\n    void unionBySize(int u, int v) {\n        int ulp_u = findUPar(u);\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (size[ulp_u] &lt; size[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n            size[ulp_v] += size[ulp_u];\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            size[ulp_u] += size[ulp_v];\n        }\n    }\n};\n</code></pre>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/03-disjoint-set-union-by-rank-and-size/#code-to-be-copied-for-disjoint-set-by-rank","title":"Code to be copied for <code>Disjoint set by Rank</code> \u2705 \ud83d\udc48","text":"<pre><code>class DisjointSet {\n    vector&lt;int&gt; rank, parent;\npublic:\n    DisjointSet(int n) {\n        rank.resize(n + 1, 0);\n        parent.resize(n + 1);\n\n        // initially, everyone is self-parent.\n        for (int i = 0; i &lt;= n; i++) {\n            parent[i] = i;\n        }\n    }\n\n    int findUPar(int node) {\n        if (node == parent[node])\n            return node;\n        return parent[node] = findUPar(parent[node]); // path compression\n    }\n\n    void unionByRank(int u, int v) {\n        int ulp_u = findUPar(u);\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (rank[ulp_u] &lt; rank[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n        }\n        else if (rank[ulp_v] &lt; rank[ulp_u]) {\n            parent[ulp_v] = ulp_u;\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            rank[ulp_u]++;\n        }\n    }\n};\n</code></pre>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/04-kruskal-algorithm/","title":"Kruskal's algorithm (<code>Minimum spanning tree using Disjoint Set</code>)","text":"<ul> <li>To find <code>Minimum spanning tree (MST)</code> using Kruskal's algorithm, we use Disjoint Set.</li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/04-kruskal-algorithm/#important-point-regarding-disjoint-set","title":"Important point regarding <code>Disjoint Set</code>","text":"<p>Disjoint set provides two important functions:</p> <ul> <li>findUPar() =&gt; function helps to find the ultimate parent of a particular node</li> <li>Union =&gt; basically helps to add the edges between two nodes</li> </ul>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/04-kruskal-algorithm/#approach","title":"Approach","text":"<ul> <li> <p>First, we need to extract the edge information(if not given already) from the given adjacency list in the format of (wt, u, v) where u is the current node, v is the adjacent node and wt is the weight of the edge between node u and v and we will store the tuples in an array.</p> </li> <li> <p>Then the <code>array must be sorted in the ascending order of the weights</code> so that while iterating we can get the edges with the minimum weights first.</p> </li> <li> <p>After that, we will iterate over the edge information, and for each tuple, we will apply the  following operation:</p> </li> </ul> <p>algorithm: </p> <ul> <li>First, we will take the two nodes <code>u</code> and <code>v</code> from the tuple and check if the ultimate parents of both nodes are the same or not using the <code>findUPar()</code> function provided by the Disjoint Set data structure.</li> <li>If the ultimate parents are the same, we need not do anything to that edge as there already exists a path between the nodes and we will continue to the next tuple.</li> <li>If the ultimate parents are different, we will add the weight of the edge to our final answer(i.e. mstWt variable used in the following code) and apply the union operation(i.e. either <code>unionBySize(u, v)</code> or <code>unionByRank(u, v)</code>) with the nodes <code>u</code> and <code>v</code>. The union operation is also provided by the Disjoint Set.</li> </ul> <p>Finally, we will get our answer (in the mstWt variable as used in the following code) successfully.</p> <p></p>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/04-kruskal-algorithm/#code","title":"Code","text":"<pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\n\nclass DisjointSet {\n    vector&lt;int&gt; rank, parent;\npublic:\n    DisjointSet(int n) {\n        rank.resize(n, 0);\n        parent.resize(n);\n        for (int i = 0; i &lt; n; i++) {\n            parent[i] = i;\n        }\n    }\n\n    int findUPar(int node) {\n        if (node == parent[node])\n            return node;\n        return parent[node] = findUPar(parent[node]);\n    }\n\n    void unionByRank(int u, int v) {\n        int ulp_u = findUPar(u);\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (rank[ulp_u] &lt; rank[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n        }\n        else if (rank[ulp_v] &lt; rank[ulp_u]) {\n            parent[ulp_v] = ulp_u;\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            rank[ulp_u]++;\n        }\n    }\n};\n\nclass Solution\n{\npublic:\n    //Function to find sum of weights of edges of the Minimum Spanning Tree.\n    int spanningTree(int V, vector&lt;vector&lt;int&gt;&gt; adj[])\n    {\n        // 1 - 2 wt = 5\n        /// 1 - &gt; (2, 5)\n        // 2 -&gt; (1, 5)\n\n        // 5, 1, 2\n        // 5, 2, 1\n        vector&lt;pair&lt;int, pair&lt;int, int&gt;&gt;&gt; edges;\n        for (int i = 0; i &lt; V; i++) {\n            for (auto it : adj[i]) {\n                int adjNode = it[0];\n                int wt = it[1];\n                int node = i;\n\n                edges.push_back({wt, {node, adjNode}});\n            }\n        }\n        DisjointSet ds(V);\n        sort(edges.begin(), edges.end());\n\n        int mstWt = 0;\n        for (auto it : edges) {\n            int wt = it.first;\n            int u = it.second.first;\n            int v = it.second.second;\n\n            if (ds.findUPar(u) != ds.findUPar(v)) {\n                mstWt += wt;\n                ds.unionBySize(u, v);\n            }\n        }\n\n        return mstWt;\n    }\n};\n</code></pre>"},{"location":"04-dsa/01-graph/04-minimum-spanning-trees/04-kruskal-algorithm/#time-complexity","title":"Time complexity \u23f2\ufe0f","text":"<p>Time Complexity</p> <p>O(N+E) + O(E logE) + O(E*4\u03b1*2)   where N = no. of nodes and E = no. of edges. O(N+E) for extracting edge information from the adjacency list. O(E logE) for sorting the array consists of the edge tuples. Finally, we are using the disjoint set operations inside a loop. The loop will continue to E times. Inside that loop, there are two disjoint set operations like findUPar() and UnionBySize() each taking 4 and so it will result in 4*2. That is why the last term O(E*4*2) is added.</p> <p>Space Complexity</p> <p>O(N) + O(N) + O(E) where E = no. of edges and N = no. of nodes. O(E) space is taken by the array that we are using to store the edge information. And in the disjoint set data structure, we are using two N-sized arrays i.e. a parent and a size array (as we are using unionBySize() function otherwise, a rank array of the same size if unionByRank() is used) which result in the first two terms O(N).</p>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/01-kosaraju-algorithm/","title":"Strongly Connected Components (SCC) &amp; Kosaraju's algorithm","text":""},{"location":"04-dsa/01-graph/05-important-graph-algorithms/01-kosaraju-algorithm/#strongly-connected-components-scc","title":"Strongly connected components (SCC)","text":"<p>A component is called a Strongly Connected Component(SCC) only if for every possible pair of vertices (u, v) inside that component, u is reachable from v and v is reachable from u.</p> <p></p> <ul> <li> <p>By definition, a component containing a single vertex is always a strongly connected component. For that vertex 3 in the above graph is itself a strongly connected component.</p> </li> <li> <p>the above graph contains 4 strongly connected components like (0,1,2), (3), (4,5,6), and (7).</p> </li> </ul>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/01-kosaraju-algorithm/#kosarajus-algorithm-intuition","title":"Kosaraju's Algorithm intuition","text":"<ul> <li>SCC means, you can reach from any node within scc to any other in scc.</li> </ul> <ul> <li>If we do dfs traversal for a graph, it should be something like, moving from one scc to another scc.</li> </ul> <ul> <li> <p>By definition, within each SCC, every node is reachable. So, if we start DFS from a node of SCC1 we can visit all the nodes in SCC1 and via edge e1 we can reach SCC2. Similarly, we can travel from SCC2 to SCC3 via e2 and SCC3 to SCC4 via e3. Thus all the nodes of the graph become reachable.</p> </li> <li> <p>But if we reverse the edges e1, e2, and e3, the graph will look like the following:</p> </li> </ul> <p></p> <ul> <li> <p>After reversing all the edges, we will still be able to do dfs within SCC, as they are all strongly connected, but we can't go from one scc to another scc.</p> </li> <li> <p>Now in this graph, if we start DFS from node 0 it will visit only the nodes of SCC1. Similarly, if we start from node 3 it will visit only the nodes of SCC2. Thus, by reversing the SCC-connecting edges, the adjacent SCCs become unreachable. Now, the DFS will work in such a way, that in one DFS call we can only visit the nodes of a particular SCC. </p> </li> <li> <p>So, the number of DFS calls will represent the number of SCCs.</p> </li> <li> <p>One problem may arise if we don't have clue about starting node:</p> </li> </ul> <p>Now, the question might be like,</p> <p></p> <p>if node 0 is located in SCC4 and we start DFS from node 0, again we will visit all the SCCs at once even after reversing the edges. This is where the <code>starting time and the finishing time concept will come in</code>.</p>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/01-kosaraju-algorithm/#algorithm","title":"Algorithm","text":"<ul> <li>Sort all the nodes according to their finishing time:</li> </ul> <p>To sort all the nodes according to their finishing time, we will start <code>DFS from node 0</code> and while backtracking in the DFS call we will store the nodes in a stack data structure. The nodes in the last SCC will finish first and will be stored in the last of the stack. After the DFS gets completed for all the nodes, the stack will be storing all the nodes in the sorted order of their finishing time.</p> <ul> <li>Reverse all the edges of the entire graph:</li> </ul> <p>Now, we will create another adjacency list and store the information of the graph in a reversed manner.</p> <ul> <li>Perform the DFS and count the no. of different DFS calls to get the no. of SCC:</li> </ul> <p>Now, we will start DFS from the node which is on the top of the stack and continue until the stack becomes empty. For each individual DFS call, we will increment the counter variable by 1.</p> <p>We will <code>get the number of SCCs by just counting the number of individual DFS calls as in each individual DFS call</code>, all the nodes of a particular SCC get visited.</p> <ul> <li>Finally, we will get the number of SCCs in the counter variable. If we want to store the SCCs as well, we need to store the nodes in some array during each individual DFS call in step 3.</li> </ul>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/01-kosaraju-algorithm/#reiterate","title":"Reiterate","text":"<p>Steps</p> <ul> <li>The first step is to know, from which node we should start the DFS call.</li> <li>The second step is to make adjacent SCCs unreachable and to limit the DFS traversal in such a way, that in each DFS call, all the nodes of a particular SCC get visited.</li> <li>The third step is to get the numbers of the SCCs. In this step, we can also store the nodes of each SCC if we want to do so.</li> </ul> <p>Note</p> <p>The sorting of the nodes according to their finishing time is very important. By performing this step, we will get to know where we should start our DFS calls.</p> <ul> <li>The top-most element of the stack will finish last and it will surely belong to the SCC1. So, the sorting step is important for the algorithm.</li> </ul>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/01-kosaraju-algorithm/#code","title":"Code","text":"<p>GFG SCC Kosaraju's algorithm question link</p> <p>GFG SCC Kosaraju's algorithm question link</p> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\n\nclass Solution\n{\nprivate:\n    void dfs(int node, vector&lt;int&gt; &amp;vis, vector&lt;int&gt; adj[],\n             stack&lt;int&gt; &amp;st) {\n        vis[node] = 1;\n        for (auto it : adj[node]) {\n            if (!vis[it]) {\n                dfs(it, vis, adj, st);\n            }\n        }\n\n        st.push(node);\n    }\n\n    void dfs3(int node, vector&lt;int&gt; &amp;vis, vector&lt;int&gt; adjT[]) {\n        vis[node] = 1;\n        for (auto it : adjT[node]) {\n            if (!vis[it]) {\n                dfs3(it, vis, adjT);\n            }\n        }\n    }\npublic:\n    //Function to find number of strongly connected components in the graph.\n    int kosaraju(int V, vector&lt;int&gt; adj[])\n    {\n        vector&lt;int&gt; vis(V, 0);\n        stack&lt;int&gt; st;\n        for (int i = 0; i &lt; V; i++) {\n            if (!vis[i]) {\n                dfs(i, vis, adj, st);\n            }\n        }\n\n        vector&lt;int&gt; adjT[V];\n        for (int i = 0; i &lt; V; i++) {\n            vis[i] = 0;\n            for (auto it : adj[i]) {\n                // i -&gt; it\n                // it -&gt; i\n                adjT[it].push_back(i);\n            }\n        }\n        int scc = 0;\n        while (!st.empty()) {\n            int node = st.top();\n            st.pop();\n            if (!vis[node]) {\n                scc++;\n                dfs3(node, vis, adjT);\n            }\n        }\n        return scc;\n    }\n};\n</code></pre>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/01-kosaraju-algorithm/#time-space-complexity","title":"Time &amp; Space complexity","text":"<p>Time Complexity</p> <p>O(V+E) + O(V+E) + O(V+E) ~ O(V+E) , where V = no. of vertices, E = no. of edges. The first step is a simple DFS, so the first term is O(V+E).</p> <ul> <li>The second step of reversing the graph and the third step, containing DFS again, will take O(V+E) each.</li> </ul> <p>Space Complexity</p> <p>O(V)+O(V)+O(V+E), where V = no. of vertices, E = no. of edges. Two O(V) for the visited array and the stack we have used.</p> <ul> <li>O(V+E) space for the reversed adjacent list.</li> </ul>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/02-bridges-in-graph/","title":"Bridges in Graph (<code>Tarjan's algorithm</code>)","text":"<ul> <li>Any edge in a component of a graph is called a bridge when the component is divided into two or more components if we remove that particular edge.</li> </ul>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/02-bridges-in-graph/#approach","title":"Approach","text":"<ul> <li>We will create two arrays: <code>time_of_insertion</code> &amp; <code>lowest_time_of_insertion</code>.</li> </ul> <p>Time of insertion: Dring the DFS call, the time when a node is visited, is called its time of insertion.</p> <p>For example, if in a graph, we start DFS from node 1 it will visit node 1 first then node 2, node 3, node 4, and so on. So, the time of insertion for node 1 will be 1, node 2 will be 2, node 3 will be 3 and it will continue like this. </p> <p>Lowest time of insertion: In this case, the current node refers to all its adjacent nodes except the parent and takes the minimum lowest time of insertion into account, and updates its <code>minimum time</code>.</p> <ul> <li> <p>Now, if <code>lowest_time_of_insertion</code> of a child node is smaller than <code>time_of_insertion</code> of parent node, means, there exists a back-edge from child node to parent node's parents. So, the <code>child node</code> and <code>parent node</code> are not connected by a Bridge.</p> </li> <li> <p>Else, that connection edge is a Bridge.</p> </li> </ul> <p>Condition for the edge to be Bridge</p> <ul> <li>p &lt;= parent node</li> <li>u &lt;= child node</li> </ul> <pre><code>if (lowest_time_of_insertion[u] &gt; time_of_insertion[p]){\n    cout&lt;&lt;\"The connection is a bridge\"&lt;&lt;endl;\n}\n</code></pre>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/02-bridges-in-graph/#explanation-of-the-condition","title":"Explanation of the condition","text":"Why does the condition matters and how can one say so? <ul> <li>In case, a back-edge is present, then, lowest_time_of_insertion will be reduced, denoting we can reach it following another smaller path too. (Since, we're using DFS, so we have come depth, and not breadth.)</li> <li>Then, when we compare it with a node with some <code>time_of_insertion</code>, we check, if the <code>time to reach</code> node is greater than <code>lowest time to reach child node</code>. If it is, means, backedge was present. So, <code>no bridge</code>.</li> <li>Else, that edge connection is <code>bridge</code>.</li> </ul> <p>Note: </p> <p>We are not considering the parent\u2019s insertion time during calculating the lowest insertion time as we want to check if any other path from the node to the parent exists excluding the edge we intend to remove.</p>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/02-bridges-in-graph/#code","title":"Code","text":"<p>Leetcode Hard bridges in a graph question link</p> <p>Critical connections in a network</p> <pre><code>class Solution {\npublic:\n    void modified_dfs(int n, vector&lt;int&gt; adj[],\n        vector&lt;int&gt; &amp;time_of_insertion,\n        vector&lt;int&gt; &amp;lowest_time_of_insertion,\n        vector&lt;bool&gt; &amp;visited, int node, int parent, int &amp;counter, vector&lt;vector&lt;int&gt;&gt;&amp;ans){\n\n            visited[node]=true;\n            time_of_insertion[node] = counter;\n            lowest_time_of_insertion[node] = counter;\n            counter++;\n\n            for(auto&amp;e:adj[node]){\n                if(visited[e]==false){\n                    modified_dfs(\n                        n, adj,\n                        time_of_insertion,\n                        lowest_time_of_insertion,\n                        visited, e, node, counter,ans\n                    );\n                    // update lowest_time_of_insertion\n                    lowest_time_of_insertion[node]=min(lowest_time_of_insertion[node],lowest_time_of_insertion[e]);\n                    // bridge condition\n                    if(lowest_time_of_insertion[e] &gt; time_of_insertion[node]){\n                        ans.push_back({node, e});\n                    }\n                }\n                else if(e!=parent){\n                    // if e- visited, but not parent; means `backedge`\n                    // update lowest_time_of_insertion\n                    lowest_time_of_insertion[node]=min(lowest_time_of_insertion[node],lowest_time_of_insertion[e]);\n                    // // bridge condition\n                    if(lowest_time_of_insertion[e] &gt; time_of_insertion[node]){\n                        ans.push_back({node, e});\n                    }\n                }     \n            }\n\n    }\n\n    vector&lt;vector&lt;int&gt;&gt; criticalConnections(int n, vector&lt;vector&lt;int&gt;&gt;&amp; connections) {\n        vector&lt;int&gt; time_of_insertion(n,-1), lowest_time_of_insertion(n,-1);\n\n        vector&lt;bool&gt; visited(n,false);\n        vector&lt;vector&lt;int&gt;&gt; ans;\n\n        vector&lt;int&gt; adj[n];\n        for(auto&amp;e:connections){\n            int x = e[0], y = e[1];\n            adj[x].push_back(y);\n            adj[y].push_back(x);\n        }\n\n        int counter = 0;\n        int node = 0, parent = -1;\n        modified_dfs(\n                        n, adj,\n                        time_of_insertion,\n                        lowest_time_of_insertion,\n                        visited, node, parent, counter,ans\n                    );\n\n        return ans;\n    }\n};\n</code></pre>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/02-bridges-in-graph/#time-space-complexity","title":"Time &amp; Space complexity","text":"<p>Time complexity</p> <p>O(V+2E), where V = no. of vertices, E = no. of edges. It is because the algorithm is just a simple DFS traversal.</p> <p>Space complexity</p> <p>O(V+2E) + O(3V), where V = no. of vertices, E = no. of edges. O(V+2E) to store the graph in an adjacency list and O(3V) for the three arrays i.e. tin, low, and vis, each of size V.</p>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/03-articulation-point-in-graph/","title":"Articulation point in Graph","text":"<ul> <li>Articulation Points of a graph are the nodes on whose removal, the graph breaks into multiple components. </li> </ul>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/03-articulation-point-in-graph/#video-link","title":"Video link","text":"<p>Striver video link for articulation point</p> <p>Striver video: Articulation Point</p>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/03-articulation-point-in-graph/#approach","title":"Approach","text":"<ul> <li>Approach to find <code>Articulation point</code> is similar to <code>Bridges in graph</code>.</li> <li>We will have a vector <code>time_inserted</code>, similar to <code>bridges in graph</code>.</li> <li>Another vector <code>lowest_node_it_can_reach</code>, that stores the lowest node a node can reach.</li> <li>Once dfs traversal is done for a node's all adjacent nodes, we update <code>lowest_node_it_can_reach</code> for the node to be minimum of its current value &amp; value of all adjacent nodes.</li> <li>For a node to be articulation point, if <code>time_inserted[node] &lt;= lowest_node_it_can_reach[child_node]</code>. It means, child_node couldn't reach someone in the prior of the node.</li> <li>The above algorithm is valid only for non-root nodes.</li> <li>For the root node with parent (-1), we simply need to count <code>number of independent (non-visited) children</code>. If multiple nodes are connected, they all will be traversed in DFS.</li> </ul>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/03-articulation-point-in-graph/#tip","title":"Tip","text":"<ul> <li>Same node can be articulation point for multiple DFS traversals.</li> <li>So, better to use <code>set</code> for storing all the articulation points.</li> </ul> <ul> <li>While checking for node 2, we will get the node as the articulation point once for the first component that contains nodes 4, 5, and 6 and we will again get the same node 2 for the second component that includes the nodes 7, 8, and 9.</li> </ul>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/03-articulation-point-in-graph/#code","title":"Code","text":"<p>GFG Articulation Point in a graph question link</p> <p>Articulation Point</p> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\n//User function Template for C++\n\nclass Solution {\nprivate:\n    void dfs(int node, int parent, vector&lt;int&gt; &amp;vis, int tin[], int low[],\n             vector&lt;int&gt; &amp;mark, vector&lt;int&gt;adj[], int timer) {\n        vis[node] = 1;\n        tin[node] = low[node] = timer;\n        timer++;\n        int child = 0;\n        for (auto it : adj[node]) {\n            if (it == parent) continue;\n            if (!vis[it]) {\n                dfs(it, node, vis, tin, low, mark, adj, timer);\n                low[node] = min(low[node], low[it]);\n                if (low[it] &gt;= tin[node] &amp;&amp; parent != -1) {\n                    mark[node] = 1;\n                }\n                child++;\n            }\n            else {\n                // if already visited, then, low = the node number\n                // unlike, `bridge in graph`, we're not doing: low[node] = min(low[node], low[it]);\n                low[node] = min(low[node], tin[it]);\n            }\n        }\n        if (child &gt; 1 &amp;&amp; parent == -1) {\n            mark[node] = 1;\n        }\n    }\npublic:\n    vector&lt;int&gt; articulationPoints(int n, vector&lt;int&gt;adj[]) {\n        vector&lt;int&gt; vis(n, 0);\n        int tin[n]; // time_inserted\n        int low[n]; // lowest node it can reach\n        vector&lt;int&gt; mark(n, 0);\n        int timer = 1;\n\n        for (int i = 0; i &lt; n; i++) {\n            if (!vis[i]) {\n                dfs(i, -1, vis, tin, low, mark, adj, timer);\n            }\n        }\n        vector&lt;int&gt; ans;\n        for (int i = 0; i &lt; n; i++) {\n            if (mark[i] == 1) {\n                ans.push_back(i);\n            }\n        }\n        if (ans.size() == 0) return { -1};\n        return ans;\n    }\n};\n</code></pre>"},{"location":"04-dsa/01-graph/05-important-graph-algorithms/03-articulation-point-in-graph/#time-space-complexity","title":"Time &amp; Space complexity","text":"<p>Time complexity</p> <p>O(V+2E), where V = no. of vertices, E = no. of edges. It is because the algorithm is just a simple DFS traversal.</p> <p>Space complexity</p> <p>O(3V), where V = no. of vertices. O(3V) is for the three arrays i.e. tin, low, and vis, each of size V.</p>"},{"location":"04-dsa/02-dp/","title":"Dynamic Programming","text":""},{"location":"04-dsa/02-dp/#contents","title":"Contents","text":""},{"location":"04-dsa/02-dp/introduction/","title":"Introduction to Dynamic Programming","text":"<p>Dynamic Programming's quote</p> <p>Those who can't remember their past, are condemned to repeat it.</p> <ul> <li>Dynamic Programming can be described as storing answers to various sub-problems to be used later whenever required to solve the main problem.</li> </ul>"},{"location":"04-dsa/02-dp/introduction/#two-approaches-to-solve-dp","title":"Two approaches to solve DP","text":"<p>The two common dynamic programming approaches are:</p> <ul> <li> <p>Memoization:</p> <ul> <li><code>top-down</code></li> <li>typically, recursive</li> <li><code>start from solving main problem, that requires base case to be solved, and then we come back to the main problem to solve it. (Top-Bottom-Top)</code></li> <li><code>slow due to lots of recursive calls</code></li> <li><code>the lookup table is filled on demand</code></li> <li><code>performs better if some time-consuming sub-problems in the subproblem space are not needed to be solved at all for the main problem</code></li> </ul> </li> <li> <p>Tabulation:</p> <ul> <li><code>bottom-up</code></li> <li>typically, iterative</li> <li><code>Start from solving base case, and then gradually move towards the main problem to be solved.</code></li> <li><code>more efficient</code> as we directly access previous state</li> <li>may calculate solution for the states, which are not even required by the main problem</li> <li>harder to think solution, but since more efficient, plus, no recursive calls, gives upper edge in interview.</li> </ul> </li> </ul> <p>Note</p> <p>The base case does not always mean smaller input. It depends upon the implementation of the algorithm.</p>"},{"location":"04-dsa/02-dp/introduction/#comparison-table","title":"Comparison table","text":""},{"location":"04-dsa/02-dp/introduction/#approach-in-dp","title":"Approach in DP \ud83e\udee8","text":""},{"location":"04-dsa/02-dp/introduction/#fibonacci-problem","title":"Fibonacci problem","text":"<p>Fibonacci problem statement</p> <p>We need to find the nth Fibonacci number, where n is based on a 0-based index.</p> <p>Every ith number of the series is equal to the sum of (i-1)th and (i-2)th number where the first and second number is given as 0 and 1 respectively.</p> <p>f(0) = 0, f(1) = 1, f(2) = 1, f(3) = 2, etc.</p>"},{"location":"04-dsa/02-dp/introduction/#simple-recursive-method","title":"Simple recursive method","text":"<ul> <li>time complexity: O(2^n)<ul> <li>exponential time complexity. This is because each node in the recursion tree splits into two subbranches</li> </ul> </li> <li>space complexity: O(1)</li> </ul> <pre><code>int my_fib(int n){\n    // base case: f(0)=0, f(1)=1\n    if(n&lt;2)\n        return n;\n\n    return my_fib(n - 1) + my_fib(n - 2);\n}\n</code></pre>"},{"location":"04-dsa/02-dp/introduction/#memoization-method","title":"Memoization method","text":"<ul> <li>time complexity: O(n)</li> <li>space complexity: O(2*n) // dp-array + recursive stack</li> </ul> <pre><code>int my_memoization(int n, vector&lt;int&gt;&amp;dp){\n    // base case: f(0)=0, f(1)=1\n    if (n &lt; 2)\n        return n;\n\n    if (dp[n] != -1)\n        return dp[n];\n\n    return dp[n] = my_memoization(n - 1, dp) + my_memoization(n - 2, dp);\n}\n\nint my_fib(int n){\n    vector&lt;int&gt; dp(n + 1, -1);\n    return my_memoization(n, dp);\n}\n</code></pre>"},{"location":"04-dsa/02-dp/introduction/#tabulation-method","title":"Tabulation method","text":"<ul> <li>time complexity: O(n)</li> <li>space complexity: O(n)</li> </ul> <pre><code>int my_fib(int n){\n    if(n&lt;2)\n        return n;\n\n    vector&lt;int&gt; dp(n + 1, -1);\n\n    dp[0] = 0;\n    dp[1] = 1;\n\n    for (int i = 2; i &lt;= n;i++){\n        dp[i] = dp[i - 1] + dp[i - 2];\n    }\n        return dp[n];\n}\n</code></pre>"},{"location":"04-dsa/02-dp/introduction/#tabulation-method-with-space-optimization","title":"Tabulation method with space optimization","text":"<ul> <li>time complexity: O(n)</li> <li>space complexity: O(1)</li> <li><code>we don't need the whole dp-array, we only need: *last* &amp; *second-last*</code></li> </ul> <pre><code>int my_fib(int n)\n{\n    if (n &lt; 2)\n        return n;\n\n    int ans;\n    int last = 1, second_last = 0;\n\n    for (int i = 2; i &lt;= n; i++)\n    {\n        ans = last + second_last;\n        second_last = last;\n        last = ans;\n    }\n    return ans;\n}\n</code></pre>"},{"location":"04-dsa/03-intermediate-data-structures/01-linked-list/01-introduction/","title":"Linked List","text":""},{"location":"04-dsa/03-intermediate-data-structures/02-stack/01-introduction/","title":"Stack","text":""},{"location":"04-dsa/03-intermediate-data-structures/03-queue/01-introduction/","title":"Queue","text":""},{"location":"04-dsa/03-intermediate-data-structures/04-sliding-window-and-two-pointer/01-introduction/","title":"Sliding window &amp; Two pointers","text":""},{"location":"04-dsa/03-intermediate-data-structures/05-heap/01-introduction/","title":"Heap (Priority Queue)","text":""},{"location":"04-dsa/04-trees/","title":"Trees","text":""},{"location":"04-dsa/04-trees/#contents","title":"Contents","text":""},{"location":"04-dsa/04-trees/01-binary-tree/01-introduction/","title":"Binary tree introduction","text":""},{"location":"04-dsa/04-trees/01-binary-tree/01-introduction/#what-is-binary-tree","title":"What is Binary Tree?","text":"<ul> <li>a non-linear data structure in which each node can have at most two children: <ul> <li>left child and the right child.</li> </ul> </li> </ul>"},{"location":"04-dsa/04-trees/01-binary-tree/01-introduction/#types-of-binary-tree","title":"Types of Binary Tree","text":"<ol> <li> <p>Full Binary Tree</p> <ul> <li>A full binary tree is a binary tree with either zero or two child nodes for each node.</li> </ul> </li> <li> <p>Complete Binary Tree</p> <ul> <li>A complete binary tree is a special type of binary tree where all the levels of the tree are filled completely except the lowest level nodes which are filled from as left as possible.</li> </ul> </li> <li> <p>Perfect Binary Tree</p> <ul> <li>All leaf nodes are at the same depth. In a perfect binary tree, all leaf nodes are at the maximum depth of the tree. This means that the tree is completely filled with no gaps.</li> </ul> </li> <li> <p>Balanced Binary Tree</p> <ul> <li>A binary tree is balanced if the height of the tree is O(Log n) where n is the number of nodes.</li> </ul> </li> </ol> <p></p>"},{"location":"04-dsa/04-trees/01-binary-tree/01-introduction/#representation-of-binary-tree","title":"Representation of Binary Tree","text":"<p>Each node in a Binary Tree has three parts:</p> <ul> <li>Data</li> <li>Pointer to the left child</li> <li>Pointer to the right child</li> </ul> <p> </p>"},{"location":"04-dsa/04-trees/01-binary-tree/01-introduction/#implementing-binary-tree","title":"Implementing Binary Tree","text":"<pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass Node{\n\n    public:\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x){\n        this -&gt;data = x;\n        this -&gt;left = NULL;\n        this -&gt;right = NULL;\n    }\n};\n\nNode* Construct_tree(vector&lt;int&gt; arr){\n\n    if(arr.empty()){\n        return NULL;\n    }\n\n    queue&lt;Node*&gt; q;\n    int index = 1;\n\n    Node* root = new Node(arr[0]);\n    q.push(root);\n\n    while(!q.empty()){\n\n        Node* t = q.front();\n        q.pop();\n\n        if(index &lt; arr.size() &amp;&amp; arr[index] != -1){\n            Node* ln = new Node(arr[index]);\n            t -&gt;left = ln;\n            q.push(t -&gt;left);\n        }\n        index++;\n\n        if(index &lt; arr.size() &amp;&amp; arr[index] != -1){\n            Node* rn = new Node(arr[index]);\n            t -&gt;right = rn;\n            q.push(t -&gt;right);\n        }\n        index++;\n    }\n\n    return root;\n}\n\nvoid display(Node* root){\n\n    if(root == NULL){\n        return;\n    }\n\n    string str = \"\";\n    str += root -&gt;left == NULL ? \".\" : to_string(root -&gt;left -&gt;data) + \"\";\n    str += \"&lt;--\" + to_string(root -&gt;data) + \"--&gt;\";\n    str += root -&gt;right == NULL ? \".\" : to_string(root -&gt;right -&gt;data) + \"\";\n\n    cout&lt;&lt;str&lt;&lt;endl;\n\n    display(root -&gt;left);\n    display(root -&gt;right);\n}\n\n\nint main(){\n\n    vector&lt;int&gt; arr = {50, 25, 75, 12, 37, 62, 87, -1, -1, 30, -1, -1, 70, -1, -1};\n\n    Node* root = Construct_tree(arr);\n    display(root);\n\n    cout&lt;&lt;endl;\n\n}\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/02-traversals/","title":"Traversals in Binary Tree","text":""},{"location":"04-dsa/04-trees/01-binary-tree/02-traversals/#depth-first-search-dfs","title":"Depth-first Search (DFS)","text":"<ul> <li>Pre-order traversal</li> <li>In-order traversal</li> <li>Post-order traversal</li> </ul> pre-orderIn-orderPost-order <pre><code>// pre-order: root, left, right\n\nvoid preOrder(Node* node){\n    if (node == NULL){\n        return;\n    }\n\n    cout &lt;&lt; node-&gt;data &lt;&lt; \" \";\n    preOrder(node-&gt;left);\n    preOrder(node-&gt;right);\n}\n</code></pre> <pre><code>// in-order: left, root, right\n\nvoid inOrder(Node* node){\n    if (node == NULL){\n        return;\n    }\n\n    inOrder(node-&gt;left);\n    cout &lt;&lt; node-&gt;data &lt;&lt; \" \";\n    inOrder(node-&gt;right);\n}\n</code></pre> <pre><code>// post-order: left, right, root\n\nvoid postorder(Node* node){\n    if (node == NULL){\n        return;\n    }\n\n    postorder(node-&gt;left);\n    postorder(node-&gt;right);\n    cout &lt;&lt; node-&gt;data &lt;&lt; \" \";\n}\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/02-traversals/#breadth-first-search-bfs","title":"Breadth-first Search (BFS)","text":"<ul> <li>Level-order traversal</li> </ul> Level-order <pre><code>// level-order: root, left, right\n\nvoid levelOrder(Node* node){\n    if (node == NULL){\n        return;\n    }\n\n    queue&lt;Node*&gt; q;\n    q.push(node);\n\n    while (!q.empty()){\n        Node* t = q.front();\n        q.pop();\n\n        cout &lt;&lt; t-&gt;data &lt;&lt; \" \";\n\n        if (t-&gt;left != NULL){\n            q.push(t-&gt;left);\n        }\n        if (t-&gt;right != NULL){\n            q.push(t-&gt;right);\n        }\n    }\n}\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/02-traversals/#iterative-traversal","title":"Iterative traversal","text":""},{"location":"04-dsa/04-trees/01-binary-tree/02-traversals/#pre-order-iterative-code","title":"pre-order iterative code","text":"<pre><code>void preOrderIterative(Node* node){\n    if (node == NULL){\n        return;\n    }\n\n    stack&lt;Node*&gt; s;\n    s.push(node);\n\n    while (!s.empty()){\n        Node* t = s.top();\n        s.pop();\n\n        cout &lt;&lt; t-&gt;data &lt;&lt; \" \";\n\n        if (t-&gt;right != NULL){\n            s.push(t-&gt;right);\n        }\n\n        if (t-&gt;left != NULL){\n            s.push(t-&gt;left);\n        }\n    }\n}\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/02-traversals/#in-order-iterative-code","title":"in-order iterative code","text":""},{"location":"04-dsa/04-trees/01-binary-tree/02-traversals/#post-order-iterative-with-2-stacks","title":"post-order iterative (with 2 stacks)","text":""},{"location":"04-dsa/04-trees/01-binary-tree/02-traversals/#post-order-iterative-with-2-stacks_1","title":"post-order iterative (with 2 stacks)","text":""},{"location":"04-dsa/04-trees/01-binary-tree/02-traversals/#pre-order-in-order-post-order-in-one-traversal","title":"Pre-order, In-order, Post-order in one traversal","text":""},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/","title":"Medium Problems related to Binary Tree","text":""},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#height-of-a-binary-tree","title":"Height of a Binary Tree","text":"<ul> <li>https://leetcode.com/problems/maximum-depth-of-binary-tree/</li> </ul> <pre><code>class Solution {\npublic:\n    int maxDepth(TreeNode* root) {\n        if(root==NULL)return 0;\n        return max(maxDepth(root-&gt;left), maxDepth(root-&gt;right))+1;\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#check-if-a-binary-tree-is-height-balanced","title":"Check if a Binary Tree is height-balanced","text":"<ul> <li>https://leetcode.com/problems/balanced-binary-tree/description/</li> </ul> <pre><code>class Solution {\n    int depth(TreeNode* root){\n        if(root==NULL)return 0;\n        int l = depth(root-&gt;left);\n        int r = depth(root-&gt;right);\n\n        if(l==-1 || r==-1){\n            return -1; // we already know tree is not height-balanced\n        }\n\n        if(abs(l-r)&gt;1)return -1;\n\n        return max(l,r) + 1;\n    }\npublic:\n    bool isBalanced(TreeNode* root) {\n        int val = depth(root);\n        return val!=-1;\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#diameter-of-a-binary-tree","title":"Diameter of a Binary Tree","text":"<ul> <li>https://leetcode.com/problems/diameter-of-binary-tree/</li> </ul> <pre><code>class Solution {\n    int depth(TreeNode*root, int* ans){\n        if(root==NULL)return 0;\n        int l = depth(root-&gt;left, ans);\n        int r = depth(root-&gt;right, ans);\n\n        *ans = max(*ans, l+r);\n\n        return max(l,r)+1;\n    }\npublic:\n    int diameterOfBinaryTree(TreeNode* root) {\n        int ans = 0;\n        depth(root, &amp;ans);\n        return ans;\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#maximum-path-sum-in-a-binary-tree","title":"Maximum path sum in a Binary Tree","text":""},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#check-if-two-binary-trees-are-identical","title":"Check if two Binary Trees are identical","text":"<ul> <li>https://leetcode.com/problems/same-tree/</li> </ul> <pre><code>class Solution {\npublic:\n    bool isSameTree(TreeNode* p, TreeNode* q) {\n        if(p==NULL &amp;&amp; q==NULL)return true;\n        if(p==NULL || q==NULL)return false;\n\n        if(p-&gt;val != q-&gt;val)return false;\n\n        bool l = isSameTree(p-&gt;left, q-&gt;left);\n        bool r = isSameTree(p-&gt;right, q-&gt;right);\n\n        return l &amp;&amp; r;\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#zig-zag-traversal","title":"Zig-Zag traversal","text":"<ul> <li>https://leetcode.com/problems/binary-tree-zigzag-level-order-traversal/</li> </ul> <pre><code>class Solution {\npublic:\n    vector&lt;vector&lt;int&gt;&gt; zigzagLevelOrder(TreeNode* root) {\n        vector&lt;vector&lt;int&gt;&gt; ans;\n        if(root==NULL)return ans;\n\n        queue&lt;TreeNode*&gt;q;\n        q.push(root);\n\n        int level = 1;\n        int levelLength = q.size();\n\n        vector&lt;int&gt; v;\n\n        while(!q.empty()){\n            TreeNode* tmp = q.front();\n            v.push_back(tmp-&gt;val);\n            if(tmp-&gt;left)q.push(tmp-&gt;left);\n            if(tmp-&gt;right)q.push(tmp-&gt;right);\n            q.pop();\n            levelLength--;\n\n            if(levelLength==0){\n                if(level%2){\n                    // odd =&gt; left to right\n                    ans.push_back(v);\n                }\n                else{\n                    // even =&gt; right to left\n                    reverse(v.begin(), v.end());\n                    ans.push_back(v);\n                }\n                v.clear();\n\n                level++;\n                levelLength = q.size();\n            }\n\n        }\n        return ans;\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#boundary-traversal","title":"Boundary traversal","text":""},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#vertical-order-traversal","title":"Vertical order traversal","text":"<ul> <li>https://leetcode.com/problems/vertical-order-traversal-of-a-binary-tree/description/</li> </ul> <pre><code>class Solution {\n    void solver(TreeNode* root, int h, int v, map&lt;int, map&lt;int, vector&lt;int&gt;&gt;&gt;*mp){\n        if(root==NULL)return;\n        (*mp)[h][v].push_back(root-&gt;val);\n        solver(root-&gt;left, h-1, v+1, mp);\n        solver(root-&gt;right, h+1, v+1, mp);\n    }\npublic:\n    vector&lt;vector&lt;int&gt;&gt; verticalTraversal(TreeNode* root) {\n        map&lt;int, map&lt;int, vector&lt;int&gt;&gt;&gt;mp; // horizontal, vertical, values\n        solver(root, 0, 0, &amp;mp);\n\n        vector&lt;vector&lt;int&gt;&gt; ans;\n        for(auto &amp;e:mp){\n            vector&lt;int&gt; v;\n            for(auto &amp;f:e.second){\n                sort(f.second.begin(), f.second.end());\n                for(auto&amp;z:f.second)v.push_back(z);\n            }\n            ans.push_back(v);\n        }\n\n        return ans;\n\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#top-view-of-a-binary-tree","title":"Top-view of a Binary Tree","text":"<ul> <li>https://www.geeksforgeeks.org/problems/top-view-of-binary-tree/1</li> </ul> <pre><code>class Solution\n{\n    void solver(Node* root, int x, int y, map&lt;int,pair&lt;int,int&gt;&gt; *mp){\n        if(root==NULL)return;\n\n        if(((*mp).find(x)==(*mp).end()) || (*mp)[x].second &gt; y)\n            (*mp)[x]={root-&gt;data, y};\n\n        solver(root-&gt;left, x-1, y+1, mp);\n        solver(root-&gt;right, x+1, y+1, mp);\n    }\n    public:\n    //Function to return a list of nodes visible from the top view \n    //from left to right in Binary Tree.\n    vector&lt;int&gt; topView(Node *root)\n    {\n        //Your code here\n        map&lt;int,pair&lt;int,int&gt;&gt; mp; // mp[x]={val, y}\n        solver(root, 0, 0, &amp;mp);\n        vector&lt;int&gt; ans;\n        for(auto &amp;e: mp)\n            ans.push_back(e.second.first);\n        return ans;\n    }\n\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#bottom-view-of-a-binary-tree","title":"Bottom-view of a Binary Tree","text":"<ul> <li>https://www.geeksforgeeks.org/problems/bottom-view-of-binary-tree/1</li> </ul> <pre><code>class Solution {\n\n    void solver(Node*root, int x, int y, map&lt;int, pair&lt;int,int&gt;&gt;*mp){\n        if(root==NULL)return;\n        // inorder traversal, so rightmost will come at end\n        solver(root-&gt;left, x-1, y+1, mp);\n\n        // '=' to account for same (x,y) node and bcoz of inorder traversal, rightmost will come at end\n        if(((*mp).find(x)==(*mp).end()) || (*mp)[x].second &lt;= y) \n            (*mp)[x]={root-&gt;data, y};\n\n        solver(root-&gt;right, x+1, y+1, mp);\n    }\n\n  public:\n    vector &lt;int&gt; bottomView(Node *root) {\n        // Your Code Here\n        map&lt;int,pair&lt;int,int&gt;&gt;mp; // mp[x]={val, y}\n        solver(root, 0, 0, &amp;mp);\n\n        vector&lt;int&gt; ans;\n\n        for(auto &amp;e:mp){\n            ans.push_back(e.second.first);\n        }\n        return ans;\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#leftright-view-of-a-binary-tree","title":"Left/right-view of a Binary Tree","text":"<ul> <li>https://leetcode.com/problems/binary-tree-right-side-view/description/</li> </ul> <pre><code>class Solution {\n    vector&lt;int&gt; levelOrderTraversal(TreeNode* root){\n        vector&lt;int&gt; ans;\n        if(root==NULL)return ans;\n        queue&lt;TreeNode*&gt; q;\n\n        q.push(root);\n\n        while(!q.empty()){\n            ans.push_back(q.back()-&gt;val);\n\n            int N = q.size();\n            for(int i=0;i&lt;N;i++){\n                TreeNode* currNode = q.front();\n                q.pop();\n\n                if(currNode-&gt;left)q.push(currNode-&gt;left);\n                if(currNode-&gt;right)q.push(currNode-&gt;right);\n            }\n        }\n\n        return ans;\n    }\npublic:\n    vector&lt;int&gt; rightSideView(TreeNode* root) {\n        // do level-wise traversal and insert the last element of each level\n        return levelOrderTraversal(root);\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/03-medium-problems/#symmetric-binary-tree","title":"Symmetric Binary Tree","text":"<ul> <li> <p>https://leetcode.com/problems/symmetric-tree/description/</p> </li> <li> <p>We can also do this by checking if level order traversal array is same as reversed level order traversal array. But, not so straightforward. We've to account for null nodes.</p> </li> </ul> <pre><code>class Solution {\n    bool isHelper(TreeNode* left, TreeNode* right){\n        if(left==NULL &amp;&amp; right==NULL)return true;\n        if(left==NULL || right==NULL)return false;\n\n        if(left-&gt;val != right-&gt;val)return false;\n        return isHelper(left-&gt;left, right-&gt;right) &amp;&amp; isHelper(left-&gt;right, right-&gt;left);\n\n    }\n\npublic:\n    bool isSymmetric(TreeNode* root) {\n        if(root==NULL)return true;\n        return isHelper(root-&gt;left, root-&gt;right);\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/04-hard-problems/","title":"Hard Problems related to Binary Tree","text":""},{"location":"04-dsa/04-trees/01-binary-tree/04-hard-problems/#lowest-common-ancestor-lca-in-a-binary-tree","title":"Lowest Common Ancestor (LCA) in a Binary Tree","text":"<ul> <li>https://leetcode.com/problems/lowest-common-ancestor-of-a-binary-tree/description/</li> </ul> <pre><code>class Solution {\npublic:\n    TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) {\n        if(root==NULL || root==p || root==q)return root;\n\n        TreeNode* left = lowestCommonAncestor(root-&gt;left, p, q);\n\n        TreeNode* right = lowestCommonAncestor(root-&gt;right, p, q);\n\n        if(left!=NULL &amp;&amp; right!=NULL){\n            // both left and right has values\n            // means, current node is LCA\n            return root;\n        }\n        else if(left!=NULL){\n            return left;\n        }\n        return right; // could be a node, or null (both valid)\n\n    }\n};\n</code></pre>"},{"location":"04-dsa/04-trees/01-binary-tree/04-hard-problems/#root-to-leaf-paths","title":"Root to Leaf Paths","text":"<ul> <li>https://www.geeksforgeeks.org/problems/root-to-leaf-paths/1</li> </ul> <pre><code>class Solution {\n    void solver(Node*root, vector&lt;vector&lt;int&gt;&gt; &amp;ans, vector&lt;int&gt; currPath){\n        if(root==NULL){\n            return;\n        }\n\n        currPath.push_back(root-&gt;data);\n        if(root-&gt;left)solver(root-&gt;left, ans, currPath);\n        if(root-&gt;right)solver(root-&gt;right, ans, currPath);\n\n        if(root-&gt;left==NULL &amp;&amp; root-&gt;right==NULL)\n            ans.push_back(currPath);\n    }\n  public:\n    vector&lt;vector&lt;int&gt;&gt; Paths(Node* root) {\n        // code here\n        vector&lt;vector&lt;int&gt;&gt; ans;\n        vector&lt;int&gt; currPath;\n        solver(root, ans, currPath);\n        return ans;\n    }\n};\n</code></pre>"},{"location":"04-dsa/05-segment-and-fenwick-tree/","title":"Segment Tree &amp; Fenwick Tree","text":""},{"location":"05-design-patterns/","title":"Design Patterns","text":"<p>Design Patterns</p> <p>Design patterns are typical solutions to common problems in software design.</p> <ul> <li>Each pattern is like a blueprint</li> <li>that you can customize to solve a particular design problem in your code.</li> </ul> <p></p>"},{"location":"05-design-patterns/01-classification-of-design-patterns/","title":"Classification of Design Patterns","text":""},{"location":"05-design-patterns/01-classification-of-design-patterns/#different-design-patterns","title":"Different design patterns","text":""},{"location":"05-design-patterns/design-pattern-index/","title":"Design Patterns Concepts &amp; Examples","text":""},{"location":"05-design-patterns/design-pattern-index/#creational-patterns","title":"Creational Patterns","text":"<ol> <li>Singleton design pattern</li> <li>Builder design pattern</li> <li>Factory design pattern</li> <li>Abstract Factory design pattern</li> <li>Prototype design pattern</li> </ol>"},{"location":"05-design-patterns/design-pattern-index/#structural-patterns","title":"Structural Patterns","text":"<ol> <li>Adapter design pattern</li> <li>Bridge design pattern</li> <li>Composite design pattern</li> <li>Decorator design pattern</li> <li>Facade design pattern</li> <li>Flyweight design pattern</li> <li>Proxy design pattern</li> </ol>"},{"location":"05-design-patterns/design-pattern-index/#behavioral-patterns","title":"Behavioral Patterns","text":"<ol> <li>Chain of Responsibility design pattern</li> <li>Command design pattern</li> <li>Iterator design pattern</li> <li>Mediator design pattern</li> <li>Memento design pattern</li> <li>Observer design pattern</li> <li>State design pattern</li> <li>Strategy design pattern</li> <li>Template Method design pattern</li> <li>Visitor design pattern</li> </ol>"},{"location":"05-design-patterns/introduction/","title":"What's a design pattern?","text":"<p>Design patterns</p>"},{"location":"05-design-patterns/introduction/#design-patterns","title":"Design Patterns","text":"<ul> <li>Design patterns are typical solutions to commonly occurring problems in software design.</li> <li>They are like pre-made blueprints that you can customize to solve a recurring design problem in your code.</li> </ul> <p>You can\u2019t just find a pattern and copy it into your program, the way you can with off-the-shelf functions or libraries. The pattern is not a specific piece of code, but a general concept for solving a particular problem. You can follow the pattern details and implement a solution that suits the realities of your own program.</p> <p>Design Patterns Vs Algorithms</p> <p>Patterns are often confused with algorithms, because both concepts describe typical solutions to some known problems. While an algorithm always defines a clear set of actions that can achieve some goal, a pattern is a more high-level description of a solution. The code of the same pattern applied to two different programs may be different.</p> <ul> <li>An analogy to an algorithm is a cooking recipe: both have clear steps to achieve a goal.</li> <li>On the other hand, a pattern is more like a blueprint: you can see what the result and its features are, but the exact order of implementation is up to you.</li> </ul>"},{"location":"05-design-patterns/introduction/#history","title":"History","text":"<p><code>four authors: Erich Gamma, John Vlissides, Ralph Johnson, and Richard Helm</code>; in 1994, they published Design Patterns: Elements of Reusable Object-Oriented Software, in which they applied the concept of design patterns to programming.</p> <ul> <li>The <code>book featured 23 patterns</code> solving various problems of object-oriented design and became a best-seller very quickly.</li> <li>Due to its lengthy name, people started to call it \u201cthe book by the gang of four\u201d which was soon shortened to simply \u201cthe GoF book\u201d.</li> </ul>"},{"location":"05-design-patterns/introduction/#criticism","title":"Criticism","text":""},{"location":"05-design-patterns/02-creational/01-singleton/","title":"Singleton Design Pattern","text":"<ul> <li>Only one instance of a class will be available at any time.</li> <li>E.g., a single instance of a database connection pool.</li> </ul> <pre><code>// main.go file\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nvar lock = &amp;sync.Mutex{}\n\ntype single struct {\n}\n\nvar singleInstance *single\n\nfunc getInstance(wg *sync.WaitGroup) *single {\n    defer wg.Done()\n\n    // check if instance is already created, to avoid latency bcoz of locks\n    if singleInstance == nil {\n        lock.Lock()\n        defer lock.Unlock()\n        if singleInstance == nil {\n            fmt.Println(\"Creating single instance now.\")\n            singleInstance = &amp;single{}\n        } else {\n            fmt.Println(\"Single instance already created.\")\n        }\n    } else {\n        fmt.Println(\"Single instance already created.\")\n    }\n    return singleInstance\n}\n\nfunc main() {\n\n    var wg sync.WaitGroup\n\n    for i := 0; i &lt; 30; i++ {\n        wg.Add(1)\n        go getInstance(&amp;wg)\n    }\n\n    wg.Wait()\n}\n</code></pre> <ul> <li>If we'd used something like:</li> </ul> <pre><code>func getInstance(wg *sync.WaitGroup) *single {\n    defer wg.Done()\n\n    // check if instance is already created, to avoid latency bcoz of locks\n    lock.Lock()\n    defer lock.Unlock()\n    if singleInstance == nil {\n        fmt.Println(\"Creating single instance now.\")\n        singleInstance = &amp;single{}\n    } else {\n        fmt.Println(\"Single instance already created.\")\n    }\n    return singleInstance\n}\n</code></pre> <ul> <li><code>locking</code> would have been a bottleneck. So, better to first make sure that the instance is not created, and only then lock and create it.</li> </ul>"},{"location":"05-design-patterns/02-creational/01-singleton/#but-why-use-lock-for-singleton","title":"But, why use <code>lock</code> for singleton?","text":"<ul> <li>If different threads are trying to create the single instance, then possibly both of them will be able.</li> <li>So, we need to use <code>lock</code> to make sure that only one thread is able to create the single instance.</li> </ul>"}]}